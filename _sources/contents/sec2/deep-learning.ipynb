{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(sec:deep-learning)=\n",
    "# 深層学習による物体認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "前回、[特徴量抽出](sec:feature-extraction)では、画像から特徴量を検出し、それを画像認識に利用する方法を見てきた。\n",
    "\n",
    "2000年台まで、画像認識の分野では、**画像を如何に特徴化するか**と**得られた特徴からどのように物体を認識するか**という二つの研究が中心となってきた。\n",
    "\n",
    "そのために、SIFTを始めとする特徴量の改善や、カーネル法を用いたSVMの性能改善などが試みられてきたが、その性能は徐々に頭打ちになっていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**深層学習の歴史**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "そんな折、彗星のごとく現れた技術がニューラルネットワークを多層化した深層学習である。実は、ニューラルネット自体は人間の脳のシナプス同士の結合を模したモデルとして1950年代から研究されていた。\n",
    "\n",
    "最初にニューラルネットが日の目を見たのは1980年代で、この頃には、入力層、隠れ層、出力層の三層を持つニューラルネットがある程度の性能を出せることが知られていた。当然ながら、その当時も、より多層のニューラルネットワークを利用しようという考え自体はあり、検討が試みられたが、ニューラルネットワークの持つ多数のパラメータを上手く最適化する手法がなく、その時代には実現が難しいと考えられていた。\n",
    "\n",
    "なお、多層のニューラルネットの考え方を最初に提唱したのは、当時NHKの放送技術研究所の研究員であった福島邦彦氏であるとされており、その論文は、驚くべきことに1980年に出版されている {cite}`fukushima1980neocognitron`。\n",
    "\n",
    "2010年代に入ると、それまで下火だったニューラルネットが再び注目を集めることになる。それまで細々と続けられていたニューラルネットワークの研究の中で、パラメータの過学習や、最適化時の勾配消失といった問題が徐々に解決されるとともに、GPUを用いた汎用計算であるGPGPU (General Purpose Computing on GPU)により並列計算の公立が大幅に上昇するなど、ニューラルネットワークを取り巻く環境が徐々に変化してくる。そして、2012年に事件が起こる。\n",
    "\n",
    "ImageNetと呼ばれる大規模画像データセットの識別チャレンジであるILSVRC (ImageNet Large Scale Visual Recognition Challenge)において、トロント大学のGeoffrey Hintonらの研究チームが、AlexNet (筆頭著者のfirst nameから)と呼ばれる二股のニューラルネットを用いて、2位のエラー率26.2%に大差をつけ、エラー率わずか17.0％を達成し、優勝する {cite}`krizhevsky2012imagenet`。この時の2位のチームが用いた手法はSIFT, Fisher Vector, SVMを組み合わせたものであった。\n",
    "\n",
    "この優勝を皮切りに、2013年の大会ではオックスフォード大学のチームがVGGというネットワークで2位に入り、以後、2014年はGoogleのチームがGoogLeNetというネットワークで2位、2015年はMicrosoftのチームがResNetというネットワークで優勝する。\n",
    "\n",
    "こうして、2016年くらいになると、現在のニューラルネットワークの構築において一般的になっている諸技術、例えば、\n",
    "\n",
    "- Rectified Linear Unit (ReLU)\n",
    "- Max Pooling\n",
    "- Dropout\n",
    "- Batch Normalization\n",
    "- Skip Connection (Residual Block)\n",
    "- Adaptive Momentum Estimation (Adam)\n",
    "\n",
    "などの技術が、一通り出そろう。\n",
    "\n",
    "さらには、この頃になるとNVIDIAのCaffeや、モントリオール大学のtheano、FacebookのTorch、そしてPreferred NetworkのChainerといった汎用の深層学習用ライブラリが多数登場する。これによって、深層学習の研究が一気に花開き、現在に至る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "10000"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "n_samples"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "下準備のコード\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from tqdm.notebook import tqdm\n",
    "from myst_nb import glue\n",
    "\n",
    "# 実験に使うサンプル数\n",
    "n_samples = 10000\n",
    "glue(\"n_samples\", n_samples, display=False)\n",
    "\n",
    "# グラフの設定\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 150\n",
    "sns.set(style=\"white\", palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4fee0644a9407cb9a156d036956d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "平仮名73文字データセットの準備\n",
    "\"\"\"\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://lab.ndl.go.jp/dataset/hiragana73.zip\"\n",
    "filename = os.path.basename(url)\n",
    "\n",
    "# HTTPリクエストを送ってデータサイズを取得\n",
    "r = requests.get(url, stream=True)\n",
    "total_size = int(r.headers.get(\"content-length\", 0))\n",
    "chunk_size = 65535\n",
    "\n",
    "# 実際のファイルのダウンロード\n",
    "pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True)\n",
    "with open(filename, \"wb\") as f:\n",
    "    for data in r.iter_content(chunk_size):\n",
    "        f.write(data)\n",
    "        pbar.update(chunk_size)\n",
    "\n",
    "# ダウンロードが完了したらZIPを展開する\n",
    "with zipfile.ZipFile(filename, \"r\") as f:\n",
    "    f.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## PyTorchの基本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of y = f(x) is 8.0\n",
      "The value of dy/dx is 12.0\n"
     ]
    }
   ],
   "source": [
    "# 変数を作成後、自動微分を有効にする\n",
    "x = torch.Tensor([2.0])\n",
    "x.requires_grad_(True)\n",
    "\n",
    "# y = f(x) = x^3の計算\n",
    "y = x * x * x\n",
    "print(\"The value of y = f(x) is {:.1f}\".format(y.item()))\n",
    "\n",
    "# 微分の計算\n",
    "y.backward()\n",
    "print(\"The value of dy/dx is {:.1f}\".format(x.grad.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### データローダの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HiraganaDataset(Dataset):\n",
    "    def __init__(self, dataroot, transform=None):\n",
    "        super(HiraganaDataset, self).__init__()\n",
    "\n",
    "        self.dataroot = dataroot\n",
    "        self.transform = transform\n",
    "\n",
    "        folders = sorted([d for d in os.listdir(self.dataroot)])\n",
    "        chars = [chr(int(d.replace(\"U\", \"0x\"), 16)) for d in folders]\n",
    "        n_chars = len(chars)\n",
    "        char2num = {c: i for i, c in enumerate(chars)}\n",
    "\n",
    "        folders = [os.path.join(self.dataroot, d) for d in folders]\n",
    "        self.data = []\n",
    "        for d in folders:\n",
    "            char = os.path.basename(d).replace(\"U\", \"0x\")\n",
    "            char = chr(int(char, 16))\n",
    "            num = char2num[char]\n",
    "\n",
    "            image_files = [os.path.join(d, f) for f in os.listdir(d)]\n",
    "            image_files = [f for f in image_files if f.endswith(\".png\")]\n",
    "            image_files = sorted(image_files)\n",
    "            self.data.extend([(f, num) for f in image_files])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file, num = self.data[idx]\n",
    "        image = Image.open(image_file)\n",
    "        if image is None:\n",
    "            raise IOError(\"Failed to load image: {:s}\".format(f))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = transform(image)\n",
    "\n",
    "        return image, num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### ネットワークの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.fc3 = nn.Linear(32, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.fc1(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.bn2(self.fc2(x))\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        y = F.log_softmax(x, dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(),\n",
    "        transforms.RandomAffine(degrees=[-90, 90], scale=[0.8, 1.1]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float32),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = HiraganaDataset(dataroot=\"hiragana73\", transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "例のごとく、最初の{glue}`n_sample`個のデータだけを実験に用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, dataset = torch.utils.data.random_split(dataset, [n_samples, len(dataset) - n_samples])\n",
    "test_data, _ = torch.utils.data.random_split(dataset, [n_samples, len(dataset) - n_samples])\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 最適化手法の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = Network(48 * 48, 73)\n",
    "optim = torch.optim.Adam(net.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 誤差関数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674645117bc84d48b64c698beaca651f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(train_loader)\n",
    "for data in pbar:\n",
    "    X, y_true = data\n",
    "    X = X.reshape((X.size(0), -1))\n",
    "    y_pred = net(X)\n",
    "    loss = criterion(y_pred, y_true)\n",
    "    acc = (torch.argmax(y_pred, dim=1) == y_true).float().mean()\n",
    "\n",
    "    pbar.set_description(\"loss={:1.3f}, acc={:1.3f}\".format(loss.item(), acc.item()))\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1bd07eed454cefb5eaef596743afe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.291\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(test_loader)\n",
    "n_succ = 0\n",
    "for data in pbar:\n",
    "    X, y_true = data\n",
    "    X = X.reshape((X.size(0), -1))\n",
    "    y_pred = net(X)\n",
    "    n_succ += (torch.argmax(y_pred, dim=1) == y_true).float().sum()\n",
    "\n",
    "print(\"Acc: {:.3f}\".format(n_succ / len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 畳み込みニューラルネット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 32, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.fc3 = nn.Linear(12 * 12 * 32, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.relu(x)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = torch.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.reshape((x.size(0), -1))\n",
    "        x = self.fc3(x)\n",
    "        y = F.log_softmax(x, dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = CNN(1, 73)\n",
    "optim = torch.optim.Adam(net.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d988e2e0c1e74d0f93efb248878a143b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(train_loader)\n",
    "for data in pbar:\n",
    "    X, y_true = data\n",
    "    y_pred = net(X)\n",
    "    loss = criterion(y_pred, y_true)\n",
    "    acc = (torch.argmax(y_pred, dim=1) == y_true).float().mean()\n",
    "\n",
    "    pbar.set_description(\"loss={:1.3f}, acc={:1.3f}\".format(loss.item(), acc.item()))\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810d2a17a5624e2c8fdd7d64cdbf84ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.504\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(test_loader)\n",
    "n_succ = 0\n",
    "for data in pbar:\n",
    "    X, y_true = data\n",
    "    y_pred = net(X)\n",
    "    n_succ += (torch.argmax(y_pred, dim=1) == y_true).float().sum()\n",
    "\n",
    "print(\"Acc: {:.3f}\".format(n_succ / len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 参考文献\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
