{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(sec:q-learning)=\n",
    "# Q学習の基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ここまでで扱った多腕バンディット問題は、取れる行動の種類が少なく、また、問題の状態が変化しない、すなわち、いつスロットを回しても、各アームの当たり確率は変化しない、という特徴があった。しかし、実際の問題は取れるべき行動の種類が多く(場合によっては連続変数)、また、ある時刻で取った行動により、行動を行う対象の状態が変化するのが一般的である。\n",
    "\n",
    "このような状況において用いられる強化学習の手法に**Q学習**がある。Q学習のQとは**行動価値関数**を表すQ値のQであり、とある**状態**$s$ (stateのs)において取った**行動**$a$ (actionのa)の価値を関数として、$Q(s, a)$のように表す。\n",
    "\n",
    "このようなQ値を学習する方法はQ学習以外にも**SARSA**(state-action-reward-state-action)と呼ばれる方法もあるが、本節ではQ学習に絞って説明する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "下準備のコード\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "\n",
    "try:\n",
    "    from myst_nb import glue\n",
    "except:\n",
    "    glue = lambda _: _\n",
    "\n",
    "# 乱数のシードを固定\n",
    "random.seed(31415)\n",
    "np.random.seed(31415)\n",
    "\n",
    "\n",
    "# グラフの設定\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 150\n",
    "sns.set(style=\"white\", palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are running the code in the local computer.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Google Colab用の準備\n",
    "\"\"\"\n",
    "\n",
    "IN_COLAB = True\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    print(\"You are running the code in Google Colab.\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"You are running the code in the local computer.\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Gymnasiumのインストール\n",
    "    !pip install \"gymnasium[classic-control]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 背景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Q学習で扱う対象は**Markov決定過程**と呼ばれる状態遷移のモデルである。\n",
    "\n",
    "Markov決定過程をかみ砕いて言えば、その時々で取った行動により次の状態が変化するが、それより過去に取った行動がその状態の変化に影響を与えることはない、という性質 (この性質を**Markov性**と呼ぶ)を満たす状態遷移のモデルである。\n",
    "\n",
    "Markov性を満たす状態遷移であれば、とある状態$s$において、行動を$a$取ったときに、別の状態$s'$に移る確率は$s, a$だけに関する事後確率として$P(s' | s, a)$のように書ける。\n",
    "\n",
    "Q学習では、この事後分布$P(s' | s, a)$を用いて、行動評価関数$Q(s, a)$が以下のBellmanの最適性公式を満たすと仮定する。\n",
    "\n",
    "$$\n",
    "Q(s, a) = R(s, a) + \\gamma \\sum_{a' \\in \\mathcal{A}} P(s' | s, a) Q(s', a')\n",
    "$$ (eq:bellman-equation)\n",
    "\n",
    "この式において$\\gamma$は**割引因子** (discount factor)と呼ばれる値で、$0 < \\gamma < 1$であり、$R(s, a)$は状態$s$において行動$a$を取ったときに即座に得られる報酬を表す。\n",
    "\n",
    "{eq}`eq:bellman-equation`は、**最適な行動価値関数が、その時、即座に得られる報酬$R(s, a)$と未来の行動から得られる報酬に一定の減衰を加えたものの和として表せる**ことを示している。\n",
    "\n",
    "一方、多くの状態遷移のモデルでは、状態遷移は確率的なものではなく、行動$a$の結果として**一意に次の状態が決まる**ことが多い。そこで$P(s' | s, a) = 1$と仮定する。さらに、仮に理想的なQ関数が求まっているのであれば、$s'$において行動価値が最大になる行動$a'$をQ関数から決定できるので、$a'$は行動価値が最大になるものであると仮定する。\n",
    "\n",
    "これら2つの仮定により、{eq}`eq:bellman-equation`は、以下の形で書き直せる。\n",
    "\n",
    "$$\n",
    "Q(s, a) = R(s, a) + \\gamma \\max_{a' \\in \\mathcal{A}} Q(s', a')\n",
    "$$ (eq:bellman-equation-2)\n",
    "\n",
    "Q学習は、{eq}`eq:bellman-equation-2`を満たすような$Q(s, a)$を強化学習の枠組みによって求めるものである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Q学習は、実際の環境において、適当な行動を取ったときに得られる報酬と状態遷移から、{eq}`eq:bellman-equation-2`の両辺の差が小さくなるように$Q(s, a)$の値を更新する。\n",
    "\n",
    "典型的なQ学習の実装では、$s$と$a$を離散化して、$Q(s, a)$を二次元配列として扱う。このような離散化されたQ関数を**Qテーブル**と呼ぶ。\n",
    "\n",
    "Qテーブルの更新は現在の$Q(s, a)$の値 (学習途中は必ずしも{eq}`eq:bellman-equation-2`を満たしていないことに注意)を{eq}`eq:bellman-equation-2`の右辺に近づくように更新する。\n",
    "\n",
    "具体的には、学習率$0 < \\alpha < 1$を用いて、以下の式で$Q(s, a)$を更新する。\n",
    "\n",
    "$$\n",
    "Q_{\\rm new}(s, a) = (1 - \\alpha) Q(s, a) + \\alpha \\left[ R(s, a) + \\gamma \\max_{a'} Q(s', a') \\right]\n",
    "$$\n",
    "\n",
    "また、この式は以下の形で書き直すことができる。\n",
    "\n",
    "$$\n",
    "Q_{\\rm new}(s, a) = Q(s,a ) + \\alpha \\left[ R(s, a) + \\gamma \\max_{a'} Q(s', a') - Q(s, a) \\right]\n",
    "$$ (eq:q-update)\n",
    "\n",
    "{eq}`eq:q-update`の右辺の\n",
    "\n",
    "$$\n",
    "R(s, a) + \\gamma \\max_{a'} Q(s', a') - Q(s, a)\n",
    "$$\n",
    "\n",
    "は、**TD誤差** (temporal difference error)と呼ばれ、Q学習はこのTD誤差を最小化する問題であると言い換えることができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 倒立振子のバランシング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Q学習を実際に試すために、比較的単純な倒立振子のバランスを取るゲームについて考える。倒立振子のシミュレータは[Gymnasium](https://gymnasium.farama.org/)というライブラリ(旧名: OpenAI Gym)から簡単に使用することができる。\n",
    "\n",
    "モジュール`gymnasium`をインポート後 (`gym`とエイリアスをつける)、`gym.make`関数を用いてゲーム環境`env`を作成してみる。\n",
    "\n",
    "`gym.make`関数に倒立振子のゲーム環境である`CartPole-v1`を指定し、`render_mode`パラメータに`rbg_array`を指定する。\n",
    "\n",
    "このように`render_mode`を指定しておくと、`env.render`関数によって画面の情報をNumPyの配列として得ることができるので、Matplotlibを用いて、初期状態を描画してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# ゲーム環境の作成\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# ゲーム環境のリセット\n",
    "obsrv = env.reset(seed=31415)\n",
    "\n",
    "# 現在の状態をRGB画像として取得する\n",
    "img = env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "ax.set(xticks=[], yticks=[])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "このように、CartPoleは台車 (cart)の上に倒立振子 (pole)が取り付けられたものを制御して、できる限り長い時間、振子が倒れないようにバランスを取るゲームである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "倒立振子は、その状態を表すいくつかのパラメータを持っており、それが`reset`関数の戻り値として取得される`obsrv`の中に格納されている。\n",
    "\n",
    "`obsrv`は`tuple`型の変数になっていて、CartPole環境の場合には**第1要素に状態を表す変数が入っている**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.1067048e-05 -3.8479745e-02  3.6217723e-02  3.3740070e-02]\n"
     ]
    }
   ],
   "source": [
    "# 現在の状態変数を確認\n",
    "print(obsrv[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "CartPole環境の場合は、4つの浮動小数が格納されており、先頭から、\n",
    "- 台車の水平位置\n",
    "- 台車の速度\n",
    "- 振子の角度\n",
    "- 振子の角速度\n",
    "をそれぞれ表している。\n",
    "\n",
    "また、それぞれの値が取る範囲は以下のようになっている [[参考URL]](https://gymnasium.farama.org/environments/classic_control/cart_pole/)。\n",
    "\n",
    "|Num|Observation|Min|Max|\n",
    "|---|---|---|---|\n",
    "| 0 | 台車の位置 | -4.8 | +4.8 |\n",
    "| 1 | 台車の速度 | -Inf | +Inf |\n",
    "| 2 | 振子の角度 | -24° | +24° |\n",
    "| 3 | 振子の角速度 | -Inf | +Inf |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "この値は、`env`の`observation_space`フィールドで確認することができる。\n",
    "\n",
    "CartPole環境の場合には`observation_space`は`Box`という型で表されていて、`low`、`high`というフィールドにパラメータの最小値、最大値が格納されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bound: [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "Upper bound: [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lower bound:\", env.observation_space.low)\n",
    "print(\"Upper bound:\", env.observation_space.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Gyminasiumのゲーム環境には、この他にも多数の関数が用意されており、それを強化学習に用いることができる。\n",
    "\n",
    "まずは、その挙動を理解するために、ランダムに行動を選んだ場合にどのような動きになるのかを確認してみよう。\n",
    "\n",
    "ランダムな行動選択には、`env.action_space.sample()`を使うことができる。CartPole環境の場合には`env.action_space.n`に格納されているとおり、取り得る行動は **0: 左に移動**, **1: 右に移動** の2つだけなので、`sample`関数はこのうちの一方をランダムに返してくる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# ランダムに5回行動選択をしてみる\n",
    "for i in range(5):\n",
    "    print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "選んだ行動をとって状態を更新するには`env.step`関数を用いる。`step`関数の引数に行動を表す整数を与えることで状態が更新される。\n",
    "\n",
    "`step`関数もまた`reset`関数と同様に`tuple`型の変数を返してくる。ここには`reset`関数の時よりも多くの情報が含まれていて、\n",
    "\n",
    "- **第1要素:** 現在の状態を表すパラメータ (上記の`obsrv`と同様)\n",
    "- **第3要素:** 行動により直接得られた報酬\n",
    "- **第4要素:** エピソードが終了したかどうか (ゲームオーバーになったかどうか)\n",
    "- **第2要素:** 行動を表すパラメータが範囲外に外れたかどうか (今回は使用しない)\n",
    "- **第5要素:** その他の追加情報 (今回は使用しない)\n",
    "\n",
    "のような構成となっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [-0.00080066 -0.23410185  0.03689252  0.3376265 ]\n",
      "Reward: 1.0\n",
      "Finished?: False\n"
     ]
    }
   ],
   "source": [
    "obsrv, reward, done, _, _ = env.step(0)\n",
    "print(\"Observation:\", obsrv)\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Finished?:\", done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムな行動選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "これらを用いてランダムに行動選択をし、その時々の状態を画像として格納する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ゲーム環境のリセット\n",
    "obsrv, _ = env.reset()\n",
    "frames = []\n",
    "\n",
    "# ゲームループ\n",
    "while True:\n",
    "    # 現在の画面を画像として保存\n",
    "    img = env.render()\n",
    "    frames.append(img)\n",
    "\n",
    "    # ランダムに行動選択\n",
    "    a = env.action_space.sample()\n",
    "\n",
    "    # 状態を更新する\n",
    "    obsrv, reward, done, _, _ = env.step(a)\n",
    "\n",
    "    # もしゲームが終了していたらループを抜ける\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAEk1tZGF0AAACrwYF//+r\n",
       "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzEwOCAzMWUxOWY5IC0gSC4yNjQvTVBF\n",
       "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMyAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
       "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
       "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
       "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
       "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTE1\n",
       "IGxvb2thaGVhZF90aHJlYWRzPTIgc2xpY2VkX3RocmVhZHM9MCBucj0wIGRlY2ltYXRlPTEgaW50\n",
       "ZXJsYWNlZD0wIGJsdXJheV9jb21wYXQ9MCBjb25zdHJhaW5lZF9pbnRyYT0wIGJmcmFtZXM9MyBi\n",
       "X3B5cmFtaWQ9MiBiX2FkYXB0PTEgYl9iaWFzPTAgZGlyZWN0PTEgd2VpZ2h0Yj0xIG9wZW5fZ29w\n",
       "PTAgd2VpZ2h0cD0yIGtleWludD0yNTAga2V5aW50X21pbj0xMCBzY2VuZWN1dD00MCBpbnRyYV9y\n",
       "ZWZyZXNoPTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0w\n",
       "LjYwIHFwbWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAA\n",
       "BF9liIQAO//+906/AptFl2oDklcK9yHrOuLcX/hC+FSuAAADAAADAAADADB2N9dUvGtnWaAAAAvY\n",
       "AjYN4Pvgdr3AH/kMlsqeC/bNDXCRTvmkQnSOiYZefk4T9jcR+GTlwOONRA+T1RV7yOMuzRm6oBKz\n",
       "QnUBRhfcrNrbYaku1sqO0WKmnU+gyBgiZ+2xVmp5EiEVMlMyth5X+DKv0SzzPIO2UJoYySL+6jys\n",
       "0pfVj2vwuJl68zgOWU5+BImYG0yjs1mlV4bMmNHXaQsriGqMyPnKFm0rwyubk17mkgoJHrq5Mv27\n",
       "qqjFkPmhebJsUq+JimkLeQX1H6lexuHPGMLmn7jkIVbelt6xV+E7/6pjE2zg+xfoCwlgw5qkwqzX\n",
       "qzTnjajJf526INBaFovZosIR0hkifKS+vnNQr1gZrnrTWzhTAKxUyg29oPPN3HOij+OZOTTC0CHF\n",
       "mB6gjk0RQX1W1rE3q939nTWienN3tXqAAAArHXD4V2qRMQV3QvKcNYajQ+VfypZgsOCkS76M/ZOC\n",
       "pLNzET8srKkPTrfJ+lR5BXZkD47r627itl648iGHU/pedO10ANG/6UOvimYSu/bTA3EE4ath4o+R\n",
       "qOEoQ0J1aAbtsDPpuaLo1bv9i5RB6nYKTC2upxd88NezxSDcLJws0NzxLn+5Usb3z4p6XZ/O/W5o\n",
       "7JDbousDWD7lmtaFO6W6q+cQks7EZPeKy5bKNpbz/rlRZOF5fHyzADj02IvEGT7+DxkT4p38IDjs\n",
       "jlqhIJsoZUuKFEJX4g6063JGfUwmAq9z+rD4+EQKXcjXfAAAAwBUEZ61Lq0cAAEqgK/DLAAAAwAA\n",
       "FdpBoApz9KTvNl6NoLQM6cD/0JPjJFNn7Swm/gtBLPxFzTmX/1x85g97YJlJdcxsu/Uc1qwABD5u\n",
       "4N8RszlhSheaU4AEqr2qZhBEHiXvPE8ws8oVD9FwxWIAkZxTGzX+9aI6uTx2ERzLvLG/7Ic8jqrv\n",
       "+MHh3iFbUk7HaCRZTrSitlSauTPqe+OVjkWpGeo6ZyK6wEFu1Q7r+BBGT10hcUv/nmwGoFKESN1g\n",
       "sK+L4pTWp/cFYImXotnt6zSar0sMknIfAH1aTKuTEZ0zMm4sFQfWtPlBkFhRae1S5i7fs8+DUk3M\n",
       "gwQpcmC9TIfKog1XnpnyAY7njYk9sscn/u/do14IfyO5xK7wLpOuhokTExs8MILnN6mA1x1K8DRK\n",
       "VdbDlpQUXu5AOZeA3LVlNqZ7X956qWoEGXuutxGpqPJV/8UDuRVwisjHL98fIksgOBqQ8Q+enyp+\n",
       "1bMXFA16W2TfDXzfMboqOTL/LhYt7PXGb7ttJ4xee3z54JSa5W60ISQ3o7dqDpAR+X4YAAADAAAD\n",
       "AUinghXOg1nN1yQ4Oq1FS9QlAIguZB6c2uRoAkLI8OFqzSFYjm2ZW6DbYWBdtQgr+XlY08CoRmWH\n",
       "ViFmcKVfYjTk5zweKtLbDG1kYf7xP+rDRJYgAAADAAADAAADAWcAAAFnQZokbEO//qmWAATBdnoA\n",
       "hGpxsmaD6zeEtQN40nkBfg2OlIAGB/mmXKvyq77rho0CRpAyqEhQMSxgOdnEs6BfZ2QMf9zgAQa9\n",
       "ot7xxo1kd33xsBrqoen/I9uy7LPB862XUIQEOicgADXQnC4QbjGmwq5/n2pSSvFwMyW0WWOCvh53\n",
       "7g57EO+JGEsjhz49lpzaadnk1pgKEuQTWbBt8KZYB2EkUgoIEbV5j7SbGTVFqcMVxXMRlhgXeykc\n",
       "vdZpD9xZWr++tivcNTTiup18N/O+KYAx+Fd2zgYhwim0JicL0RaBKPpeHY/ZyBgr+vhfqsenuDaq\n",
       "2VWLKOFsvEXZTiSKkSZGPh1FX2r/a1zrSMex6tC6Ed18phtnqJsIAvKztHbe6HQvAWYT7SNT3BQ8\n",
       "xvqeBmQ/963n51SdYkxhYWGhoJDY8PEItQkt4o/EC4xGLMHAbqhm6fhc/6kg5WZmRhZ9smComPsH\n",
       "KiQAAACfQZ5CeId/AAJg5WeQLuUAEs5ybct0Td2Bup+58r7rGUfGlFJUcWPbuIN3raBpJ1GCqUZp\n",
       "zMun2+oyUKXYYH3WCXrcjUOlCw9Nj6+mxbkOCThfTHw9Yy/YhZmzicX/3qbSJDLZfZwQ+WCFMAPy\n",
       "a50NazNrGqoclRy8Ya8oAEewZnpaymCqC2xj0QzxUqaYVOPRai+SGMoL1y6VPgUe0NSBAAAAcAGe\n",
       "YXRDfwADX9anRNcAJei5EkDLfGCI8oOxHewqzN8QXPnGTkR2ZsLIqapDt5nQNX7S24Ek8D/Y3Wpp\n",
       "RP189H/cPmr3aCp26SYRVwsrtE/kR4Zq8c8Ab6nbP5OtMdY2K9w4uG4LoiKpIA9dBeVeN6AAAACQ\n",
       "AZ5jakN/AAMvIKCQAgZRGImq5DCVFp8bKNlBZ9llQ2+gBcGogoVRL8InqF2H8r3e7XppFjENKg5n\n",
       "dWrc00tHrFyO7iAieLO/rU+KxnVyvkQO6prz6jePhRcSwVqW6AgTQ/2yRJLc0P2NfwjXc2MYxO8Z\n",
       "oMMM1xg/QUrFZ6oMspw14CcymctPehs7Q6ehyD5hAAABS0GaaEmoQWiZTAh3//6plgAEgm/MaAFW\n",
       "2X3Yb+CLgmcfKxctqr8jg4/XB9+fYf9Og699g6TliPVxLRdqPjPmhdb+jUTTCiq1gMNc0cMw7Drl\n",
       "f3eYhXRXQrzkf7jiJpH/ObURhFTvALrFagnzcRo0CwWUCy/10aMzCQBez06TBDUzHH6kuc+jmt4L\n",
       "+O0BW2pOO2bMGfJCGiaAdOcZrEKrMpjfojNPYHsNaNztDuaIjjNbP0V86KUGpR4G47UTe3Vveqyl\n",
       "Lgh0ud90cn8Ho3Puk9D8YM/ANCaS3dgvJuOM0KQjVevpVZjz2xRUiosW8gk/PvLE0qqvEPbIK719\n",
       "yl1kqTM5hsydNLalj6No6sQAs4jIqkM5O0FObsLuqx4oHyr2BYFTivskKtrqfLEs5IIPhMNdVtse\n",
       "cP2tLoQXTsuBK6LpT79jbHK2QwUHBO0AAACuQZ6GRREsO/8AAjpolsQANWDqY6O9SkfgLhzNRAMF\n",
       "xvrRUCm7G1bP4o2eGGZsF73xp111kvY+5nUzMopTs3D6n//wqkL0KG/Hsy0D7K2gDHY2/uWf7J5i\n",
       "inJs+6sgfaeEFTI3aGLyfAV6IxTCLK+y6pMVHgugQfoTrBZpvzyREFq/dMYCrV5l9synRR07AQ34\n",
       "vyUL/VMhZ3eNk0WVG6/TN0Mce4x3pv9UQGTg+AFbAAAAkwGepXRDfwADN5Yb3ACBkVUK/kALZ+Kj\n",
       "TaD2IxTzd6Hw937p7PVnN1B1F7RNJFCh6ae7wE6nQvOrP4ltnP/DymbnqsppS3ywUa1gd588Cce5\n",
       "bOJejWh3di31sCpLxITy+3yMT5vqLA9Z9xfPcft5Ft1Uv1dEYG3IChZZ/0qr6mAKk9tmSdbHdeja\n",
       "ZDqq6XquatxFVQAAAIUBnqdqQ38AAzgFuQAhOhuMeoAcgkpOz/c2pNk3zYQjl+wrY/UeelK3wJcf\n",
       "2aPoFwTdP9HQcavdoCzXkOMdDuXmrsaP2QDTIAhRJEbgraxgi885iPBtLhR52jpeXMKD4kNZy1ki\n",
       "0B+fEMlMmFQryhiju03PWM8gqHwmShy80t9pERRriwHdAAABgkGarEmoQWyZTAhv//6nhAAI9SaU\n",
       "4AB/g1+Ye+QZlmAsDxc2+eNL8lp25nVpYyoI8Xx7I3Z7olOkdmF0bj1Yt8PMKGMlelefmUuNu5Lt\n",
       "XGc3jAFuQSNw44RuA87kP01fo9c0rk49ItW44+mD5KEopWvDwXvIXGSlavgwqgmWiex6l6FZeB3A\n",
       "8WRojRVz/xWcQGBVUziBB64fiefog7Uaaf2DZ7ACqzML6hJHcNd6itQRQUY3YO61a9wIUnxY36Tc\n",
       "5DXtUnAFurov0Tq1sFUQZ4f0Ic0V7aqezcjwbq1pQbDwt+Koum8OUnKnwwDf4yf3aJCL7BT5Ea1W\n",
       "Brwh56/+XtiEeg/fmPXNgYGPNRlLCOFAeWMIGqBer4hCmX5LLtxfFo18sTtzUVhsajVfd+DfGyD2\n",
       "mGIeVMFandFtHTEHcMxFblROH2MAxFJTE4VJoPl6bTRL2o5PQAh0Wdh1hyENJhlBeuwTjPQjRFIt\n",
       "LiCibgItTHSQ8hnTKLMdn0qh/wb2gzQ8AAAAuUGeykUVLDv/AAJA41N2WDgAmX8l9hr94zET+tJF\n",
       "BGBzC8Gu58QwHAJUdTNCjXD0mgsZvJN2sAABHIGbdNTiJnD1PCCpwS3bUD+g89Ys7V95zWCuPUI5\n",
       "Z3ydlht6e/hJzDUtK4ULDCPQytUFG5e0vV42AIvj0jNI+DlByGYvKp+ux7YNEGiCrh+adT9FlJlo\n",
       "MxU3SdTaDUJVdUsXM+nuNSU2lXVLrZmnI1k6zEH0jeA5b/UhPO5HAA/xAAAAhwGe6XRDfwADN9Vv\n",
       "SEgA+HZ9RDgt9Cx9tnlTeL1zOLBD6fUXUPy5J7BePbTaHSfhKwSOxLu4twVA2k8qO6g+bH2CYoM3\n",
       "ALBdXoqIBYw/u8bIbUNsty2LhsBJnUi86UMMfuORLPQV/W/C+3NxKZAUHcGP4YQDXyA1IpLNG+lJ\n",
       "vkRQUlLtojwNmAAAAJQBnutqQ38AAyL38vIATV7fEZVQKe41ZWzAEXiGCtLSz//6KPryqF4ryoAk\n",
       "PO4wPyuca7n2wIOVzYY2IMcRhs5iDPFS3UyfH5EDOGk/Mz17ypPQGTm79lbSOpSQopuFBqMqAplI\n",
       "xDQHdpLJyqhONyA+Csjs68TK0E7K1tNSVyxcOObdF+lzoQjuc7uShlBXQLAe4Af4AAAA10Ga7kmo\n",
       "QWyZTBRMN//+p4QACKcu3/BDeAAm347HnqTGCQstmCkhJU++8L9wlUBQ6lsLtOeIblaj/PNcHx17\n",
       "4nehVR2Tob4FDcuWpU4FsIqs9lI1dQp1DKhUdWqjRCfy0sdYadxFfQ8+CX8xH9+c1nCCaXKPg4Nl\n",
       "T5djGx5IA51buKSYMVucq2nle2mspb7yQ86rxWBjF9w2biIfW/fhhzcg9Rl1cAx5tPZ3ihf0KkHo\n",
       "kjmZQSsi1YpOiAhbY8mdZNj6OEy2G8NQimX2iFvZt3iyLytwBv/BAAAAswGfDWpDfwADHHX4dZeP\n",
       "X8AJVGXdLQ1UT7/0Ueyta6IM5BujeQHy5w4RD1J2d2QoDtZXvI6qGtrbRe32kPKd3Z1s/JV+T+zJ\n",
       "VuAUkoI6k3ZQzXDS6ttOcGftrRlhnGlCS/LoEAXMitSd5+aW60pYVY3LAUSErYH0bHHnSJTQ9QgE\n",
       "HE3nrnrnBR5cEX+0Cfej3bm7pfMSU5CRzqAxOu3jNg7HBQn/j/zXdqYC2DdXmCemgAi5AAAD5W1v\n",
       "b3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAXcAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAA\n",
       "AAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAMQ\n",
       "dHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAXcAAAAAAAAAAAAAAAAAAAAAAABAAAA\n",
       "AAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAKAAAAB4AAAAAAAJGVkdHMAAAAcZWxzdAAA\n",
       "AAAAAAABAAAF3AAACAAAAQAAAAACiG1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAKAAAADwAVcQA\n",
       "AAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAAjNtaW5mAAAA\n",
       "FHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAHz\n",
       "c3RibAAAALdzdHNkAAAAAAAAAAEAAACnYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAKAAeAA\n",
       "SAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAADVhdmND\n",
       "AWQAFv/hABhnZAAWrNlAoD2hAAADAAEAAAMAFA8WLZYBAAZo6+PLIsD9+PgAAAAAHHV1aWRraEDy\n",
       "XyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAAAPAAAEAAAAABRzdHNzAAAAAAAAAAEA\n",
       "AAABAAAAiGN0dHMAAAAAAAAADwAAAAEAAAgAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAA\n",
       "BAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAA\n",
       "AAAAAAEAAAQAAAAAAQAADAAAAAABAAAEAAAAABxzdHNjAAAAAAAAAAEAAAABAAAADwAAAAEAAABQ\n",
       "c3RzegAAAAAAAAAAAAAADwAABxYAAAFrAAAAowAAAHQAAACUAAABTwAAALIAAACXAAAAiQAAAYYA\n",
       "AAC9AAAAiwAAAJgAAADbAAAAtwAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYXVkdGEAAABZbWV0YQAA\n",
       "AAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAsaWxzdAAAACSpdG9vAAAAHGRh\n",
       "dGEAAAABAAAAAExhdmY2MC4zLjEwMA==\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# アニメーションの描画\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.set(xticks=[], yticks=[])\n",
    "\n",
    "# 各フレームの描画\n",
    "draw = []\n",
    "for i, f in enumerate(frames):\n",
    "    ims = plt.imshow(f)\n",
    "    txt = plt.text(20, 30, f\"frame #{i+1:d}\")\n",
    "    draw.append([ims, txt])\n",
    "\n",
    "# アニメーションの作成\n",
    "ani = ArtistAnimation(fig, draw, interval=100, blit=True)\n",
    "html = display.HTML(ani.to_html5_video())\n",
    "display.display(html)\n",
    "\n",
    "# Matplotlibのウィンドウを閉じる\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "このようにランダムに行動した場合には、途中で棒の傾きが一定以上になってしまい、エピソードが終了していることが分かる。以下では、Q学習によって行動評価関数を最適化し、より長い時間、倒立状態を保てるようにしてみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Q学習による行動選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "まずはQテーブルを作成するために、4種類のパラメータを離散化しておこう。以下の例では、**速度と各速度の範囲を適当に狭めておき、その上で各パラメータの取り得る範囲を8分割する**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_INPUTS = env.observation_space.shape[0]\n",
    "N_ACTIONS = env.action_space.n\n",
    "N_DIGITS = 8\n",
    "\n",
    "lower = env.observation_space.low\n",
    "upper = env.observation_space.high\n",
    "lower[1], upper[1] = -5.0, 5.0  # 速度の範囲を修正\n",
    "lower[3], upper[3] = -0.5 * np.pi, 0.5 * np.pi  # 角速度の範囲を修正"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "今回の倒立振子の例ではパラメータ4つを8分割しているので、取り得る離散状態の組み合わせは$8^4 = 4096$通りである。取り得る行動は左に行くか、右に行くかの2種類であるので、結局、Qテーブルのサイズは$4096 \\times 2$となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q値テーブルの初期化 (乱数による初期化)\n",
    "q_table = np.random.random(size=(N_DIGITS**N_INPUTS, env.action_space.n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "8分割されたパラメータの範囲を求めるには`np.linspace`関数が使える。この関数はこれまで第1, 第2引数にスカラー値を入力して使ってきたが、サイズが同じであれば配列を指定することもできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.8        -3.4285717  -2.057143   -0.68571424  0.68571424  2.0571427\n",
      "   3.4285717   4.8       ]\n",
      " [-5.         -3.5714285  -2.142857   -0.71428585  0.71428585  2.1428576\n",
      "   3.5714283   5.        ]\n",
      " [-0.41887903 -0.2991993  -0.17951958 -0.05983984  0.05983987  0.1795196\n",
      "   0.29919934  0.41887903]\n",
      " [-1.5707964  -1.1219974  -0.67319846 -0.22439945  0.22439945  0.67319834\n",
      "   1.1219975   1.5707964 ]]\n"
     ]
    }
   ],
   "source": [
    "bins = np.transpose(np.linspace(lower, upper, N_DIGITS))\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "今、とある状態変数が与えられた時に、それが4096個の離散状態のどれに対応するのかを定めておく必要がある。\n",
    "\n",
    "これには、4つあるパラメータのそれぞれが8個の範囲のどれに入るのかを求めて、その値を元に状態を表わす整数を計算する必要がある。\n",
    "\n",
    "各パラメータが8つの範囲のどれに属するかを求めるには`np.digitize`関数が使える。4つのパラメータのそれぞれについて、リスト内包表記によって所属する範囲のインデックスを求めるとすれば、以下のようなコードになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "obsrv, _ = env.reset()\n",
    "digits = [np.digitize(o, b) for o, b in zip(obsrv, bins)]\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "現在は各パラメータの範囲を8つに分割しているので、`digits`には0-7の整数が与えられる。従って、この数字を8進数であると考えて、10進数表記に直せば、各離散状態に対して重複のない整数のインデックスを付与することができる。\n",
    "\n",
    "このような計算は、単純には以下のようなfor文を用いたコードで実現できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for n in digits:\n",
    "    index = index * N_DIGITS + n\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "もう少しPythonらしい書き方にするのであれば、`functools.reduce`関数を用いて以下のように書くこともできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "index = reduce(lambda a, b: a * N_DIGITS + b, digits)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "これを踏まえて、状態を表わすインデックスを計算するコードを関数化しておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_state_index(obsrv, bins):\n",
    "    digits = [np.digitize(o, b) for o, b in zip(obsrv, bins)]\n",
    "    return reduce(lambda a, b: a * N_DIGITS + b, digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### $\\varepsilon$-greedy法によるQテーブルの更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ここまでで下準備が整ったので、前回[強化学習の基礎](sec:reinforcement-learning)の節で紹介した$\\varepsilon$-greedy法を用いてQ学習を実行してみる。\n",
    "\n",
    "Q学習においては、とある状態$s$において**何らかの方策**によって行動$a$を決定し、行動後の状態$s'$を得る。その後、$s$, $a$, $s'$の組に基づき、{eq}`eq:q-update`に従ってQテーブルを更新する。\n",
    "\n",
    "この際、行動$a$を決定する際に用いる方策に、$\\varepsilon$-greedy法の他、前節で紹介した手法が使える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Q学習で$\\varepsilon$-greedy法を用いる場合、多腕バンディット問題の時と同様、適当な$0 < \\varepsilon < 1$を決めておき、$\\varepsilon$の確率でランダムな行動を、$1-\\varepsilon$の確率でQテーブルに基づいた最適な行動を取れば良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ランダムに行動する\n",
    "a = env.action_space.sample()\n",
    "obsrv, reward, done, _, _ = env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 一番価値が高く見積もられている行動をとる\n",
    "s0 = to_state_index(obsrv, bins)\n",
    "a = np.argmax(q_table[s0, :])\n",
    "s1 = env.step(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "今回は、以下のハイパーパラメータを用いてQ学習を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q学習のハイパーパラメータ\n",
    "alpha = 0.1\n",
    "gamma = 0.99\n",
    "n_episodes = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "また、多腕バンディット問題の時と同様に$\\varepsilon$の値はエピソードが進むごとに徐々に小さい値になるようにスケジューリングしておく。\n",
    "\n",
    "以下が、$\\varepsilon$-greedy法によるQ学習のコードの一例である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afbe965853340eeb7054a039cff1977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e0 = 0.3\n",
    "e1 = 0.001\n",
    "e_scale = np.exp((np.log(e1) - np.log(e0)) / (n_episodes - 1))\n",
    "epsilon = e0\n",
    "\n",
    "# Q値テーブルの初期化\n",
    "q_table = np.random.random(size=(N_DIGITS**N_INPUTS, env.action_space.n))\n",
    "\n",
    "for epi in tqdm(range(n_episodes)):\n",
    "    # ゲーム環境のリセット\n",
    "    obsrv, _ = env.reset()\n",
    "\n",
    "    # エピソード開始\n",
    "    while True:\n",
    "        # 現在の状態に対応する行番号を計算\n",
    "        s0 = to_state_index(obsrv, bins)\n",
    "\n",
    "        # ε-greedy法による行動選択\n",
    "        if np.random.uniform(0.0, 1.0) < epsilon:\n",
    "            a = env.action_space.sample()\n",
    "        else:\n",
    "            a = np.argmax(q_table[s0, :])\n",
    "\n",
    "        # 状態の更新\n",
    "        obsrv, reward, done, _, _ = env.step(a)\n",
    "\n",
    "        # 新たな状態に対する行番号を計算\n",
    "        s1 = to_state_index(obsrv, bins)\n",
    "\n",
    "        # Qテーブルの更新\n",
    "        q0 = q_table[s0, a]\n",
    "        best_q1 = np.max(q_table[s1, :])\n",
    "        q_table[s0, a] = (1.0 - alpha) * q0 + alpha * (reward + gamma * best_q1)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # epsilonの更新\n",
    "    epsilon *= e_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "学習が終了したら、実行フェーズにおいては、常にQテーブルに基づいて最適な行動を取ることとする。\n",
    "\n",
    "状態の画像を保存しつつ、学習結果に基づいて行動をするコードは以下の通りである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "obsrv, _ = env.reset()\n",
    "while True:\n",
    "    img = env.render()\n",
    "    frames.append(img)\n",
    "\n",
    "    # 最もQ値の高い行動を選択\n",
    "    s0 = to_state_index(obsrv, bins)\n",
    "    a = np.argmax(q_table[s0, :])\n",
    "\n",
    "    obsrv, reward, done, _, _ = env.step(a)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAALmltZGF0AAACrwYF//+r\n",
       "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzEwOCAzMWUxOWY5IC0gSC4yNjQvTVBF\n",
       "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMyAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
       "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
       "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
       "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
       "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTE1\n",
       "IGxvb2thaGVhZF90aHJlYWRzPTIgc2xpY2VkX3RocmVhZHM9MCBucj0wIGRlY2ltYXRlPTEgaW50\n",
       "ZXJsYWNlZD0wIGJsdXJheV9jb21wYXQ9MCBjb25zdHJhaW5lZF9pbnRyYT0wIGJmcmFtZXM9MyBi\n",
       "X3B5cmFtaWQ9MiBiX2FkYXB0PTEgYl9iaWFzPTAgZGlyZWN0PTEgd2VpZ2h0Yj0xIG9wZW5fZ29w\n",
       "PTAgd2VpZ2h0cD0yIGtleWludD0yNTAga2V5aW50X21pbj0xMCBzY2VuZWN1dD00MCBpbnRyYV9y\n",
       "ZWZyZXNoPTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0w\n",
       "LjYwIHFwbWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAA\n",
       "BQ1liIQAO//+906/AptFl2oDklcK9yHrOuLcX/hC+FSuAAADAAADAAADADB2N9dUvGtnWaAAAAvY\n",
       "AjYN4Pvgdr3AVJGHpzxDAiOR9jP+Ew3E/5z5GRYomC/pElRpHtZh0c3ugpw6ICcoW3pMn9x8k/Bc\n",
       "O/8paMvYaFDHlUHRL9mWryDDKGsyAI3PwKbSq+vP/kdf1Bvez4t2/C9XQas6ji+wKMcFR6BCu3Tx\n",
       "VTT6b+XmRPiiOJCu2n/qp3XjLQW98F8NyJDFMYMGQv2/jBnVbM3cy1ootZ2AC57ifMsrNU2oCuVO\n",
       "A+QopJtrj8j78OfZbHDf4byf5+/ivYeMs1LnBByKUA1kk1LF6F9xHI8F0X81l05xALq/9wMVam9y\n",
       "zKV5poczVczjrGuQXWMvZk1H1pWBGcqrNRfY7t212S7PMlMCJzSRMZUSKUUqtFviIDBskm0O86WL\n",
       "Dw9YUfLGEfu8aAd6z/57d3tp9EgOYuVYJTDjrNWZsbUUfEjhHoAIm5GacBkDBmFKoIRYu18oEPj+\n",
       "yulhpNzD3+RPqTtUgDHHYQQxX5m7AV4ADdHDMyvfP2ojvoxk8Z0eA8DQfJIO9Aid19pOwfRH9KoQ\n",
       "4SjG4/kGZvNizLe2yxcy3Lus8Xg1wtaSKrrY7zEgzC4qQDKzJ70ZjSVJSY6DIYQlpT+ovzlxlDw9\n",
       "bIApbSc04A9WnQaPJ4mI2FpfD0Tm7M2Y/vmY3ySQVT3QZhelH90a591Q0iTg4yBkCnSSZXVgavmo\n",
       "maSU0p8l3yVQ95yKXJhIwL1j5Yn1tucyss8c+leualY9Ql6J3PN2Ws/zsO4vQne1wGIhE/Vs2bkP\n",
       "K6Yg2xXJWXGH56IlmdiPpkIB84AANXZT4x4qt2QALkJaLMNMWYeNbXvBAoa8Ewlcz/1imqG/E9Fn\n",
       "eosqySPphTDpjMLsW4Bkw4ysLOHfINNNE6+RHFul/AlcGPGYkxoj1DNn4ZrzAFusJT/uzQX/fniR\n",
       "VUgwu0ARnVJ4QIMfLMp97EtVhlEiEKvYnHo90Axy/sg5DIXL64gaICjDP+YTxRsLwtej4I8pZXlc\n",
       "sHnaLJCOHHhJ9G4zEljbw19xWfeUN4AFuXd6djj0O4M+AW87l+EWIGuKqSdkAAtk4TCQhjVxlkF3\n",
       "YWY9MBOv7idFCpOB9+axoOm51SCsloB2dgGAKIBbztswmyNDGzA5oxv9EWr3VAIkQYaBvPnj9/oi\n",
       "4zxfax0bMs5aJ5xCBibODPa5v2BwO+PDniSk1nBmoCSFOo2ExVkwb9Fqw2OSJMtmy91pza5COIzS\n",
       "8ukCN/WHFnl4XbncuR2so+HOQS0gQHAY6kYWc2UY3s+EKKriBBBV1d6Cv1BkYFTwz2xYUGiBC3v5\n",
       "FNW0FMuF2lw5BL0012lImBmS8flWEB6NKOB4SFlgulZArIv9jN7RhX4gk846HGeUX79whl16Ag8z\n",
       "Ae5YPlnwp28bvNTC/z89P5/gPBYygNAhMArx+EMpLlIbWbESxQlbvGFpfjOI6Xpxcd8APvfYlE78\n",
       "8we6oDhvxYdBV/91qrglyayyWFCUl9Ml+OocWn636dPVBlBghLHQrcwcB1+YoAAM1VbH7eAahnD2\n",
       "tpS1xOtX/x4784KfEa8l10Xu0oB/0Ia1lIa/mQoVyJtu61kbBZ224BrDh3gEk43qtRwOyB9MnyQj\n",
       "n1gfROEVj6j9pDJrpeyD7jx02q37HDVMQAAMsAAAAwAAAwAAAwAAB3UAAAEoQZokbEO//qmWAATh\n",
       "dnoBm/CVIeqO1Bf0/hSnfjxHrPg2vnnnsU5qqvQBdYhEI6jvFAtKfMXUkwqwCILbi3RmozbYZ4i5\n",
       "cH0fi9440Ofec8SkHM0F1Ga+bgO2i0xcbn6CjWLRLwsrQRD7fDNWlNXdcP6Zzx5KEXQgIhn4ZuCB\n",
       "/Bd9v4oEOwg9tQOj2Zvyi46vjDIlwTczhtw230IWMDfY25YB9/knqXFOZXiRBV9u0wvVscqVBc1f\n",
       "S7W1OCe5R17hRqHMlsGrJkpFn4Jn0b8C0XDhxuH4V9cgzrVmIYp4kcC095lVekfuLYjH7TxSa2sU\n",
       "6fPYVm0DKf5RJlcyUn/yXK8FBzE+LQnpUT/4AtP7N9lChhgTvUrG/tkBiZF00ff7hUwH6CI3tZgA\n",
       "AAB3QZ5CeId/AAJw5V3KMh0AHks6y9aWZ7k9xmX+HYNKmM3mhQH2D9hJ6oo8IcVQ1ws6FrWibjp9\n",
       "1/prJpLFpmVUtYhqEh8TRnDVsbeXSfyXsMo/OgOlFJLb6bRdZ52CqDIYBEzC0dWsR2hUyrhb3npH\n",
       "bc0Zto5oBO0AAABmAZ5hdEN/AAN0KnkGlcAJpqsxppCnlCOAAaXHwNbWU8+uIJAgOoGPszE/zYY8\n",
       "ClvRpJmbhcVsrGTiIg1eNrbk0rWkSoxQq5JTBeOwa/9albHUSZVuyFU6CWo+Z2amgow4pSsKKCqg\n",
       "AAAAawGeY2pDfwADOKdyQAbF8s9kehJ76NrH9Mrq4s56OGkWF7kCbapVzon5Qv9kL7syaJvWRWyO\n",
       "LbjDCc2jNJknSSN8jShCfQiWd5vQWVwWGKz3+hfBWiJfQci1QqH0IoweiGCqWPcRPd5pcFBBAAAA\n",
       "/kGaaEmoQWiZTAgj//61KoAAlGcgyuAG45vb7YkBTFwuFmfWjdLKFf/MzoqF/06np+1yUpIIIWDb\n",
       "BMWh9f7AKnn8X58FjoAWLFbaRFg3taanKoMufGXxj1pgXcXpBB/72yaBBPYRFAIT7LEme/Es6ca1\n",
       "9FdPDE/9sYigiZH0wQusDedi0/X8lINzageg4pirLBSdxrOoAR3jnWfJNeXYpYwbccbIdPj9WJ1N\n",
       "5tp89tSOUY02soEszek6Z6ivpAL6ikm26oqIp0hmxA6Rb+7pwy1ZF5eJaddkPhx0LEDOIO/P2SkR\n",
       "lqeiPCwQyhq89dSrx15UpZbObGxgeVv6FUTRAAAAlUGehkURLDv/AAI6aJbEADVg7Qc+dFl7zaGU\n",
       "3W1f4MD6dbAtE9EfbvexpVQUairVl0cpa7kszxGQ1uj1lh2uvec2LAyyNi3moAIIoZ4ofExuVTY3\n",
       "tILaU3/rEwpqKrhahqLhne63/7gI3MvNoYXOOxTZJZM/QSwvgXVY6TgDkrv9nbOUxGImpOnzx5Pi\n",
       "epli5RW6nxTRAAAAVgGepXRDfwADN5Yb3ACBkhZsr+KHi8AtU4C1raLQIOdei8a/PsRH9LPti6uL\n",
       "7U5xu9bDRNTpDGZVX+eAN/kaaYEtR86jT+d5c66FVGL0Q41rvLIZJ6D/AAAAYQGep2pDfwADOAW5\n",
       "ACE6G4x6gByBwqZ72T0JYdKCwqygS5CdGV+NgH0QujcCwCQodqAcxHX0scL6cfs7cPKaCx0ysCxL\n",
       "3qLFgoKM0m2ROJp+KlpMfWy8gLIBmT//7QQ+hWwAAAFWQZqsSahBbJlMCCH//qpVAAEoWgWoAgUN\n",
       "vmR/GaOxqpCN75/msEq1vwMOEGOrIMev3llQCkUa7Mk3oAwjuRZUHb8NrHK7/hphRQqtB+AS65ki\n",
       "mYvJ+1L+8Pgy7YYMg3Km0HoeNoipcnq6XF8yqTdrcmY/Qjx5nQj3mI+xhoMkEQladKLvzSs9xC5k\n",
       "ricjwPLsCSqfIliFxj+9pv1YfS3jrNo6iIbA2qbdJ5ptjDNz9GvEpnRuaz2P6yomalhGQ+7Ih/QT\n",
       "bGfqbx0Xh4vD+BY43w3LFH8IyiePDX5k+exYAsWxSsOas+MDBaM6KeemDSLUflRec8CG6Mvh1Ww/\n",
       "AfIAzWchJiWGXNAHfRfels3eJpjaNndUaVbKU7C+DZKkAusLwdE56ll1oAXxUrl/cmqV1MhBn8lK\n",
       "loGt0aLnw/JyCJVfXS7kF7bW+vy4Bu8q/LNY869YHJs8AAAATUGeykUVLDv/AAJA41N2WDgAmJyK\n",
       "4vghlB7AAySLSGcE1pai9g/O2UR1Ja3meoAB8yg739LQXpDYAJa6Bm9jOZbXFNFC7uShIWn61IP9\n",
       "AAAAUgGe6XRDfwADN9VvSEgA98+BFERb0P3p08FC2pmAusYQb9AhiolfjwKo9tNodJ6zsCx2mkrr\n",
       "hHC8Hru5s2YsuqqbMEeM018v3nAAalS/9pzqMqAAAABgAZ7rakN/AAMi9/LyAE1e3xbuqlDZ36q4\n",
       "6PpDlkMLDRr9bGEyfryqGDQUFIQgHVpbX4IvSXR/0edz7KJ8sqccXMQg4e82jdJFyQEV2G8YEakd\n",
       "S/xSDDcOAyQU71ktFGLAAAABVUGa8EmoQWyZTAh///6plgAEY15F5TsAHxipVOoe3RVv5tbBkQUJ\n",
       "ijss0uIJ14SySj8RqGEBFxKYw2Kh1+otODEjRBRH/jZJVYFok91cbJ3euioPibPTmY9mqHVegLIr\n",
       "ydp+IProCIfxFU6YKtDJMj7d5zYOvCU0MOTpEcrz0uy0VnEyPEKJZQWlv6F4TackIH4LB+qUSIRx\n",
       "lNbNB3h/RY8GakGM+MoiPtG6LChEEQVBQpM1nbQNiS+y1B1lvEXEieNZX/lnrC8Bdl5nasuzQTHD\n",
       "FEoWK0PBtzFRa7YeVrw9TzxoTgaB+Q5kt+5SXKT3cX1PSCq8t5ZKk3XAf+fpt20hSLbRtQhrLSU3\n",
       "nXPOKN79ZubMEfOrdqO8CiFvrYDYT862CEtqgkDr/RakLNknR9WXWsFg1xrEmQdTnZUIH3HTJAuE\n",
       "lsTZlbabmhFh6KIEsSAOsxRjAAAAbkGfDkUVLDv/AAIyfMAEncUav3+K707odiNvjVXDbeOW0K08\n",
       "ImTQMWdO57fPHnyidoIDDg7CGLQ4Ic57LXrJQO4fgdULVkgZGWKkofjOGbxDUrn3qMQ2+R/D7XHq\n",
       "3as3mtLEMzurjqV6KtbMUgP9AAAAdAGfLXRDfwADHHX4daPC38AJVGXdLQ1UT7/0Ueyta6IM7tdG\n",
       "8fjqR2UrS5nUKF2+3ohE8P0rRWdQZDvdp4Ws8vdSSUyI3Rb8eAmMKHiO+huRe1M4jZa9kiGycUs+\n",
       "Biwmrqom0LdHEH+lT/IdfYKGBXDKvFNBAAAAVwGfL2pDfwADJD19QAE5FF2RflylJLsvwMMPPbyH\n",
       "0mjMH8T/adZURtb6QnqvB0ZlnfHZZH3ro0p0kivb5+2YlZsCiTcZAiszEnCRFhdvXjZ+6GnXVYDa\n",
       "gAAAANJBmzJJqEFsmUwUTDv//qmWAARkE+SY4wASyL1ldUGeay0a84/KYB4lTRApPKaNSIhWoVx/\n",
       "eUjD2HTh5W43FYA+j06x23y24rwnqKRHZeuRULoY5Q7eYDkAGlTdTV2NUcAg46+wDY/XWkBSf5Sy\n",
       "ncfSZ66vQ++sKc7JqbtSXI9WcD48dfiQcPk/w+eN4ufcPz9lfKciRxvarivU9ick6yq+zlA73sXY\n",
       "mi20qusz6QUOGoxYCC6/mJ3rqKBmDixyBz+mhFjYJyy7kY9lbEjsOitkLiAAAABVAZ9RakN/AAMe\n",
       "arb4mhIASnpjlxWOCRdgqNhQPaseAi6U3jgldaf6kEXpenS9hvjKGtga5xm6mOsOCiGkZPHwyE7N\n",
       "GQ47syegAXgzeztvLNIqRAGxhQAAAcNBm1ZJ4QpSZTAh3/6plgAEgBMCXUiqANCAEsuk0ogVRX8r\n",
       "0V2bF4gaZWE+M1cEv6yJHoJYR7kFUtPJW8Jo2flzswuqvJlyZ+s67F01phxCFDNdru49v4xqnFIG\n",
       "quJxLXxRnurB12PNeEWto8I7VYav5hmdi1pd5s8Yb4NHMBqvli2cIYx/bFcJFl69ncobs+kN3Pxf\n",
       "xtpI9SHk2cjXRsZedZzc3j0CS4ov6hqOG2F6+h/9WcO/OTVrcEImfc2ksbu99NSFUSjFXf24tps8\n",
       "+aq/lQK0BcP83U43za6OdA4rkJe6oYxhgcgCUsmf8/QCR50mRrEEzqt5povyCJPrjTPb1zBYIFVe\n",
       "VA3pKBIzPI1U/fCKfb/Sd+CL33qZAMUnFnPBNs4uuno8X0hnhwqTkmr25BGtNqrHM3L/Bp7Huz60\n",
       "RM7CP24wr3v7KE6ZtlNl4YPz6m+9fIlpY3HDKzw6uVMN0kv8IMKARkD10KVaK8X/6g2J3HqGcZ/o\n",
       "s77QoBnbtPsd47y+7HplHUMUaKjzChEXp7AagCGTH6smtwfXVybRF1iaz+mUsDQ9Wkqb86NIuSdB\n",
       "qVtjjNNFNFY/F8lM9R51OaGsAAAAlUGfdEU0TDv/AAJA5HqlDILwQhwAZrkXfajNZx1Iy9vMd+RR\n",
       "Vp0XwkaFeD4aHQD7DRDyfbnzEMEJZ87d1mEKi6yrl0yGShZeqgl3ZToBj/orK2GMFkkMPa1vytZx\n",
       "AUE7oRPnWE6396K4ouKXv1hi3+o5WLrGqDPjKKPpbwUZbg0+OEzE9CtWQA3kn/xaDe/uUPoTcB/g\n",
       "AAAAXQGfk3RDfwADN9OdQSQAeGkXum3F84obOHNP5mA9hzDgHJvedYrWMzI+qlaUg6HEUCkoYbtE\n",
       "IEN7irg8w2mpukTztroofA7VP434qD0POQ32RO4rKKZGHd8b5yxXwQAAAGUBn5VqQ38AAxoQSejB\n",
       "UABO3u8BIG2F+vQ7Ys9U2Xh5O5Ez5zMuf+uHOqYqsBbNqBH43/Lv2QqoN3UnXQ9x6Wwq8c7HDAXz\n",
       "OvhGZbLWg5fn8GcKxN9SX2TWf5DrKhgXy66eYf444AAAAT9Bm5pJqEFomUwId//+qZYABGNeReYj\n",
       "ACTkdUDR39qu5X3MhNUIblk9haOA8iiRTNDFA+ueIlS2DnVezI7LwPgm4OT0edawIsGmoTs9V4g+\n",
       "yBLNO3/mKBl85bKLab8WSHUwFfaXP2IAgA2MRkyS5Il+XLvw3SQaCLli3lwDLq54i8C2W1JXLmMV\n",
       "S2iwtp16ETADpgcztWzR17+A6qn89EBAdBOPja0wVqCZwLu5UHDynTM3ow1AkkZhhtstruFZTQYw\n",
       "jQFtquZ/E919i9cKYMFTOb6GuiNn/Qq2eHt+Nu3C5gVfefV6oq+Qk/ar/7UCLlMFUUWnI24n8tSu\n",
       "6SK4mBACijd40x9t4ZVcGdtQrNUX5+enXlj8MFwaf7Mfu/RFkVHLgTzQoo8ZRRx1jKAVtNfUFrVp\n",
       "i8NDFnHnt0eO2leBAAAAckGfuEURLDv/AAIpecdwSzDACYR3KUGemWBW51ypz4UHOPj6WQMTPjcv\n",
       "XCPmUybUppo5OoguamvBwOV6ALmSOovWcOz0RU8z2Q+D6sAMoOHyvWnLASDVD5DrobINEbzkWeuG\n",
       "KfunZ+HFTWdQTIGHW+UXcQAAAG0Bn9d0Q38AAySMeQAmU+l4rbZ0pluNk6Qr/9B6pLwjbHRYOh7u\n",
       "poZ3QdigyqFtu39cepSIoc0vVzSyO930GQyc2md6iLEZBiYuHBLIE18nx8A3csKOPT7BRcCwD1kA\n",
       "ZxC36qYTT4X5HWw3Ewf4AAAAVwGf2WpDfwADJD19QAE0HGdXoGtM8hWpRmLQgRRL5AXLZLDY62fQ\n",
       "n6GdZTqCgLNsW1hGGVH0XWxSUR8VL5VzKiOxdckaKpFeCABLZmJsUYXTmm1JKsUH+QAAAatBm95J\n",
       "qEFsmUwId//+qZYABIDaagDYx1W0B/hgjaJ96VpjzfBS+zahHa/I5WdCKwJUA5VP+tExWc6OkoYx\n",
       "qdV0tDmEavzTbGE7f3a59GWV3MYqf6H9+cDmYt5TcXenY/3WEv/0eF4ZVrULM9h0kfkGJy1ybgNs\n",
       "CAQHDF+0ytj+GbRw+Ndijk5CovcFr7OkRXa6tBOh+X91zzuOWDFKsk4cL6lVwJ9e9Ob877LLEM/O\n",
       "F0thzH5yHpPmJN4VAgpX61RFMp6ZMrqTQPfqCjPhKAh8pWLVoYICChtkCcfwg8bPOPjbBP1FvZIa\n",
       "5nw1ZH9lTeAPyshiVZNjc/lnbrK6I0ZcbRBhlx81yJ7OSHYIk4uPF5gam03WtefnoaiHu1NIYD83\n",
       "5ZrBatwhWJXUqEc6gEvjxpRr6MHxxMnb+TzQdyJTZ83SYGskLQDpajWOz9kAxy1cix9v5YAKHQRE\n",
       "HdgfUPCKQTzhbpf0ZrZy0IwYQBVIuHcVUTRDJR69i8aifoLLsKo/pSNR70EmDpcNg9fxciflT+Yb\n",
       "lCQUt6co1SGdG8MP64pkYEjxUATHxh3QAAAAkkGf/EUVLDv/AAJBHxRvWQBNpAB+PdJwBQBiGy4m\n",
       "JMeFSe4P2tL+0emPu4O8lizgiiPEhCrYC7pev0SVRM59YMUH+S8dDrcA4QfxGfXLC0kkNPxsfqNh\n",
       "VeGwV7dwyaPz6Vxd7ldfIm9HcmYFSkfYd90LxMmMMFQnhk6UfqeThgAczybx1Fw3FJCDiETk1gWL\n",
       "Y4kZAAAAYwGeG3RDfwADHcvBJZ/wAeBCfjdScAPDhxsl2dCCUbbVeMEQMIJFj98ZzUs36QuCMIpk\n",
       "tQnJroNx1COdXEU/44bbzU3wUjrId3N7E5FhN++kGcPQbdjvdn7scABF5jJ3qA8B/wAAAH0Bnh1q\n",
       "Q38AAzgAV1FuSADyetijllV9/Oi13jb0PRe/PrHhXmCWHIw9O7JZINuppGx4H97l7BCUi1JTuwxF\n",
       "oT5olF4RGiSTaBFCzCPzHPPecLoSgf0csv4gXd09R7onE1xbIB25uD3xW8m6miXp+9WJJqRaHTN4\n",
       "cOaS3qROwAAAASZBmgJJqEFsmUwId//+qZYABGAV6z/5AwAV60HG1KRavMTYOv+YSo2IgbvSrOHK\n",
       "r1NDnhCFWFAwKei5xlaU82DKG5smJ1ezRpM1BmfYpV9e1r/b90LNdy/K95xSyAdHYPiSociX7gc5\n",
       "daI0zSsD80hc+3Hgx6Nkd5E18XHcPNtDp81eahpv2z51RjhqSpKrDIcOvRiCHoFubcTjZgCql6It\n",
       "OX0ZzT3WCLXm3/LL5l740kqVTm+uxezYWSWm06Kr0zsnZ732Sp9WZ3yeRHbUauU+BQ+pbRLi+1/T\n",
       "IlH2s8qkoSP/div8Y4Wu6I6TuaondvBxiX53K4xKMMNHtv4i/n34ZE7EbdsrPnKzig3zA+u9bjb8\n",
       "gveV34xEbK/j2YymVMBNi+CLJUAAAACCQZ4gRRUsO/8AAi3OMzBvKAEXAXUTZpsHhGel2hlSJFno\n",
       "8BWuMHDtc2Nc052L+R6Iw68HHlwYuY4MR3P6cjy0QKXC74V3U2H/TMqDyzCKX7BhJ5F/IWeFNqZh\n",
       "KlJMeL5EUsed1jJGkhF7gMLh1r8yDDr+ddAA4XnpLDwXmOHwMVSD/QAAAFwBnl90Q38AAyLkTsfA\n",
       "ATt7e6TB8vkDgu1/m+4N0Hx4MSQdxL02bwgYwx/kGnzBGQ4LBiFf7216fEXMXXR9umkLjjwh+Ef1\n",
       "OngzZICO5Sfat5ilkFFiTgnoUF4JeAAAAG4BnkFqQ38AAxn7WLCIl3IAS5QAHX2j7QLLUHJm3nUb\n",
       "siWYfHk04HxkfvZGc56erIy8l+AR5OrwaUrKxyKLfJq6V+U0BSdTF4Wg/tj1sqdBL3JDP81O7xDa\n",
       "KZUyii5Tzz5sJZhoM9zQRLUANuidgQAAAU1BmkZJqEFsmUwId//+qZYABGFXhQAcFMG3bHRXh+b/\n",
       "PCaItYBXt66MVWjOPiQfIDlVJgwMoUKNnwjay488Cizz8vOVbynSMMLjKr433BHWTC4FX3P/54vs\n",
       "CrrO8rSF0ElQ3x+aRdv6HtjY5jMPKw4n0Pn0eGWgD8fEWhc6n+lffGoweU+mDBvW0iL0Z6a4a/LD\n",
       "C3GN0FxB2FvNyymFGQXihx8SVTw9mahi8OsTxxOoW7DXju0DXM3+CPFZB5EnYLDOKKYuAh13KgJL\n",
       "4fHQi7q8Rl/IPOIfMKUerGbU8GK2itdYYJuQldaK1gn4KYerXVtrapT2VRBBsmDWrKFi+jaxViz5\n",
       "DDLyN5brKVNYNBh8TRMNFHb8PI9F9vI+iqmJ0p1grxhwfGoVoKuWm4BTma3r3zNYYKTdlCkE08Jp\n",
       "V8X/paCSge8dMWBdlsCjGcAAAAB/QZ5kRRUsO/8AAjJ8wANXTSJX5QFhBv46CTzlzJc7XiS0r+sR\n",
       "WG3d6i5YFcPsJH4AMbYk8BTjbIb+nZ/5SC/uQC1rzbcRnnT8NB+4MnmHT4EV4hrM2T9BrVMTGCUB\n",
       "tThKsm/Aw9Mub4zD7xd1cK/AnORZ/vlcuWsjJVkeeGGA/wAAAGwBnoN0Q38AAyOXXucAJmIpi1D6\n",
       "jtwf6empxvr+V/R47NJ+4IOcBodq/iI4D//+5/EQdYJSMm7GO4sDIS2iN0DBARHziGuSWsebhXKA\n",
       "NKegee/kHOHeNllrLLGXVXdGjH05CzdNu4QIlklgUXcAAABdAZ6FakN/AAMearb4mhIAS4EUK0aY\n",
       "56h2ELghK8F+eUqZH1ieYiw+pcANwiTkg2lS2JEYfWyM+4oyxbLD8+/jgLhWUhA3oKtKYtwgZFGV\n",
       "w6N+0GEGUqsHKNbg8Am5AAABPUGaikmoQWyZTAh3//6plgAEgNrsACbjKCU4yDsr75ylNorZKod5\n",
       "T4Fdr7Dq7zvgYgawg/JsSuqRR9IolsshH9Hmr0Q9AS4ptCgn9sHH38TykXrhGLo73+gQpw9d84O8\n",
       "2VtJA+L8yoJ+3FLTOQ4ENVHFPhGF5aKrZrX4IBvNEgHpPC2XvhFtOLOVnLuJBH3KuBmcrGN8EDU4\n",
       "teR593Rn+xGd1sbmkDfwEOKexX/+ZghzMCacqny8UvNJafU6oLwwo+ZCviKk0jL1A37eT0uA3uqh\n",
       "hkJyWI5thPYP46SVmzQYZJJ3DjQJGllEs19vAeDKgKD+aEqva5J3e6S1OeYkv61oZPwD64igGm1k\n",
       "jrqxm6VNcUg5LI2nSnQ3LRqyMDRubPS8bQG8PE0ga+EgIZzPfWMpUe7eoEz7ICQDPQf5AAAAeEGe\n",
       "qEUVLDv/AAJA40KWVi7FCOgAhJlbC6T/t3XUwdh0W+yLNjgWJbQ6NHJwfl0YdLDn4z6flagMXhJ4\n",
       "+r6GSB1s2bbfHY5J5HbwIoJFXRUPm3FlZGzC3cKaDefqob0uEfHTvRMH2MvaDgMhK4D3eM9Zfcw9\n",
       "cIijFgAAAGUBnsd0Q38AAzgp55PySADusoTll9oEKlaYtUPHWazK5CaSdPEX5rTP6o/8y8QGsg5d\n",
       "bVb2+j8gensYyBsswrJ2R8FJWKQyUU34wCWyiJfadLJ/vOrTNIDgHrPvR1lSh0aJ0IBZQAAAAF0B\n",
       "nslqQ38AAyC9d544ATV7e6TB8vkDgpBcDyfdWEOdUwTaTicQ52MujsoGoCDZ0vHPsZEWhnd2Yns1\n",
       "nJvxikDg0d2XeIbQ2cfIwvVRUc8hHlQwa0o7zQT11y56kYsAAAEOQZrOSahBbJlMCHf//qmWAARn\n",
       "lf1MFPCwhACSP0eQ0P/VgHPf9/EQ19PoOgpGE22jx6EXG8WvduIMfpIlszTew37L9ZjliAVQdeEa\n",
       "dV1PAy9jMyL4IPnpVAnDX2LNkQGptURLpShVjaMCBtGkLnoJ3IhmeOC9PXKNG6TJ7Hw7BOdc6HQb\n",
       "/sgqtV7Qq+hwtRggx0wP5FoH/45yxSevcxD1hPfh/WAJMz6+5MBqno1lQiqugLNnohivphL/Wpfz\n",
       "9hj544JgWusQBOAUvY04Rj4gbzW+Ldv6oieV6EhBYSzE9Cmzpw4LXr3oece+ZwwqFOmtQFKEc0Oz\n",
       "JI+l9ww6MV0W87kXAKqCuy3J79OmAEbAAAAAekGe7EUVLDv/AAIpi7RU2BgBZroav392TXn7L1g7\n",
       "ZS/C2oALFKBO8lgbmS+PMa3+OP4rPll7nrIYkL4W3+5Z+dqLvEJ6YyfYqmgilppzqKdnXh5dFw/E\n",
       "L3fLXNYUmUQZ/0Al9qyGCcU4CyaDI/kqbRMuLE8RWQz0YFtAAAAAfgGfC3RDfwADJlrgBMqB3aya\n",
       "Kky9Uu+V5ZQgyD5zVT7Z9zZxAtcfNwmUTEeZbc639WbpTFY7OKnMnzCH8CSMv7Y+WyxjnphtEu5j\n",
       "mm+0rxCCCCGkwDV46OxAYkZwzJEVMkOBtDsSOnb8m7QBLXlSTs1rm3BBO/XslpI4LSAGzQAAAGoB\n",
       "nw1qQ38AAyQ9fUABLQbmnph3Fvrg8hxAhZjMV7mfTLwbLdVaFUIvMyeWz1z+04QFqFR9Im9+7vV5\n",
       "Uok+SWJNJC5TuYZ7yFSOIalSk5JSzUkwp9f6im8/ov6VkY3MXjuY7IUD0dV3wE3BAAABsUGbEkmo\n",
       "QWyZTAgh//6qVQABKECPUAM2F+ZicSjHzD4oEL1d4269NA5PUlMGKe0bKpXxHLjIn4aQl/L8f/Hj\n",
       "FfMJv8R/4xjyfeMr9BiPkTo0RgW7cfRN/wLniEC0KMDJiWc4o8JEaLnq7SVpYBAyTCusdP6Mz/6p\n",
       "wf11a/VqtcXzP2geW9mUOk6A4t6Jx/GmhPbREf1QzZUyI9mexPyYQjyWtVPshzbySwKNr21yN076\n",
       "F/ezRBGpz6tzbCIrkiVU5x0ARiYhOGzBUsjuPLcnkDZpeAxF4mQiwigKT2kF4G0d9e+mEoIEwmRH\n",
       "ccLtsKCMPiuPNH3xrDw5xPwAyLc7+JOfclNz2zw9/ScOrz3mB+dqg26bwX2vTOUVSgXX++iMqNX3\n",
       "yUbipQAEnxH5ng43DVZ4mqK/GPj6cr4xSJbUZVPP+/9PSyeRKC1Zebog7km2wC7AZnlJZnibdgc8\n",
       "dFr5umRu+mwdUE+N4LSxiMFyJYjNrwNvpexGLjImmlIMwxGVS2/u00zI1HdG8aFlvnzO8j1fJm/W\n",
       "F/mv2ycZ7aWht5Ho2+3940y5hig7n6O6Dk9zx/MAAACoQZ8wRRUsO/8AAkEfvIxm0SQAlkW/qoKt\n",
       "POPDNecTx8q4PfsRgGmSQ9AiLMQr0LsTe4IvNo2cPZxceQEpMq6WTiNDtp7wMg9ozd/p8KvlZO/z\n",
       "m8FRABk8MBECrOlxTndLLHcKvskJPRSDG12ZzPA5hVagPIdCvN5+mCxsn3ZKoZY8c6gaegIHoxWa\n",
       "/6b2eT2DRAqoMR5XastRMawMgMrM33+1tXnD4gP8AAAAdgGfT3RDfwADIt5e1n/AB8U15Gak8lBS\n",
       "qR/SRevVlnERVpTXQMUJsRMaY6yZ51g6nfvnMtmoCMzxNNX4R8VhAZLcTthBkS+XL3/wzBvSZvHJ\n",
       "huOaxT2d/tlTuoaMgmE68GHPZzHoBE465t8CLGhgpaGlGU7OB/gAAACMAZ9RakN/AAM4AMB8kAJc\n",
       "luvzskn0459SyhVwHqWgWHqDukeV9yh38bUA6lnNNTYwZINmhTcMaCTiZXCHXyJRBbTbr2ePotXh\n",
       "LFkhTT6Sg08ZQ84E2X/WbKyd7KQfS4RlhpHSKdaBFPHtdIPoCZ5CvjbVJsLhsqhcKjLYE5vh3Gjg\n",
       "kE8TD8iGWaqgP8EAAADmQZtWSahBbJlMCHf//qmWAASA2moARla2D1cRt/ckq91fJEYsm/DnH0oV\n",
       "GYXDoED/DJ9UdPjNMfcG5GWb7JKXWIcSWXsHU+zWmDLAVH+/rNJ2cvFa7Q3fA2AtEJPlyb00l9Ee\n",
       "kyv0CXHymK23oqhpD+ngz3/v2f+8N4xDxW69y1sb19ES3Cd9V88TVi0qaMXcnKliA4f6BUpCNDjc\n",
       "5KdEV0jfv8uD32fLLYNBKVyqXxso0aT0BJ2ePP0dlAL3OB41UgMUjJzHl1qXDoevj06NHPjLEckV\n",
       "gkv2lXFbOGaR7cqU1Otv90AAAACtQZ90RRUsO/8AAkDjQzZigroALk4KBdckHyIl1F+/o5o7MooF\n",
       "EZEbBNivFV+Mku2/EO8EjVMUHLICGDw9pk4KVhcxroLGZl3Jp6MZ6/onfLUEg6kjSGD+qHFfWJW+\n",
       "l07bdctpSc5TTp4m0BlOvzJP2xQTgZqnPJWVYpYTOyP0n96FqeaAMqX1pF1uw5wzAIuvhqd3vlB3\n",
       "CseI48zyki6sA40q0G2GNcUGhz4UXcAAAAByAZ+TdEN/AAMi5E7HwAE7e3+TwM66B0T8aVe2vgd1\n",
       "cfS2GiOJx7RRYilMJl8u/dtclZ7D3dI5v3RQf9kSSiSGQRxFgOU4W1H57xFcUPhpqPNTUmkVtpYA\n",
       "dbza9rKxTxVV4b0TwEB9Hrkxd2QhlJP5IDUhAAAAhQGflWpDfwADI1PPO3IASyQPJgDR+T5SypLx\n",
       "+MYwD0ue3qoE48gGdgIPDCICNeS2fBsb3kULfn6+UpA0pEHgv3/wT+ir6FbIj18IzYqan46kRVzB\n",
       "BXwuBsdQoLDDA/cZ2VQU0q6cQhxbUhc4W0OW0DzVjcWBfcteldL9CGbkUBqs2Z8MAP8AAACgQZua\n",
       "SahBbJlMCG///qeEAAinQzsWJcAJph2OZvxVsD6f/+mN8vpnuv03Du9d3MaLE1Ec/lJEDY+xH6ua\n",
       "4aJh2rQPV4T/qC4UE+3Qfx3w+qSSLdW0S8KHbH0EgaLgzFztt+69wkADPglrnz8kgJAT17ypvWFO\n",
       "RZNOKaQkXlGpUAjZiqFADy448r6cZnLxS4mCRjLODqjSrpxq4aXqGOlX5wAAAMBBn7hFFSw7/wAC\n",
       "MnzAA+KvVAqfhdytVtpzasTeXVWeSRUC60T1HU8d5U5sr+czoIPyssU8O3vAlf6FnItGt36gVT8h\n",
       "TY88wIddM/Ns25oAIYQezB3OPz3C8ml++bbYlOVKS3enAumpHs+M4XbFXjX4a97tImmT7bDmyAYP\n",
       "pJftXhAA7M415+VCTlOs4OXl1NjJoYHV5NfjMfdB65pTP0UpLtK770XmM43Rxzy9PVyL8EmekA1c\n",
       "ZnGSeMrM4K0QD/EAAACEAZ/XdEN/AAMjkW7KAAlE9xGX7MDJ9DJ+WbjjNhqKivJ0BSNJRpK2FCVi\n",
       "VsbeqfCWoQIzh0dA8bQA/t5RbN9rz1uYJAcNAno/MrFggH47TSqhfy6AjMP924jhQm0yolq4YpsY\n",
       "vcyv11sejYjqdwnuLoYpxnvlFiocqTez1wZNvIrSQQVsAAAAjgGf2WpDfwADHlsZwfkAJpmtKHhr\n",
       "JfYGHGsGvZnqI7S/iKRkONzGrMTsaKdkXnWCd0otlBqCPcqMa0vDGqZVfrg/qRAvEVwOo1Xrcz97\n",
       "sD9tSUKOWtdGrB//ZEhSqp92n1ZDM1Ze6CQFP2Fza/y3HFC8k82pv+FXahn1ljgFkR+NUioDHVoC\n",
       "P8twHdhkccEAAAX1bW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAFwwAAQAAAQAAAAAAAAAA\n",
       "AAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAgAABSB0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAFwwAAAAAAAAA\n",
       "AAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAoAAAAHgAAAAAAAk\n",
       "ZWR0cwAAABxlbHN0AAAAAAAAAAEAABcMAAAIAAABAAAAAASYbWRpYQAAACBtZGhkAAAAAAAAAAAA\n",
       "AAAAAAAoAAAA7ABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRs\n",
       "ZXIAAAAEQ21pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAA\n",
       "AAx1cmwgAAAAAQAABANzdGJsAAAAt3N0c2QAAAAAAAAAAQAAAKdhdmMxAAAAAAAAAAEAAAAAAAAA\n",
       "AAAAAAAAAAAAAoAB4ABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAGP//AAAANWF2Y0MBZAAW/+EAGGdkABas2UCgPaEAAAMAAQAAAwAUDxYtlgEABmjr48siwP34\n",
       "+AAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAADsAAAQAAAAA\n",
       "FHN0c3MAAAAAAAAAAQAAAAEAAAHoY3R0cwAAAAAAAAA7AAAAAQAACAAAAAABAAAUAAAAAAEAAAgA\n",
       "AAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAA\n",
       "AAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAA\n",
       "AAEAAAwAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAA\n",
       "AQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAAB\n",
       "AAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEA\n",
       "AAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAA\n",
       "AAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAI\n",
       "AAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAABxzdHNj\n",
       "AAAAAAAAAAEAAAABAAAAOwAAAAEAAAEAc3RzegAAAAAAAAAAAAAAOwAAB8QAAAEsAAAAewAAAGoA\n",
       "AABvAAABAgAAAJkAAABaAAAAZQAAAVoAAABRAAAAVgAAAGQAAAFZAAAAcgAAAHgAAABbAAAA1gAA\n",
       "AFkAAAHHAAAAmQAAAGEAAABpAAABQwAAAHYAAABxAAAAWwAAAa8AAACWAAAAZwAAAIEAAAEqAAAA\n",
       "hgAAAGAAAAByAAABUQAAAIMAAABwAAAAYQAAAUEAAAB8AAAAaQAAAGEAAAESAAAAfgAAAIIAAABu\n",
       "AAABtQAAAKwAAAB6AAAAkAAAAOoAAACxAAAAdgAAAIkAAACkAAAAxAAAAIgAAACSAAAAFHN0Y28A\n",
       "AAAAAAAAAQAAADAAAABhdWR0YQAAAFltZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAA\n",
       "AAAAAAAAAAAAACxpbHN0AAAAJKl0b28AAAAcZGF0YQAAAAEAAAAATGF2ZjYwLjMuMTAw\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# アニメーションの描画\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.set(xticks=[], yticks=[])\n",
    "\n",
    "# 各フレームの描画\n",
    "draw = []\n",
    "for i, f in enumerate(frames):\n",
    "    ims = plt.imshow(f)\n",
    "    txt = plt.text(20, 30, f\"frame #{i+1:d}\")\n",
    "    draw.append([ims, txt])\n",
    "\n",
    "# アニメーションの作成\n",
    "ani = ArtistAnimation(fig, draw, interval=100, blit=True)\n",
    "html = display.HTML(ani.to_html5_video())\n",
    "display.display(html)\n",
    "\n",
    "# Matplotlibのウィンドウを閉じる\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "10000"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "n_episodes"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "glue(\"n_episodes\", n_episodes, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "今回は{glue}`n_episodes`エピソードしか学習を行なっていないが、それでもランダムの時と比較して、かなり長い時間に渡り振子を倒れないようにキープできていることが分かる。\n",
    "\n",
    "エピソードの数を増やしたり、$\\varepsilon$-greedy法以外の方法を用いた場合に、どのように学習結果が変化するかについては、ぜひ自信でコードを修正して試してみてほしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "## 練習問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- CartPole環境において、$\\varepsilon$-greedy法の部分をソフトマックス探索やUCB1値を用いた探索に置き換えて、学習の性能がどのように変化するかを調べよ。\n",
    "- CartPole環境は1フレームごとに報酬として常に1を返してくるが、この値を画面中央にCartがある場合に高い値になるように更新することで、できる限り画面の内側で振子を保つように学習方法を変更せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
