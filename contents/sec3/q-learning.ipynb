{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec:q-learning)=\n",
    "# Q学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで扱った多腕バンディット問題は、取れる行動の種類が少なく、また、問題の状態が変化しない、という特徴があった。しかし、実際の問題は取れるべき行動の種類が多く (場合によっては連続変数)、また、ある時刻で取った行動により、行動を行う対象の状態が変化するのが一般的である。\n",
    "\n",
    "このような状況において用いられる強化学習の手法にQ学習がある。Q学習のQとは行動価値関数を表すQ値のQであり、とある状態$s$ (stateのs)において取った行動$a$ (actionのa)の価値を関数として、$Q(s, a)$のように定義する。\n",
    "\n",
    "このようなQ値を学習する方法はQ学習以外にもSARSA (state-action-reward-state-action)と呼ばれる方法もあるが、本節ではQ学習に絞って説明する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "下準備のコード\n",
    "\"\"\"\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# グラフの設定\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 150\n",
    "sns.set(style=\"white\", palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Q学習の理論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q学習では、時刻$t$における状態$s_t$と、その時に取った行動$a_t$および、その結果得られる報酬$r_t$ (rewardのr)を用いて、行動価値関数$Q$を学習していく。\n",
    "\n",
    "この行動価値関数を考える際に満たすべき性質として、とある状態$s_t$において行動$a_t$を取った結果$s_{t+1}$という状態に遷移するとして、その後、最適な行動をとり続けたときに得られる報酬の期待値と、行動$a_t$によって直接的に得られる報酬との和を行動価値関数$Q$として採用する。\n",
    "\n",
    "これを直接的に式として書き下すと以下のような定式化となる。\n",
    "\n",
    "$$\n",
    "Q(s_{t}, a_{t}) = R(s_{t}, a_{t}) + \\gamma \\max_{a'} Q(s_{t+1}, a')\n",
    "$$\n",
    "\n",
    "この式において$\\gamma$は割引因子(discount factor)と呼ばれる値で、$0 < \\gamma < 1$である。この式を用いて$Q(s_t, a_t)$を報酬関数$r_t = R(s_t, a_t)$だけを用いて書き下すと以下のようになることが分かる。\n",
    "\n",
    "$$\n",
    "Q(s_t, a_t) = r_t + \\gamma r_{t+1} + \\cdots + \\gamma^n r_{t+n} + \\cdots\n",
    "$$\n",
    "\n",
    "従って、各時刻$t$において得られる報酬の影響は時間の経過とともに少なくなり、$Q(s_t, a_t)$を例に取れば、この値は$r_t$の影響を最も強く受けるが、十分大きな$n$に対しては$r_{t + n}$の影響は無視して良いことが分かる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 倒立振子のバランシング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ここでは、単純な問題として倒立振子のバランスを取る問題について考える。倒立振子のシミュレータは[Gymnasium](https://gymnasium.farama.org/)というライブラリから簡単に使用することができる。\n",
    "\n",
    "試しに、倒立振子のゲーム環境である`CartPole-v1`を指定し、`gym.make`関数を用いてゲーム環境`env`を作成してみる。この際、`gym.make`関数の`render_mode`パラメータに`rbg_array`を指定すると、`env.render`関数によって画面の情報をNumPyの配列として得ることができるので、Matplotlibを用いて、初期状態を描画してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# ゲーム環境の作成\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# ゲーム環境のリセット\n",
    "obsrv = env.reset(seed=31415)\n",
    "\n",
    "# 現在の状態をRGB画像として取得する\n",
    "img = env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "ax.set(xticks=[], yticks=[])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "すると、このような台車 (cart)の上に倒立振子 (pole)が取り付けられたものが描画される。\n",
    "\n",
    "倒立振子は、その状態を表すいくつかのパラメータを持っており、それが`reset`関数の戻り値として取得される`obsrv`の中に格納されている。\n",
    "\n",
    "`obsrv`は`tuple`型の変数になっていて、CartPole環境の場合には**第1要素に状態を表す変数が入っている**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.1067048e-05 -3.8479745e-02  3.6217723e-02  3.3740070e-02]\n"
     ]
    }
   ],
   "source": [
    "# 現在の状態変数を確認\n",
    "print(obsrv[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "CartPole環境の場合は、4つの浮動小数が格納されており、先頭から、\n",
    "- 台車の水平位置\n",
    "- 台車の速度\n",
    "- 振子の角度\n",
    "- 振子の角速度\n",
    "をそれぞれ表している。\n",
    "\n",
    "また、それぞれの値が取る範囲は以下のようになっている [[参考URL]](https://gymnasium.farama.org/environments/classic_control/cart_pole/)。\n",
    "\n",
    "|Num|Observation|Min|Max|\n",
    "|---|---|---|---|\n",
    "| 0 | 台車の位置 | -4.8 | +4.8 |\n",
    "| 1 | 台車の速度 | -Inf | +Inf |\n",
    "| 2 | 振子の角度 | -24° | +24° |\n",
    "| 3 | 振子の角速度 | -Inf | +Inf |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "この値は、`env`の`observation_space`フィールドで確認することができる。\n",
    "\n",
    "CartPole環境の場合には`observation_space`は`Box`という型で表されていて、`low`、`high`というフィールドにパラメータの最小値、最大値が格納されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bound: [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "Upper bound: [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lower bound:\", env.observation_space.low)\n",
    "print(\"Upper bound:\", env.observation_space.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Gyminasiumのゲーム環境には、この他にも多数の関数が用意されており、それを強化学習に用いることができる。\n",
    "\n",
    "まずは、その挙動を理解するために、ランダムに行動を選んだ場合にどのような動きになるのかを確認してみよう。\n",
    "\n",
    "ランダムな行動選択には、`env.action_space.sample()`を使うことができる。CartPole環境の場合には`env.action_space.n`に格納されているとおり、取り得る行動は **0: 左に移動**, **1: 右に移動** の2つだけなので、`sample`関数はこのうちの一方をランダムに返してくる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# ランダムに5回行動選択をしてみる\n",
    "for i in range(5):\n",
    "    print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "選んだ行動をとって状態を更新するには`env.step`関数を用いる。`step`関数の引数に行動を表す整数を与えることで状態が更新される。\n",
    "\n",
    "`step`関数もまた`reset`関数と同様に`tuple`型の変数を返してくる。ここには`reset`関数の時よりも多くの情報が含まれていて、\n",
    "\n",
    "- **第1要素:** 現在の状態を表すパラメータ (上記の`obsrv`と同様)\n",
    "- **第3要素:** 行動により直接得られた報酬\n",
    "- **第4要素:** エピソードが終了したかどうか (ゲームオーバーになったかどうか)\n",
    "- **第2要素:** 行動を表すパラメータが範囲外に外れたかどうか (今回は使用しない)\n",
    "- **第5要素:** その他の追加情報 (今回は使用しない)\n",
    "\n",
    "のような構成となっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [-0.00080066 -0.23410185  0.03689252  0.3376265 ]\n",
      "Reward: 1.0\n",
      "Finished?: False\n"
     ]
    }
   ],
   "source": [
    "obsrv, reward, done, _, _ = env.step(0)\n",
    "print(\"Observation:\", obsrv)\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Finished?:\", done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "これらを用いてランダムに行動選択をし、その時々の状態を画像として格納する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.set(xticks=[], yticks=[])\n",
    "\n",
    "frames = []\n",
    "f = 0\n",
    "obsrv, _ = env.reset()\n",
    "while True:\n",
    "    f += 1\n",
    "    ims = ax.imshow(env.render())\n",
    "    txt = ax.text(20, 30, f\"frame #{f:d}\")\n",
    "    frames.append([ims, txt])\n",
    "\n",
    "    a = env.action_space.sample()\n",
    "    obsrv, reward, done, _, _ = env.step(a)\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAEs5tZGF0AAACrwYF//+r\n",
       "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzEwOCAzMWUxOWY5IC0gSC4yNjQvTVBF\n",
       "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMyAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
       "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
       "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
       "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
       "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTE1\n",
       "IGxvb2thaGVhZF90aHJlYWRzPTIgc2xpY2VkX3RocmVhZHM9MCBucj0wIGRlY2ltYXRlPTEgaW50\n",
       "ZXJsYWNlZD0wIGJsdXJheV9jb21wYXQ9MCBjb25zdHJhaW5lZF9pbnRyYT0wIGJmcmFtZXM9MyBi\n",
       "X3B5cmFtaWQ9MiBiX2FkYXB0PTEgYl9iaWFzPTAgZGlyZWN0PTEgd2VpZ2h0Yj0xIG9wZW5fZ29w\n",
       "PTAgd2VpZ2h0cD0yIGtleWludD0yNTAga2V5aW50X21pbj0xMCBzY2VuZWN1dD00MCBpbnRyYV9y\n",
       "ZWZyZXNoPTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0w\n",
       "LjYwIHFwbWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAA\n",
       "BIpliIQAO//+906/AptFl2oDklcK9yHrOuLcX/hC+FSuAAADAAADAAADADB2N9dUvGtnWaAAAAvY\n",
       "AjYN4Pvgdr3AH/kMlsqeC/bNDXCRTvmkQnSOiYZefk4T9jcR+GTlwOONRA+T1RV7yOMuzRm6oBKz\n",
       "QnUBRhfcrNrbYaku1sqO0WKmnU+gyBgiZ+2xVmp5EiEVMlMyth5X+DKv0SzzPIO2UJoYySL+6jys\n",
       "0pfVj2vwuJl68zgOWU5+BImYG0yjs1mlV4bMmNHXaQsriGqMyPnKFm0rwyubk17mkgoJHrq5Mv27\n",
       "qqjFkPmhebJsUq+JimkLeQX1H6lexuHPGMLmn7jkIVbelt6xV+E7/6pjE2zg+xfoCwlgw5qkwqzX\n",
       "qzVaRDiMklyFNUeuWT1/7V/QbMfl9XIWoH9eT2KKyYMKY/4MWySbQzU13+UnvooevzSMGKT04K33\n",
       "nGNmHyLkhgVQ+xvjqZUJpAvRtpZoohpSsYgAAAMBUO3IBaYAiYgruhYeUFsmrq41OLg9xLJ6l2Td\n",
       "zX6gZlNHjgtyWJSkVkBxOlxrU6VgS4RFavTWdSTcsC+Ah+xYpW3fNeLmvAFaCAuXKnUpAcAo7eBk\n",
       "la4e5RcX7ASWyePWSIT6EW4Nt6pCCSrc1n0kPhUSQk0mpkAuTI7araVz8YJm+xbeprELlk02s4k6\n",
       "GeKRqba+6YgvccX/66NAOHcf0i8J7OXNV1Sg2Uxh+Hs2c7S2cnCo8sie3VUR4KoNKzh74sKMpqNj\n",
       "BO3z1ibS9Xns/UeT/PUQKvjEPD+r3AUI0Mm2baJGfu7fqD9KDAOfFXtr+dDcoq3jxEicsAAAAwAU\n",
       "Y5qc/LgA8Z8gBaFmAptvdgAAAwAAAwAAznYNAFOfpUFyRVBA5cSF13A6aUIioijBaTMZUD0bR7Us\n",
       "/EXNMej711YaPlojOqnp/2cO1NlLRgoADmrVk3vRjE7BxQ3/rUAJI1gCrbSYz0L5s7ccJpsx3l9q\n",
       "W8UVfwkV40JgLFN+xnoDGnXEsX/TTEqaZKsS+vwNlvdbO+66KFMIzfVdJMQFQYgPnfOQEHFxXMs5\n",
       "3FoHY5u2HPIEMghwJJ+dnTkSwSVHFNiUc3YxlXOP6X+oFAzkS2YKgkZaQTOeZpNsvwwXNVU6RXi2\n",
       "zikX3qtK9RkADMrZY2MxMc9eTQAIPHW968yMX83/v55NV5jZshJfTkhxMAB2wNLnPur/u864qTPO\n",
       "3jPs31jE20rcSnFb83C4n/m95F98sEmfAd/4oRPVMYqXhq/N/ss9vYYpYhaDiUtVjs6jgzwzETpm\n",
       "WP870arCW+CtbGKYHHIfPS9qDLuobx2LILzheiPVygMG5tZ4lRACjYxa+nxx/LAvULZqGxs31SIY\n",
       "YeZ4Q+16eUr/U1fjn/XJ5i0jn+dcb5m5xYgMDfdvihLJ3CQJ+TAAAAMAAAMAAYa8LrdfDJOw40uq\n",
       "vsvPE1C+BwzrCnV/jKglk/Ui0ekgbZmv2n0T/4UnAu2oQV/cypVEqD23H1qgPGm7HbOOB0rvwv52\n",
       "9RyeezVpX80lfX8bZwQACJQAAAMAAAopAAABB0GaJGxDv/6plgAEgWTUAIfABJqiSg9B1wHHt7bB\n",
       "VCwAFX67r7MK+awER178cE+OJUQb1qLJaJFeyu4mA2/eONMibrNNbypNCQAM5iDYGcDpkA6Fb3jX\n",
       "v5h3mK4A+EJ5EzQwZY93Ytz3QaDU1Fn3ZiQil9m9b/++10UIpIYdx1vexzfXBPzmbeI/j3cF1lYL\n",
       "J0RPav2qVQFXZbAv2dvACnoCfdwQA58KPLFCibISoVPHHlpLhw7qFj01I+yTu0Ir+ta/ueh7aaOn\n",
       "gKQnQlSh5hsW7jbZCPWace8rjwrIono96G488rJSp9RNZFX3wzmQ8nqqmOoEgqpqjsjTHcBtfD8J\n",
       "swKUKAFBAAAAnkGeQniHfwACQCLZjQAeOdVTc6RrXcg1inEGA+qKsa7KGeDWc8OQ+5ccoStnz7Rl\n",
       "rXrdwIcxVVCjW7Hb12Xcn4o+mhR84678/oSgYaOflT5xjAUuXjWZn3w4NX/dqgKNIWeVEgSK3C9N\n",
       "H5R8a60nMUMei40Xc8yZawFrQ7QAEw9/AJW3rvHaJtYR5af2xQtXGmCUrr/rFP66eZBwCOmBAAAA\n",
       "agGeYXRDfwADN9iSABNYVZi9ADY91c4Rwpd6Dt/WWBCrmfxX8Epii/wxN/4C3dGgKpsbpeo1E97c\n",
       "5JATGoLIoSAkPYXCuEPyz2gUbeXz4Ii43MVN7DmzT7UFudKC/2YcNvetzyyY7XBsYEAAAAB0AZ5j\n",
       "akN/AAMvIKCQAgZRGImq5DDkyzbM0UcyexYzMmVRrTDlhpG3X3WtoLYfpgne7XppTi6dBEi4IB10\n",
       "ezHDqf8BZl3kdGJSKO7z0dVUNLbiZ9YUDt+I6jW0q8Ab1W3vvOJHAeRkzcB0cQCFzTF7qYTlgfMA\n",
       "AAFaQZpoSahBaJlMCHf//qmWAASCb8xoAaekIhoqNBZSdwyxpJn8lcyy9BOEech2LENQJoZTcFoq\n",
       "2i1WyvnmTtZZxWxqQwJw+P9GTOpa/uxdWoshAuXCI4tizrmGKzV+mUC/8n8AvnqcYzmWZJvHJSJg\n",
       "LTKtZIl2WAk4ycq0JxjiqcU1O0C+SfHUYO6C1+n4foeLOJ6yol/Gv5XISKCxuAEGD+nb1Az/a8O7\n",
       "nh13SD93U4lLOf1/uCEQNrr1O3OPtqm3dJ3vgWzloQeKKUMfvaS47xdp7Ewp0ieHHI4jabD+xaHU\n",
       "BuytqCmcnj+KLTmJc/cWfeu7VDqjJ56RSNf7+SgrSH2glglTHhXchQ1Z4PrUHbQksXr98/ufFgM0\n",
       "Z/0QGDm9FUAyTXBJXKQiDQKWogTt1D8MRGdZ6eJJcWwJWAU9ctra5tpx577RRLm8bEdKlGHuKTKn\n",
       "9vACK2JWnwAAAMFBnoZFESw7/wACOYv5mLQAasHUx0eFBtrknqSW5tDy24Li/Kis1418QRI1PSmV\n",
       "73xp111j702uYnal8Nj8ekVlP/4nBqIx+Q/HlvE6KtXLU3fGdg5aONebncbm2TdkBoywX1dnR+nT\n",
       "YRRxPPnOVwCxTu6ElA0WSxLaonWpnvQa2OM6cWzh0D40EJRpt2IftEFqr0zhkS72+PIqso+AGBy5\n",
       "j139xmOHeAUdVftrv/v9Is72JDaLxcfaeUWszmmiwAIfAAAAigGepXRDfwADN5Yb3ACBkirqwHCz\n",
       "AnvSw3EHAu0gZwcwdtka4w9xIOyXST7qt7GxZnVKgVMpt5PJD3TykcH8PKQ6Aea4HQ5XOG0TRny7\n",
       "M3irc88tm5aVsuK9WeSdN9XOuhCYOxLEbsu6qeqWS6QXbHJXbOUSNPUhlrm6DWfs58qtCn2yNCmq\n",
       "2xwHzQAAAI4BnqdqQ38AAzgFuQAhOfxhcjdp9MvRUhPwhkNp0JjzBpchaxK/GxFimM56F1zWugp1\n",
       "B8LQuiVT/cqsbyNfy0FjplWBhSBer7b1W2ZfqwTdaF933u0If8Ulwwes/+IMfdW1AHXoHx386SCJ\n",
       "rxX67guekeQZ2OrUlgkvol7UoSAkOPJMtoTRHcQjDD/ApwPmAAABgEGarEmoQWyZTAh3//6plgAE\n",
       "gVWuAAZ8zfGDJBSXqTT37FrUavzz9BLslnzbwi0od087vnsKTcaR4puu8GPw8wohCoVAgHpq0EHL\n",
       "6fmOFINI6YpWGoZn1tzNoipcnq6Wtn0+BdrcmY/RlIyjcZ6cMgBb9G40n8HdldfYexIrU3Fz64aR\n",
       "whZsO5li3m1PUA2RtudOzxf43hXWFtTTdjfR5AYAuN/7mkJnBk1I6Pp+sdABxqueeNiEySqws9up\n",
       "9xiNEzP0/SLS1KoFfhr5r7K5S0UUIk9PU9FMku+cpqEb0ThtwXyE78upOEdsUjMyKizhpqvItQM2\n",
       "Zg7JzFMZr1cQuF7rupUS+6x2W/fFjq49uq8GT5dqPOosFxiVifKBVMsRDKVseUAeRZFtF4dYP7G8\n",
       "yMdGJ+ejrs7IW3lqoDqeRKUD9Bhc5hpOMIAWo+gizSC2lPGRICxiY71+dBJ+K5gWXZLkpC+BJt/x\n",
       "YUog7jqhQPpLwITDtujQDNfcFwUgSGVRnAAAALFBnspFFSw7/wACQONTdlg4AJl/JfX4IZQewyJp\n",
       "IrA7lNM+P8JARP4AlR1M0KNcPSaCxm8k3a5oAHcwzb+TnGysvU8IKVBsRRLYUAU27BQjPDhuImyK\n",
       "7BsGNqpG4T/GH+pI5ooxHLfG5ofX01cruX5VaVZrVoro/F44WScjHLbERH+NkThxrhR0lC7Aq4gV\n",
       "qKPZmndrdR1mzlOPShb7jR3sri6FmBIrdzx90IRakiZAIWEAAABwAZ7pdEN/AAM31W9ISAD4dn1E\n",
       "OC30LF+T4KbRjXM4sEPp9RdOtKPjhno9tNodJ+Ek8d6Oct2gVfaSXvBu/h9SvGBOvFYv7fRUPmQ8\n",
       "sv/t8T/2H30Aaa1ZRxCWFcjDA90KAeK3TUtIkBwJ8aZMgUiZgAAAAIsBnutqQ38AAyL38vIATV7e\n",
       "6/B3KGzyuNloQWGmNcK5GbQ/9zX68qhirMhSEIEnYWHnaL2VIPpqF0BVTybzwnNItxAHCXYLNyFe\n",
       "Ibd4bEHtFN4fr8TWNL+aAb637ultgMTkHgM94K15o4KYkkBUzPW2+AneR7u1LBLQ4GNGEv1sKAmx\n",
       "eh+WHTxYRzGpAAABE0Ga70moQWyZTAhv//6nhAAIrZ2TcgBL7+/26/6A+bl/6ueF4ULlwUBTrZOO\n",
       "eXpezyBPn8uulilZGqB8orL4eYLoUb6FprFDXdlkYzeJ+7/d8hd1Xv26D354rVZxxCulkETQ/vBj\n",
       "LbuzSjVmBUVStKy1JSsaiWgpL25UuTINvvXQDcBPnt5nc21u9lsecjbVVrn/T3lyvDv8Z4qIrpkc\n",
       "piHXwy8tp5mxGUMhckLLlgGuCrp5g5B3/Isbga/oDGkpFUVBm54Q6PlnSOBibxgygQj6nJxxYJTL\n",
       "WfbQT75/L1ZAMPPS1RTh/K7a+emLHTYja+/Vu13fEXRJxstWBhau41GzbVFLsHsfB8ALH1TjJmXH\n",
       "FKltAAAArUGfDUUVLDf/AAMaDyLM5Kv8AJVGXdLQ1P/gL3ePlLP3RSoT5qMzdqAcMhF/MuUUxoX4\n",
       "YIKY2aXYi0uXjRqLJMU1U5F59ADx70QoSA+2Ju+ttOcWHHrR92xGtjIKy+KjvvUXK93jMBClePxy\n",
       "AVpItO7n6EYoFG/NQ7+aJ6qXlQKopTRYAk69gYaNEU4kLF/1F1r53NIvL7NOAFysDbglzJmUNZys\n",
       "g8N8NKVOYAMXAAAApwGfLmpDfwADI5cRB8AH465kr6dKSBWO2ZjRqTVNu/r3g3Dp9r/2BFinNbo3\n",
       "RqZng9FLoSpDpf0OoCFIGSH0dJ6C72V+/pHmmDb26YIc1En/wkK9d85s220bUmh1+S+kVUPX/3q5\n",
       "+sxoFBJw6gWlPKBEdPwrNdgWGclQnel4oGcF+ZEM8XCcjC7jhzouO/vqqywvRuadDASTnWvnaOa3\n",
       "udCviZvnKAfNAAAD6W1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAZAAAEAAAEAAAAAAAAA\n",
       "AAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAIAAAMUdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAZAAAAAAAAA\n",
       "AAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAKAAAAB4AAAAAAA\n",
       "JGVkdHMAAAAcZWxzdAAAAAAAAAABAAAGQAAACAAAAQAAAAACjG1kaWEAAAAgbWRoZAAAAAAAAAAA\n",
       "AAAAAAAAKAAAAEAAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5k\n",
       "bGVyAAAAAjdtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEA\n",
       "AAAMdXJsIAAAAAEAAAH3c3RibAAAALdzdHNkAAAAAAAAAAEAAACnYXZjMQAAAAAAAAABAAAAAAAA\n",
       "AAAAAAAAAAAAAAKAAeAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAABj//wAAADVhdmNDAWQAFv/hABhnZAAWrNlAoD2hAAADAAEAAAMAFA8WLZYBAAZo6+PLIsD9\n",
       "+PgAAAAAHHV1aWRraEDyXyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAAAQAAAEAAAA\n",
       "ABRzdHNzAAAAAAAAAAEAAAABAAAAiGN0dHMAAAAAAAAADwAAAAEAAAgAAAAAAQAAFAAAAAABAAAI\n",
       "AAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQA\n",
       "AAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAEAAAAAACAAAEAAAAABxzdHNjAAAAAAAAAAEA\n",
       "AAABAAAAEAAAAAEAAABUc3RzegAAAAAAAAAAAAAAEAAAB0EAAAELAAAAogAAAG4AAAB4AAABXgAA\n",
       "AMUAAACOAAAAkgAAAYQAAAC1AAAAdAAAAI8AAAEXAAAAsQAAAKsAAAAUc3RjbwAAAAAAAAABAAAA\n",
       "MAAAAGF1ZHRhAAAAWW1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAA\n",
       "LGlsc3QAAAAkqXRvbwAAABxkYXRhAAAAAQAAAABMYXZmNjAuMy4xMDA=\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython.display as display\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "\n",
    "# Create the animation\n",
    "ani = ArtistAnimation(fig, frames, interval=100, blit=True)\n",
    "html = display.HTML(ani.to_html5_video())\n",
    "display.display(html)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "このようにランダムに行動した場合には、途中で棒の傾きが一定以上になってしまい、エピソードが終了していることが分かる。以下では、Q学習によって行動評価関数を最適化し、より長い時間、倒立状態を保てるようにしてみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "この時、各変数は連続的な値を取るため、Q値のテーブルを学習するためには、値を離散化して置く必要がある。これにはNumPyのdigitize関数が使える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "N_DIGITS = 10\n",
    "N_INPUTS = env.observation_space.shape[0]\n",
    "N_ACTIONS = env.action_space.n\n",
    "\n",
    "lower = env.observation_space.low\n",
    "upper = env.observation_space.high\n",
    "lower[1], upper[1] = -5.0, 5.0  # 速度の範囲を修正\n",
    "lower[3], upper[3] = -0.5 * np.pi, 0.5 * np.pi  # 角速度の範囲を修正\n",
    "\n",
    "bins = np.transpose(np.linspace(lower, upper, N_DIGITS))\n",
    "obsrv, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q値テーブルの初期化\n",
    "q_table = np.zeros((N_DIGITS**N_INPUTS, env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ランダムに行動する\n",
    "a = env.action_space.sample()\n",
    "s1 = env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 一番価値が高く見積もられている行動をとる\n",
    "digits = [np.digitize(x, bin) for x, bin in zip(obsrv, bins)]\n",
    "s0 = reduce(lambda a, b: a + b * 10, digits)\n",
    "a = np.argmax(q_table[s0, :])\n",
    "s1 = env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x - np.max(x, axis=0)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7807f4285b5745eb80a27bd9bcadf019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q学習のハイパーパラメータ\n",
    "alpha = 0.5\n",
    "gamma = 0.99\n",
    "\n",
    "# Q値テーブルの初期化\n",
    "q_table = np.zeros((N_DIGITS**N_INPUTS, env.action_space.n))\n",
    "\n",
    "for epi in tqdm(range(10000)):\n",
    "    # ゲーム環境のリセット\n",
    "    obsrv, _ = env.reset()\n",
    "\n",
    "    # エピソード開始\n",
    "    while True:\n",
    "        # 現在の状態に対応する行番号を計算\n",
    "        digits = [np.digitize(x, bin) for x, bin in zip(obsrv, bins)]\n",
    "        s0 = reduce(lambda a, b: a + b * 10, digits)\n",
    "\n",
    "        # ε-greedy法による行動選択\n",
    "        # if np.random.random() < 0.5:\n",
    "        #     a = env.action_space.sample()\n",
    "        # else:\n",
    "        #     a = np.argmax(q_table[s0, :])\n",
    "\n",
    "        # softmax探索による行動選択\n",
    "        prob = softmax(q_table[s0, :])\n",
    "        a = np.random.choice(np.arange(len(prob)), p=prob)\n",
    "\n",
    "        # 状態の更新\n",
    "        obsrv, reward, done, _, info = env.step(a)\n",
    "\n",
    "        # 新たな状態に対する行番号を計算\n",
    "        digits = [np.digitize(x, bin) for x, bin in zip(obsrv, bins)]\n",
    "        s1 = reduce(lambda a, b: a + b * 10, digits)\n",
    "\n",
    "        # Qテーブルの更新\n",
    "        q0 = q_table[s0, a]\n",
    "        best_q1 = np.max(q_table[s1, :])\n",
    "        q_table[s0, a] = (1.0 - alpha) * q0 + alpha * (reward + gamma * best_q1)\n",
    "\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.set(xticks=[], yticks=[])\n",
    "\n",
    "frames = []\n",
    "f = 0\n",
    "obsrv, _ = env.reset()\n",
    "while True:\n",
    "    f += 1\n",
    "    ims = ax.imshow(env.render())\n",
    "    txt = ax.text(20, 30, f\"frame #{f:d}\")\n",
    "    frames.append([ims, txt])\n",
    "\n",
    "    digits = [np.digitize(x, bin) for x, bin in zip(obsrv, bins)]\n",
    "    s0 = reduce(lambda a, b: a + b * 10, digits)\n",
    "    a = np.argmax(q_table[s0, :])\n",
    "\n",
    "    obsrv, reward, done, _, _ = env.step(a)\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "\n",
    "# Create the animation\n",
    "ani = ArtistAnimation(fig, frames, interval=100, blit=True)\n",
    "html = display.HTML(ani.to_html5_video())\n",
    "display.display(html)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
