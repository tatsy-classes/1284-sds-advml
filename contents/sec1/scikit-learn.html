

<!DOCTYPE html>


<html lang="ja" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>7. scikit-learnによる機械分類の基本 &#8212; 機械学習発展 (実践)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=927b94d3fcb96560df09"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/custom.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'contents/sec1/scikit-learn';</script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="検索" href="../../search.html" />
    <link rel="next" title="8. 演習1 - 画像入力式数独ソルバーを作る" href="exercise-sudoku.html" />
    <link rel="prev" title="6. 図形の検出" href="figure-detection.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ja"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">機械学習発展 (実践)</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">第1部 画像読み取り式数独ソルバの実装</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="setup-python.html">1. Python環境の設定</a></li>
<li class="toctree-l1"><a class="reference internal" href="numpy.html">2. NumPyの基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="matplotlib.html">3. Matplotlibの基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="pandas.html">4. Pandasの基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="opencv.html">5. OpenCVの基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="figure-detection.html">6. 図形の検出</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">7. scikit-learnによる機械分類の基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercise-sudoku.html">8. 演習1 - 画像入力式数独ソルバーを作る</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">第2部 ひらがなOCRソフトと百人一首エージェントの実装</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../sec2/data-visualization.html">1. データ可視化と次元圧縮</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec2/feature-extraction.html">2. 特徴量抽出</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec2/deep-learning.html">3. 深層学習による物体認識</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec2/exercise-ogura.html">4. 演習2 - 百人一首エージェントを作る</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">第3部 強化学習の基礎とリバーシエージェントの実装</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../sec3/reinforcement-learning.html">1. 強化学習の基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec3/q-learning.html">2. Q学習</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec3/othello-agent.html">3. オセロAIの作成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec3/deep-reinforcement-learning.html">4. 深層強化学習</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec3/exercise-othello.html">5. 演習3 - オセロエージェントを作る</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendix/notation.html">資料中の表記について</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/tatsy/1284-sds-ml-advanced/blob/master/./contents/sec1/scikit-learn.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/tatsy/1284-sds-ml-advanced" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="ソースリポジトリ"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tatsy/1284-sds-ml-advanced/issues/new?title=Issue%20on%20page%20%2Fcontents/sec1/scikit-learn.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="問題を報告"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="このページをダウンロード">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/contents/sec1/scikit-learn.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="ソースファイルをダウンロード"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="PDFに印刷"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="全画面モード"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="検索" aria-label="検索" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>scikit-learnによる機械分類の基本</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> 目次 </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification">7.1. 分類問題 (classification)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">7.2. データのスケーリング</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">7.2.1. 最近傍探索による分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">7.2.2. ロジスティック回帰による分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">7.2.3. バギングによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">7.2.4. ランダム・フォレストによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost">7.2.5. AdaBoostによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">7.2.6. 勾配ブースティングによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ssec-support-vector-machine">7.2.7. サポートベクトルマシンによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">7.2.8. カーネル法を用いたサポートベクトルマシン</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">7.2.9. ここまでの手法の比較</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">7.3. ハイパーパラメータの調整</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">7.3.1. ホールドアウト検証</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">7.3.2. 交差検証 (クロス・バリデーション)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">7.4. 学習済みデータの保存</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">7.5. 分類問題の評価方法</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">7.5.1. 2クラス分類の場合</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">7.5.2. 多クラス分類の場合</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">7.6. 練習問題</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">7.7. 参考文献</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="scikit-learn">
<span id="sec-scikit-learn"></span><h1><span class="section-number">7. </span>scikit-learnによる機械分類の基本<a class="headerlink" href="#scikit-learn" title="Permalink to this heading">#</a></h1>
<p>この項では、scikit-learnを用いた機械学習の基礎と、得られた結果の評価方法について学ぶ。</p>
<p>scikit-learnは様々な機械学習の手法が統一的なコードにより使用できるように整備されたライブラリである。例えば、機械学習器のパラメータをデータセットに合わせて調整するには<code class="docutils literal notranslate"><span class="pre">fit</span></code>という関数を用い、機械学習器を用いた予測には<code class="docutils literal notranslate"><span class="pre">predict</span></code>という関数を使う、といった具合である。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">下準備のコード</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <span class="n">ConvergenceWarning</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">glue</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">_</span>


<span class="c1"># グラフの設定</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.dpi&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;colorblind&quot;</span><span class="p">)</span>

<span class="c1"># シードの固定</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">31415</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">31415</span><span class="p">)</span>

<span class="c1"># 実験に使うデータ数</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;n_samples&quot;</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 一部の警告を無視</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">ConvergenceWarning</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="ne">FutureWarning</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;PYTHONWARNINGS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ignore&quot;</span>

<span class="c1"># 結果を格納していくDataFrame</span>
<span class="n">result_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;Method&quot;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">),</span>
        <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float64&quot;</span><span class="p">),</span>
        <span class="s2">&quot;Phase&quot;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">),</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<section id="classification">
<h2><span class="section-number">7.1. </span>分類問題 (classification)<a class="headerlink" href="#classification" title="Permalink to this heading">#</a></h2>
<p>まずは、scikit-learnのいくつかの機械学習器を用いて手書き文字のデータセットである<strong>MNIST</strong>(Modified National Institute of Standards and Technology)を分類してみる。</p>
<p>scikit-learnには<code class="docutils literal notranslate"><span class="pre">datasets</span></code>というモジュールがあり、ウェブ上に公開されているMNISTのデータを簡単にダウンロードできるので、今回はそれを利用する。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 以下のコードはデータのダウンロードを伴うため、少々時間がかかる</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">X_org</span><span class="p">,</span> <span class="n">y_org</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_openml</span><span class="p">(</span>
    <span class="s2">&quot;mnist_784&quot;</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">data_home</span><span class="o">=</span><span class="s2">&quot;./mnist&quot;</span><span class="p">,</span> <span class="n">parser</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
<span class="p">)</span>
<span class="n">X_org</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_org</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;double&quot;</span><span class="p">)</span>
<span class="n">y_org</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_org</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;uint8&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>上記の<code class="docutils literal notranslate"><span class="pre">fetch_openml</span></code>において第1引数の<code class="docutils literal notranslate"><span class="pre">mnist_784</span></code>はデータセットの名前で、今回用いるのMNISTは28x28(=784)の手書き数字を表わす白黒画像が含まれたものを使用する。ダウンロード元の<a class="reference external" href="https://www.openml.org/search">OpenML</a>では、他にも多くのデータセットが利用可能なので、興味のあるデータを検索してみると良い。</p>
<p>また<code class="docutils literal notranslate"><span class="pre">return_X_y</span></code>は関数の戻り値が画像データ<code class="docutils literal notranslate"><span class="pre">X</span></code>とラベル<code class="docutils literal notranslate"><span class="pre">y</span></code>になるようにするためのフラグで、最後の<code class="docutils literal notranslate"><span class="pre">data_home</span></code>は二度目以降にデータセットを使用するときに再度ダウンロードしないよう、データをキャッシュしておくディレクトリを指定している。なお、特に<code class="docutils literal notranslate"><span class="pre">data_home</span></code>を指定しない場合はホームディレクトリに<code class="docutils literal notranslate"><span class="pre">scikit_learn_data</span></code>というディレクトリが作成され、その中にデータがキャッシュされる。一度目に上記のコードを実行すると、データのダウンロードに時間がかかるが、二度目以降はキャッシュされたデータを読み込むため時間が短縮される (それでも数秒はかかる)。</p>
<p>上記、scikit-learnの関数で得られるデータは<a class="reference external" href="https://pandas.pydata.org/">Pandas</a>の<code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>という方になっているのでおく。なお、データを画像として可視化すると以下のようになっている。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 画像として見られるように配列の形を変更</span>
<span class="n">ims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_org</span><span class="p">[:</span><span class="mi">6</span><span class="p">],</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>

<span class="c1"># 最初の5枚を確認してみる</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">ims</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;label is </span><span class="si">{:d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_org</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/22d96eb4dc159b309f61d561a6384724b5b95ff87beac38f869e7c2fef944cba.png" src="../../_images/22d96eb4dc159b309f61d561a6384724b5b95ff87beac38f869e7c2fef944cba.png" />
</div>
</div>
<p>MNISTのデータは訓練とテストのそれぞれに60000個, 10000個のデータが用意されているので、<code class="docutils literal notranslate"><span class="pre">train_test_split</span></code>を用いてデータを分割しておく。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span>

<span class="n">X</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_org</span><span class="p">,</span> <span class="n">y_org</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>なお、今回は計算時間の短縮のために、先頭<span class="output text_plain">10000</span>個のデータだけを使って、以下の実験を行う。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">],</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">],</span> <span class="n">y_test</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id1">
<h2><span class="section-number">7.2. </span>データのスケーリング<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>機械学習器にデータを学習させる前にデータのスケールを揃えておくと精度が改善する場合が多い。最も良く用いられる方法は<strong>訓練データの平均と分散</strong>を計算して、データの各次元の平均が0、分散が1となるように変形する方法である。この方法は、scikit-learnの<code class="docutils literal notranslate"><span class="pre">StandardScalar</span></code>に実装されているので、今回はこれを使用する。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># スケーリングパラメータの計算</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># データのスケーリング</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>データのスケーリングを行う場合、<strong>スケールを決定するのに使えるデータは訓練データのみ</strong>であることに注意する (テストデータがどんなデータなのかは事前に分からないため)。また、テストをする際にスケーリングをするのを忘れないようにすること。</p>
</div>
<section id="id2">
<h3><span class="section-number">7.2.1. </span>最近傍探索による分類<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>識別を行う上で、最も単純な方法は手書き文字の画像を多次元ベクトルと見なして、多次元空間の近傍に多く存在するサンプルのラベルを、未知のデータのラベルとして採用するというものだろう。それを実現するのが<code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code>である。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="c1"># 識別モデルの構築</span>
<span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>以下は、未知のデータが与えられた時、近傍の<span class="output text_plain">20</span>枚の画像を探索して、その画像の持つラベルの中で最も多いものを未知データに対するラベルとして採用する、というコードである。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">glue</span><span class="p">(</span><span class="s2">&quot;knn_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">glue</span><span class="p">(</span><span class="s2">&quot;knn_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;k-nearest&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;k-nearest&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</details>
</div>
<p><strong>結果: 最近傍探索による分類</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">90.27</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">89.50</span>%</p></li>
</ul>
</section>
<section id="id3">
<h3><span class="section-number">7.2.2. </span>ロジスティック回帰による分類<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>続いては入力を線形変換することで出力を予測する線形モデルの一種であるロジスティック回帰 (`LogisticRegression')を使ってみる。</p>
<p>ロジスティック回帰のパラメータは行列<span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{m \times n}\)</span>とバイアス項<span class="math notranslate nohighlight">\(\mathbf{b} \in \mathbb{R}^{m}\)</span>で多クラスの分類問題の場合には、入力<span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^{n}\)</span>に対して、ソフトマックス関数<span class="math notranslate nohighlight">\(\sigma(\cdot)\)</span>を用いて出力である分類ラベル<span class="math notranslate nohighlight">\(\mathbf{y} \in \mathbb{R}^{m}\)</span>を予測する。</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y} = \sigma(\mathbf{Ax} + \mathbf{b})
\]</div>
<p>なお、ソフトマックス関数は、入力<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>を以下の式によって<span class="math notranslate nohighlight">\(\mathbf{x}'\)</span>へと変換する。</p>
<div class="math notranslate nohighlight">
\[
x'_i = \sigma(\mathbf{x}) = \frac{\exp x_i}{\sum_{j=1}^n \exp x_j}
\]</div>
<p>従って、予測ラベル<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>の各要素は0から1の値を取り、なおかつ<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>の全要素の合計は1になる。このことから<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>はラベルの予測確率を表わしており、この中で最も大きな値を持つ要素が予測識別の結果であると考えられる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># 訓練モデルの構築</span>
<span class="n">lr_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;tol&quot;</span><span class="p">:</span> <span class="mf">1.0e-3</span><span class="p">,</span> <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span> <span class="mi">5000</span><span class="p">,</span> <span class="s2">&quot;solver&quot;</span><span class="p">:</span> <span class="s2">&quot;lbfgs&quot;</span><span class="p">}</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(max_iter=5000, tol=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=5000, tol=0.001)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;logis_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;logis_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Logistic&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Logistic&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>結果: ロジスティック回帰による分類</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">99.77</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">87.96</span>%</p></li>
</ul>
</section>
<section id="id4">
<h3><span class="section-number">7.2.3. </span>バギングによる分類<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>バギング(bagging)とはBootstrap AGGregatINGから作られた造語であり、訓練データの部分集合にあたる<strong>ブートストラップ・サンプル</strong>を用いて学習した異なる分類器の多数決によって、最終的な分類予測を行う機械学習法である<strong>アンサンブル学習の一種</strong>である。</p>
<p>例えば、訓練データが<span class="math notranslate nohighlight">\(N\)</span>個のサンプルからなる時、<span class="math notranslate nohighlight">\(M\)</span>個のサブサンプル (<span class="math notranslate nohighlight">\(M \leq N\)</span>)を取り出して、分類器を学習する。この操作を複数のサブサンプルと分類器に対して実行する。このようにブートストラップ・サンプルで訓練された分類器のことを<strong>弱分類器</strong>と呼ぶ。</p>
<p>最終結果は、単純には、得られた分類器の予測の中で一番多数の票を集めたものが与えられる。以下に単純なバギングの実装例を与える。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 単純なバギングの実装例</span>
<span class="n">n_bootstrap</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">n_estims</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1">## 訓練</span>
<span class="n">estims</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_estims</span><span class="p">):</span>
    <span class="n">randidx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_bootstrap</span><span class="p">))</span>
    <span class="n">X_smp</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">randidx</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">y_smp</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">randidx</span><span class="p">]</span>
    <span class="n">estim</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>
    <span class="n">estim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_smp</span><span class="p">,</span> <span class="n">y_smp</span><span class="p">)</span>
    <span class="n">estims</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## 予測</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">vote</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="n">n_classes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">estim</span> <span class="ow">in</span> <span class="n">estims</span><span class="p">:</span>
    <span class="n">y_sub</span> <span class="o">=</span> <span class="n">estim</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">vote</span><span class="p">,</span> <span class="n">y_sub</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">put_along_axis</span><span class="p">(</span><span class="n">vote</span><span class="p">,</span> <span class="n">y_sub</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">temp</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">vote</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 精度計算</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Bagging: acc(test)=</span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Bagging: acc(test)=90.54%
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p>バギングをscikit-learnを用いて実装した場合には以下のようになる。</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>

<span class="c1"># 訓練モデルの構築 (弱識別器にロジスティック回帰を使用)</span>
<span class="n">weak</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">weak</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;bag_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;bag_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Bagging&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Bagging&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>結果: バギングによる分類</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">98.68</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">89.62</span>%</p></li>
</ul>
<p>バギングは、部分データを用いて学習した複数の分類器を組み合わせているだけなので、弱分類に用いる分類器(上記の例では<code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>)と比べて、それほど精度が増加しないことが多い。これは、部分データ同士の相関が大きく、結果として、弱分類器の予測が似通ってしまうことに起因する。</p>
</section>
<section id="id5">
<h3><span class="section-number">7.2.4. </span>ランダム・フォレストによる分類<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>ランダム・フォレストはバギングの弱分類器による推論が似通ってしまう問題を解決する分類器の一つである。バギングにおいて、予測が偏ってしまう原因は、ブートストラップ・サンプルのサイズ<span class="math notranslate nohighlight">\(M\)</span>が十分<span class="math notranslate nohighlight">\(N\)</span>に近ければ、訓練データの分布が似通ってしまうためである。</p>
<p>そこで、ランダム・フォレストでは、訓練データの特徴のうち、ランダムに数個だけを選んで弱分類器を学習する。このようにすることで十分に<span class="math notranslate nohighlight">\(N\)</span>に近い<span class="math notranslate nohighlight">\(M\)</span>であっても、分布の異なるサンプル集合を得ることができる。</p>
<p>ランダム・フォレストには通常、弱分類器として決定木が用いられることが多いが、以下では、<code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>を用いた簡易実装を紹介する。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 単純なランダム・フォレストの実装例</span>
<span class="n">n_data</span><span class="p">,</span> <span class="n">n_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="n">n_bootstrap</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">n_data</span><span class="p">)</span>
<span class="n">n_estims</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_sub_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">n_dim</span><span class="p">)</span>

<span class="c1">## 訓練</span>
<span class="n">estims</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">dims</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_estims</span><span class="p">):</span>
    <span class="n">randsmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_data</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_bootstrap</span><span class="p">))</span>
    <span class="n">randdim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_sub_dim</span><span class="p">))</span>
    <span class="n">X_smp</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">randidx</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">X_smp</span> <span class="o">=</span> <span class="n">X_smp</span><span class="p">[:,</span> <span class="n">randdim</span><span class="p">]</span>
    <span class="n">y_smp</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">randidx</span><span class="p">]</span>
    <span class="n">estim</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>
    <span class="n">estim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_smp</span><span class="p">,</span> <span class="n">y_smp</span><span class="p">)</span>
    <span class="n">estims</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estim</span><span class="p">)</span>
    <span class="n">dims</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">randdim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## 予測</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">vote</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="n">n_classes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">estim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">estims</span><span class="p">):</span>
    <span class="n">X_sub</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:,</span> <span class="n">dims</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
    <span class="n">y_sub</span> <span class="o">=</span> <span class="n">estim</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_sub</span><span class="p">)</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">vote</span><span class="p">,</span> <span class="n">y_sub</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">put_along_axis</span><span class="p">(</span><span class="n">vote</span><span class="p">,</span> <span class="n">y_sub</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">temp</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">vote</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 精度計算</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Random Forest: acc(test)=</span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest: acc(test)=89.27%
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p>ランダム・フォレストをscikit-learnを用いて実装した場合には以下のようになる。なお、scikit-learnのランダム・ランダムフォレストは弱分類器に決定木を用いるため、バギングの時のように弱分類器のモデルを指定することはできない。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># 訓練モデルの構築 (弱識別器にロジスティック回帰を使用)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestClassifier(max_depth=5, max_features=8, n_estimators=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">RandomForestClassifier</label><div class="sk-toggleable__content"><pre>RandomForestClassifier(max_depth=5, max_features=8, n_estimators=20)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;rf_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;rf_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Random forest&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Random forest&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>結果: ランダム・フォレストによる分類</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">81.32</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">79.61</span>%</p></li>
</ul>
</section>
<section id="adaboost">
<h3><span class="section-number">7.2.5. </span>AdaBoostによる分類<a class="headerlink" href="#adaboost" title="Permalink to this heading">#</a></h3>
<p>バギングを拡張したアンサンブル学習には、ランダム・フォレスト以外にも<strong>ブースティング</strong>という手法がある。ブースティングは、バギングのように独立した弱分類器を学習するのではなく、弱分類器の列を順に学習していく。この際、新しく列に追加される弱分類器は、<strong>それまでの学習結果で上手く分類できていないサンプルをより良く識別するように補正</strong>をいれて学習する。</p>
<p>このようなブースティング法には多くのバリエーションがあるが、ここではその代表格である<strong>AdaBoost</strong>を紹介する。AdaBoostの大まかな学習手順は以下のようになる。</p>
<ol class="arabic simple">
<li><p>弱分類器<span class="math notranslate nohighlight">\(f_1\)</span>を訓練データ<span class="math notranslate nohighlight">\((\mathbf{x}_i, y_i)\)</span>から作成する。</p></li>
<li><p>弱分類器<span class="math notranslate nohighlight">\(f_1\)</span>の訓練データ<span class="math notranslate nohighlight">\(y_i\)</span>に対する識別精度を求め、その識別精度が悪い物に対して大きな重み<span class="math notranslate nohighlight">\(w_i\)</span>を割り当てる。</p></li>
<li><p>重み<span class="math notranslate nohighlight">\(w_i^{(1)}\)</span>によってサンプルの重要度を変えて、次の弱識別器<span class="math notranslate nohighlight">\(f_2\)</span>を学習する。</p></li>
<li><p>以下、<span class="math notranslate nohighlight">\(f_{t-1}\)</span>の識別精度から次の弱識別器の学習に用いる重み<span class="math notranslate nohighlight">\(w_i^{(t-1)}\)</span>を計算し、弱識別器の学習を繰り返す。</p></li>
</ol>
<p>このようにして得られた弱識別器の予想を重み付き平均することにより、未知データに対する予測を得る。</p>
<div class="math notranslate nohighlight">
\[
y = \sum_{i=1}^{n_{\rm weak}} \alpha_i f_i(\mathbf{x})
\]</div>
<p>なお、<span class="math notranslate nohighlight">\(n_{\rm weak}\)</span>は弱識別器の数を表わし、<span class="math notranslate nohighlight">\(\alpha_i\)</span>は各識別器の正確さに基づく重みである。</p>
<p>scikit-learnを用いたAdaBoostによる識別には<code class="docutils literal notranslate"><span class="pre">AdaBoostClassifier</span></code>を用いる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>

<span class="c1"># 訓練モデルの構築 (弱識別器にロジスティック回帰を使用)</span>
<span class="n">weak</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">lr_params</span><span class="p">)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">weak</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>AdaBoostClassifier(estimator=LogisticRegression(max_iter=5000, tol=0.001),
                   n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" ><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">AdaBoostClassifier</label><div class="sk-toggleable__content"><pre>AdaBoostClassifier(estimator=LogisticRegression(max_iter=5000, tol=0.001),
                   n_estimators=10)</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" ><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=5000, tol=0.001)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" ><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=5000, tol=0.001)</pre></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;ada_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;ada_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;AdaBoost&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;AdaBoost&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>結果: AdaBoostによる分類</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">81.32</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">79.61</span>%</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>上記の例では弱識別器にロジスティック回帰を用いているが、それにも関わらず、<strong>ロジスティック回帰を単体で用いる場合に比べて精度が落ちている</strong>ことが分かる。これは、AdaBoostにおいて、</p>
<ol class="arabic simple">
<li><p>弱分類器の学習は、単体の分類器の学習よりも甘めに行われる (最適化問題を最後まで収束させない)</p></li>
<li><p>分類が上手くいかないデータが多い場合には、重み付け操作により、そのようなノイズデータに過剰適合しやすくなる</p></li>
</ol>
<p>という問題があるためであり、より高い精度を得るためには、ハイパーパラメータのチューニングが必要になってくる。</p>
</div>
</section>
<section id="id6">
<h3><span class="section-number">7.2.6. </span>勾配ブースティングによる分類<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>ブースティングの手法には勾配ブースティングと呼ばれる手法もある。AdaBoostでは、<span class="math notranslate nohighlight">\(f_{t-1}\)</span>で分類が上手くいっていないサンプルに<strong>重みを強くつける</strong>という方法で識別精度が上がるように補正を掛けていた。</p>
<p>勾配ブースティングは、<span class="math notranslate nohighlight">\(f_{t-1}\)</span>までの<strong>識別誤差</strong>を補正するように次の弱分類器<span class="math notranslate nohighlight">\(f_{t}\)</span>を学習する。言い換えると、各弱分類器は分類問題を解くのではなく、分類の誤差を補正するような<strong>勾配を予測する問題</strong>を解く。従って、勾配ブースティングは各弱分類器の予測を多数決で採用するのではなく、全ての弱分類器を統合した分類器<span class="math notranslate nohighlight">\(F_t\)</span>が一つの予測を返す。</p>
<p>勾配ブースティングの大まかな学習手順は以下のようになる。</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(F_1 = f_1\)</span>を訓練データ<span class="math notranslate nohighlight">\((\mathbf{x}_i, y_i)\)</span>から作成する。</p></li>
<li><p>現在の予測ベクトル<span class="math notranslate nohighlight">\(y_i^{(1)}\)</span>による誤差<span class="math notranslate nohighlight">\(L\)</span>の勾配
$<span class="math notranslate nohighlight">\(
r_i^{(1)} = -\frac{\partial L(y_i)}{\partial y_i}
\)</span>$
を計算する。</p></li>
<li><p>この残差<span class="math notranslate nohighlight">\(r_i^{(1)}\)</span>を最小化するように<span class="math notranslate nohighlight">\(f_2\)</span>を訓練データ<span class="math notranslate nohighlight">\((\mathbf{x}_i, r_i^{(1)}\)</span>により学習する。</p></li>
<li><p><span class="math notranslate nohighlight">\(f_2\)</span>により与えられる勾配の予測値<span class="math notranslate nohighlight">\(h_2\)</span>を用いて誤差が最も下がるステップ幅<span class="math notranslate nohighlight">\(\gamma\)</span>をラインサーチによって求める。</p></li>
<li><p><span class="math notranslate nohighlight">\(F_2(\mathbf{x}) = f_1(\mathbf{x}) + \gamma f_2(\mathbf{x})\)</span>と更新する。</p></li>
<li><p>以下、2.から5.のステップを新たな<span class="math notranslate nohighlight">\(f_t\)</span>に対して繰り返す。</p></li>
</ol>
<p>scikit-learnを用いた勾配ブースティングによる分類には<code class="docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code>を用いる。なお、勾配ブースティングは新たな弱分類器を学習するために、残差に対する回帰問題と、ラインサーチのステップを繰り返すため、AdaBoost等の他のブースティングのアルゴリズムに比べて多くの計算時間を要する。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="c1"># 訓練モデルの構築</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GradientBoostingClassifier(n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox" checked><label for="sk-estimator-id-9" class="sk-toggleable__label sk-toggleable__label-arrow">GradientBoostingClassifier</label><div class="sk-toggleable__content"><pre>GradientBoostingClassifier(n_estimators=10)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;gbst_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;gbst_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Gradient boosting&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Gradient boosting&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>結果: 勾配ブースティングによる分類</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">85.53</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">79.61</span>%</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title">最新の勾配ブースティング</p>
<p>現在、深層学習を用いない機械分類のアルゴリズムの中では勾配ブースティングの発展形が大きな成果を挙げている。その中には<strong>XGBoost</strong> <span id="id7">[<a class="reference internal" href="#id23" title="Tianqi Chen and Carlos Guestrin. XGBoost: a scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 785–794. ACM, aug 2016. doi:10.1145/2939672.2939785.">Chen and Guestrin, 2016</a>]</span> や<strong>LightGBM</strong> <span id="id8">[<a class="reference internal" href="#id24" title="Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. LightGBM: a highly efficient gradient boosting decision tree. Advances in Neural Information Processing Systems, 2017. URL: https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf.">Ke <em>et al.</em>, 2017</a>]</span>などがあり、いずれもscikit-learnと類似したインターフェースで利用が可能なので、興味がある読者はこれらのライブラリを試してみとともに、原著の論文についても、ぜひ目を通してほしい。</p>
</div>
</section>
<section id="ssec-support-vector-machine">
<span id="id9"></span><h3><span class="section-number">7.2.7. </span>サポートベクトルマシンによる分類<a class="headerlink" href="#ssec-support-vector-machine" title="Permalink to this heading">#</a></h3>
<p>サポートベクトルマシンは元々、2クラス分類に対して提案された手法で、<strong>サポートベクトル</strong>という境界線(より厳密には超平面)を2つのクラスに属するデータ集合から求める問題を解く。具体的には、データ空間の中で定義される超平面<span class="math notranslate nohighlight">\(\mathbf{a} \cdot \mathbf{x} + b=0\)</span>について、2つのクラスが<span class="math notranslate nohighlight">\(y_i \in \{ +1, -1 \}\)</span>のラベルを持つとして、以下の距離を最大化するような超平面のパラメータ<span class="math notranslate nohighlight">\((\mathbf{a}, b)\)</span>を求める。</p>
<p>点と超平面との距離<span class="math notranslate nohighlight">\(d(\mathbf{x}_i)\)</span>は、<span class="math notranslate nohighlight">\(y_i\)</span>の符号を考慮すると、</p>
<div class="math notranslate nohighlight">
\[
d(\mathbf{x}_i) = \frac{|\mathbf{a} \cdot \mathbf{x}_i + b|}{\| \mathbf{a} \|} = \frac{y_i (\mathbf{a} \cdot \mathbf{x}_i + b)}{\| \mathbf{a} \|}
\]</div>
<p>のように表せる。</p>
<p>このとき、サポートベクトルマシンでは、この距離を全てのサンプルに対して和を取るのではなく、サポートベクトルに最も近いサンプルまでの距離を最大化するように取るのがポイントで、このサポートベクトルまでの距離のことを「マージン」と呼ぶ。</p>
<p>従って、このマージンの値を<span class="math notranslate nohighlight">\(M\)</span>と置くと、解くべき最大化問題は、</p>
<div class="math notranslate nohighlight">
\[
\max_{M, \mathbf{a}, b} M \quad \text{s.t.} \quad \frac{y_i (\mathbf{a} \cdot \mathbf{x}_i + b)}{\| \mathbf{a} \|} \geq M \quad \text{for}~~i=1, \ldots, N
\]</div>
<p>のように書ける。問題を簡単にするために、目的関数と制約式の両方に<span class="math notranslate nohighlight">\(\frac{\| \mathbf{a} \|}{M}\)</span>を乗ずると、最大化問題は、以下のように書き直せる。</p>
<div class="math notranslate nohighlight">
\[
\max_{M, \mathbf{a}, b} \frac{1}{\| \mathbf{a} \|} \quad \text{s.t.} \quad y_i (\mathbf{a} \cdot \mathbf{x}_i + b) \geq 1 \quad \text{for}~~i=1, \ldots, N
\]</div>
<p>このとき、目的関数の最大化は<span class="math notranslate nohighlight">\(\| \mathbf{a} \|\)</span>の最小化とも見なせるので、適当な誤差関数として最小二乗誤差を取って以下のように書き直す (通常はHinge誤差が使われる)。</p>
<div class="math notranslate nohighlight">
\[
\min_{\mathbf{a}, b} \frac{1}{2} \| \mathbf{a} \|^2 \quad \text{s.t.} \quad y_i (\mathbf{a} \cdot \mathbf{x}_i + b) \geq 1 \quad \text{for}~~i=1, \ldots, N
\]</div>
<p>あとはこの問題をLagrangeの未定乗数法を用いて解けば良い。</p>
<p>上記の式にLagrangeの未定乗数法を適用してLagrange関数を求めると、
$<span class="math notranslate nohighlight">\(
\begin{aligned}
\mathcal{L}(\mathbf{a}, b, \boldsymbol{\lambda})
&amp;= \frac{1}{2} \| \mathbf{a} \|^2 - \boldsymbol{\lambda}^\top (\mathbf{y} \odot (\mathbf{X} \mathbf{a} + b \mathbf{1}) - \mathbf{1}) \\
&amp;= \frac{1}{2} \| \mathbf{a} \|^2 - \boldsymbol{\lambda}^\top (\mathbf{Y} \mathbf{X} \mathbf{a} + b \mathbf{y} - \mathbf{1})
\end{aligned}
\)</span><span class="math notranslate nohighlight">\(
のように書ける。ただし、\)</span>\mathbf{Y}<span class="math notranslate nohighlight">\(は\)</span>\mathbf{y}<span class="math notranslate nohighlight">\(の要素を対角成分に持つ対角成分である。この関数の勾配が0になる箇所を求めれば、所望の\)</span>(\mathbf{a}, b)$が得られるので、以下の連立方程式を解けば良い。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial \mathbf{a}} &amp;= \mathbf{a} - \mathbf{X}^\top \mathbf{Y}^\top \boldsymbol{\lambda} = \mathbf{0} \\
\frac{\partial \mathcal{L}}{\partial b} &amp;= -\boldsymbol{\lambda}^\top \mathbf{y} = 0 \\
\frac{\partial \mathcal{L}}{\partial \boldsymbol{\lambda}} &amp;= -\mathbf{Y} \mathbf{X} \mathbf{a} - b \mathbf{y} + \mathbf{1} = \mathbf{0}
\end{aligned}
\end{split}\]</div>
<p>この連立方程式は<span class="math notranslate nohighlight">\((\mathbf{a}, b, \boldsymbol{\lambda})\)</span>に対して線形になっており、以下のように書き直せる。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{pmatrix}
\mathbf{I} &amp; \mathbf{0} &amp; -\mathbf{X}^T \mathbf{Y}^T \\
\mathbf{0}^T &amp; 0 &amp; \mathbf{y}^T \\
\mathbf{YX} &amp; \mathbf{y} &amp; \mathbf{O}
\end{pmatrix}
\begin{pmatrix}
\mathbf{a} \\ b \\ \boldsymbol{\lambda}
\end{pmatrix} =
\begin{pmatrix}
\mathbf{0} \\ 0 \\ \mathbf{1}
\end{pmatrix}
\end{split}\]</div>
<hr class="docutils" />
<p>単純のために、二次元空間において、<span class="math notranslate nohighlight">\((-1, 0)\)</span>, <span class="math notranslate nohighlight">\((+1, 0)\)</span>の二点を中心とするガウス分布から2クラスのサンプルを抽出し、上記のLagrange関数を最小化してみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_size</span> <span class="o">=</span> <span class="mi">250</span>
<span class="n">X_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">cov</span><span class="o">=</span><span class="mf">0.05</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">data_size</span><span class="p">))</span>
<span class="n">y_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">data_size</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">X_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">cov</span><span class="o">=</span><span class="mf">0.05</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">data_size</span><span class="p">))</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">data_size</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="o">+</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">X_two_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">X_1</span><span class="p">,</span> <span class="n">X_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y_two_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y_1</span><span class="p">,</span> <span class="n">y_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$x_1$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$x_2$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/33f39939540af5f24f92b46e04f489d0135e8a1a7adec069bff9ab16e429c3f9.png" src="../../_images/33f39939540af5f24f92b46e04f489d0135e8a1a7adec069bff9ab16e429c3f9.png" />
</div>
</div>
<p>このサンプルデータに対して、上記の連立方程式を作成し、サポートベクトルとなる直線の方程式を求める。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">y_two_class</span><span class="p">)</span> <span class="o">@</span> <span class="n">X_two_class</span>
<span class="n">matA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">block</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="o">-</span><span class="n">YX</span><span class="o">.</span><span class="n">T</span><span class="p">],</span>
        <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">y_two_class</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]],</span>
        <span class="p">[</span><span class="n">YX</span><span class="p">,</span> <span class="n">y_two_class</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">y_two_class</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_two_class</span><span class="p">)))],</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">matB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">matA</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">matB</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">y_two_class</span><span class="p">)</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="n">ans</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">matA</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matA</span><span class="p">))</span> <span class="o">*</span> <span class="mf">1.0e-4</span><span class="p">,</span> <span class="n">matB</span><span class="p">)</span>
<span class="n">a_</span> <span class="o">=</span> <span class="n">ans</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">b_</span> <span class="o">=</span> <span class="n">ans</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>最後に、ここで求めた<code class="docutils literal notranslate"><span class="pre">a_</span></code>ならびに<code class="docutils literal notranslate"><span class="pre">b_</span></code>を使って、先ほどの散布図にサポートベクトルを描画してみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># サポートベクトルの端点を求める</span>
<span class="n">x_min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span>
<span class="n">y_min</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">a_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_min</span> <span class="o">+</span> <span class="n">b_</span><span class="p">)</span> <span class="o">/</span> <span class="n">a_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="o">+</span><span class="mi">5</span>
<span class="n">y_max</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">a_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_max</span> <span class="o">+</span> <span class="n">b_</span><span class="p">)</span> <span class="o">/</span> <span class="n">a_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># サポートベクトルの描画</span>
<span class="c1"># NOTE: 直線を描くとグラフの範囲がずれるので、直線を描く前の範囲を保存しておく</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$x_1$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$x_2$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axline</span><span class="p">((</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">),</span> <span class="p">(</span><span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/788438f89611bbb1b5a609a4002f961ca88b150db30543c0886b95591a87bd2b.png" src="../../_images/788438f89611bbb1b5a609a4002f961ca88b150db30543c0886b95591a87bd2b.png" />
</div>
</div>
<p>この通り、正しくサポートベクトルが求められていることが確認できる。なお、上記は二つのクラスラベルを持つサンプルがサポートベクトルの両側に分かれて存在することを仮定した最適化を行っている。</p>
<div class="admonition note">
<p class="admonition-title">注釈</p>
<p>実際のサンプルは、必ずしもサポートベクトルの両側にサンプルが分かれて存在する物ばかりではなく、分布が重なっている場合もあるので、その場合には、より複雑な最適化問題を解く必要がある。</p>
</div>
<hr class="docutils" />
<p>ここからはscikit-learnを使って、MNISTのデータを分類していく。多クラス分類の場合には、one-vs-one方式とone-vs-rest方式の二つの方式があり、それぞれ以下のような方法を指す。</p>
<ul class="simple">
<li><p><strong>one-vs-one方式:</strong> <span class="math notranslate nohighlight">\(K\)</span>個あるクラスの任意の2つのペアに対して2クラスSVMを学習させる。従って合計で<span class="math notranslate nohighlight">\(K(K-1)/2\)</span>個のSVMを学習する必要がある。</p></li>
<li><p><strong>one-vs-rest方式:</strong> <span class="math notranslate nohighlight">\(K\)</span>個あるクラスのうちの任意の1つを選び、そのクラスに属するか属さないかを2クラスSVMに学習させる。従って合計で<span class="math notranslate nohighlight">\(K\)</span>個のSVMを学習すれば良い。</p></li>
</ul>
<p>scikit-learnでSVMによる分類を行うには<code class="docutils literal notranslate"><span class="pre">SVC</span></code>クラスを用いるが、このコンストラクタには<code class="docutils literal notranslate"><span class="pre">decision_function_shape=...</span></code>というパラメータがあり、これが<code class="docutils literal notranslate"><span class="pre">&quot;ovr&quot;</span></code>(初期値)ならばone-vs-rest方式が、<code class="docutils literal notranslate"><span class="pre">&quot;ovo&quot;</span></code>ならばone-by-one方式が用いられる。</p>
<p>また、<code class="docutils literal notranslate"><span class="pre">SVC</span></code>のパラメータである<code class="docutils literal notranslate"><span class="pre">C=...</span></code>は、どの程度の割合でマージンを飛び越えるサンプルが出現しても良いかを調整しており、より大きな数を指定すると、決定境界の両側にサンプルが分かれるようなサポートベクトルを求める。</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="c1"># 訓練モデルの構築</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.0e-2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-6" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(kernel=&#x27;linear&#x27;, tol=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox" checked><label for="sk-estimator-id-10" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(kernel=&#x27;linear&#x27;, tol=0.01)</pre></div></div></div></div></div></div></div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;lsvm_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;lsvm_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Linear SVM&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Linear SVM&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>結果: 線形SVMによる分類</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">100.00</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">90.78</span>%</p></li>
</ul>
</section>
<section id="id10">
<h3><span class="section-number">7.2.8. </span>カーネル法を用いたサポートベクトルマシン<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
<p>ここまでの例では、分類対象が超平面により分割されることを仮定してきたが、実際の分布においては、必ずしも超平面で区切られる物ばかりではない。以下の例を見てほしい。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_circles</span>

<span class="n">X_circ</span><span class="p">,</span> <span class="n">y_circ</span> <span class="o">=</span> <span class="n">make_circles</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;$0$&quot;</span><span class="p">,</span> <span class="s2">&quot;$1$&quot;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_circ</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_circ</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_circ</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/2e62df10d0c03d33fdcb688916b87e5f7ceafbb6de597c854ef5789212a5f1b6.png" src="../../_images/2e62df10d0c03d33fdcb688916b87e5f7ceafbb6de597c854ef5789212a5f1b6.png" />
</div>
</div>
<p>このサンプルは、明らかに超平面(この場合は直線)では正しく二つのクラスを分割できないが、線形のSVMを学習して分類を行い、その予測結果に基づいて色づけを行うとどうなるだろうか。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.0e-2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_circ</span><span class="p">,</span> <span class="n">y_circ</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-7" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(kernel=&#x27;linear&#x27;, tol=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-11" type="checkbox" checked><label for="sk-estimator-id-11" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(kernel=&#x27;linear&#x27;, tol=0.01)</pre></div></div></div></div></div></div></div>
</div>
<p>scikit-learnには<code class="docutils literal notranslate"><span class="pre">DecisionBoundaryDisplay</span></code>という関数が用意されており、これを用いると、どの部分に決定境界があるのかを可視化することができるので、今回はこれを用いる。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>

<span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">clf</span><span class="p">,</span>
    <span class="n">X_circ</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">(),</span>
    <span class="n">colors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span>
    <span class="n">plot_method</span><span class="o">=</span><span class="s2">&quot;contour&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">linestyles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot;--&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_circ</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;$0$&quot;</span><span class="p">,</span> <span class="s2">&quot;$1$&quot;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_circ</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_circ</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/e71c924af0eacc137a032355870209d427eb6425f5d5bf0980bd3d0bbc645d57.png" src="../../_images/e71c924af0eacc137a032355870209d427eb6425f5d5bf0980bd3d0bbc645d57.png" />
</div>
</div>
<p>予想通り、線形のSVMでは正しく識別を行うことができておらず、不適切にサポートベクトルが与えられてしまっていることが分かる。</p>
<p>このような非線形の決定境界を持つようなモデルに対しては、カーネル法と呼ばれる方法でSVMを拡張する。これまで、サポートベクトルと点の間の距離は重み<span class="math notranslate nohighlight">\(\mathbf{a}\)</span>とサンプル<span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span>の内積<span class="math notranslate nohighlight">\(\mathbf{a}^T \mathbf{x}_i\)</span>を用いて計算されてきたが、これを<strong>カーネル関数</strong>といういくつかの数学的な性質を満たす関数によって置き換える。</p>
<p>本題に入る前に、<span class="math notranslate nohighlight">\(\mathbf{x}_i = (x_i, y_i)\)</span>を変形して<span class="math notranslate nohighlight">\((x_i, y_i, x_i^2 + y_i^2)\)</span>と置き換えたとしよう。すると、上記の2リングのサンプルの三次元プロットは以下のようになる。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s2">&quot;3d&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="n">elev</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;$0$&quot;</span><span class="p">,</span> <span class="s2">&quot;$1$&quot;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_circ</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">X_circ</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">X_circ</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X_circ</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/96f3dd7a6b45e9e7d7dbdc323116876064bec95f01556dcf124afff7327ed5bd.png" src="../../_images/96f3dd7a6b45e9e7d7dbdc323116876064bec95f01556dcf124afff7327ed5bd.png" />
</div>
</div>
<p>図から、何らかの変換により、次元を増やすことで、線形のSVMであっても上手く決定境界をきめることができそうであることが分かる。これがカーネル法の基本的なアイディアである。</p>
<p>例えば、多項式カーネルと呼ばれるカーネル関数:</p>
<div class="math notranslate nohighlight">
\[
k(\mathbf{x}_i, \mathbf{x}_j) = (a + \mathbf{x}_i^T \mathbf{x}_k)^n
\]</div>
<p>において、<span class="math notranslate nohighlight">\(a=1\)</span>, <span class="math notranslate nohighlight">\(n=2\)</span>とすると、</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
k(\mathbf{x}_i, \mathbf{x}_j) &amp;= (1 + x_i x_j + y_i y_j)^2 \\
&amp;= 1 + 2x_i x_j + 2y_i y_j + (x_i x_j)^2 + (y_i y_j)^2 + 2(x_i x_j) (y_i y_j) \\
&amp;= 1 + \sqrt{2}x_i \sqrt{2}x_j + \sqrt{2}y_i \sqrt{2}y_j + x_i^2 y_i^2 + x_j^2 y_j^2 + (\sqrt{2} x_i y_i) (\sqrt{2} x_j y_j) \\
&amp;= (1, \sqrt{2}x_i, \sqrt{2}y_i, x_i^2, y_i^2, \sqrt{2} x_i y_i) \cdot (1, \sqrt{2}x_j, \sqrt{2}y_j, x_j^2, y_j^2, \sqrt{2} x_j y_j)
\end{aligned}
\end{split}\]</div>
<p>のようになり、多項式カーネルが<span class="math notranslate nohighlight">\((1, \sqrt{2}x_i, \sqrt{2}y_i, x_i^2, y_i^2, \sqrt{2} x_i y_i)\)</span>のような高次元表現における内積に対応していることが分かる。</p>
<hr class="docutils" />
<p>「カーネル関数」は、上記の通り、何らかの高次元空間における内積を表わすように定義される。このような性質を満たすためには、カーネル関数<span class="math notranslate nohighlight">\(k\)</span>が<span class="math notranslate nohighlight">\(\mathbb{R}^d \times \mathbb{R}^d\)</span>から<span class="math notranslate nohighlight">\(\mathbb{R}\)</span>への写像であって、関数が<strong>半正定値性</strong>を持つ必要がある。</p>
<p>半正定値性、とは行列においては、任意のベクトルに対する二次形式が<strong>0以上</strong>になることを指す。より厳密には、行列<span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{d \times d}\)</span>が半正定値行列であるとは、</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^T \mathbf{A} \mathbf{x} \geq 0, \quad \forall \mathbf{x} \in \mathbb{R}^n
\]</div>
<p>を満たすことであり、上記の二次形式が<strong>0より大きい場合</strong> (<span class="math notranslate nohighlight">\(\mathbf{x}^T \mathbf{A} \mathbf{x} &gt; 0\)</span>の場合)は行列<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>が<strong>正定値</strong>であるという。</p>
<p>カーネル関数が半正定値である、というのも、これと類似しており、任意の<span class="math notranslate nohighlight">\(n \in \mathbb{N}\)</span>と、<span class="math notranslate nohighlight">\(\alpha_1, \ldots, \alpha_n \in \mathbb{R}\)</span>と<span class="math notranslate nohighlight">\(\mathbf{x}_1, \ldots, \mathbf{x}_n \in \mathbb{R}^d\)</span>について、以下の性質を満たすことを指す。</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^n \alpha_i \alpha_j k(\mathbf{x}_i, \mathbf{x}_j) \geq 0
\]</div>
<p>この性質が満たされるとき、以下のような行列<span class="math notranslate nohighlight">\(K \in \mathbb{R}^{n \times n}\)</span>を考える。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
K=\begin{pmatrix}
k(\mathbf{x}_1, \mathbf{x}_1) &amp; \cdots &amp; k(\mathbf{x}_n, \mathbf{x}_1) \\
\vdots &amp; \ddots &amp; \vdots \\
k(\mathbf{x}_1, \mathbf{x}_n) &amp; \cdots &amp; k(\mathbf{x}_n, \mathbf{x}_n)
\end{pmatrix}
\end{split}\]</div>
<p>この行列は、カーネル関数<span class="math notranslate nohighlight">\(k\)</span>の半正定値性から半正定値行列である。行列<span class="math notranslate nohighlight">\(K\)</span>は実対称行列であるので、固有値分解することにより、実数の固有値と互いに直交する実数の固有ベクトルが得られる。</p>
<div class="math notranslate nohighlight">
\[
K = \Phi \Lambda \Phi^T
\]</div>
<p>以上より、得られた固有ベクトル<span class="math notranslate nohighlight">\(\phi(\mathbf{x}_1), \ldots, \phi(\mathbf{x}_n)\)</span>がとある<span class="math notranslate nohighlight">\(n\)</span>次元空間の正規直交基底となることが分かる。</p>
<p>すると、任意の<span class="math notranslate nohighlight">\(\sqrt{\lambda_i} \phi(\mathbf{x}_i)\)</span>、<span class="math notranslate nohighlight">\(\sqrt{\lambda_j} \phi(\mathbf{x}_j)\)</span>の組み合わせについて、カーネル関数により内積が定義できることになる。ここで内積が定義できるためには、固有値の平方根が実数である必要があるため、カーネル関数の半正定値性が必要だったのである。</p>
<p>この関数<span class="math notranslate nohighlight">\(\phi\)</span>こそが、前述の例で示した高次元空間への写像<span class="math notranslate nohighlight">\((x, y) \mapsto (1, \sqrt{2} x, \sqrt{2}y, x^2, y^2, \sqrt{2} xy)\)</span>等に対応しており、カーネル法を用いたサポートベクトルマシンでは、元々<span class="math notranslate nohighlight">\(\mathbf{a}^T \mathbf{x} + b = 0\)</span>としていた直線の方程式をカーネル関数を用いて<span class="math notranslate nohighlight">\(k(\mathbf{a}, \mathbf{x}) + b = 0\)</span>と置き換えれば良い。</p>
<div class="admonition warning">
<p class="admonition-title">警告</p>
<p>上記は、数学的には厳密な議論ではなく、あくまで限られた<span class="math notranslate nohighlight">\(n\)</span>個のベクトル集合<span class="math notranslate nohighlight">\(\mathbf{x}_1, \ldots, \mathbf{x}_n\)</span>について、カーネル関数が内積を定義するような高次元空間への写像<span class="math notranslate nohighlight">\(\phi\)</span>が存在することを直感的に分かるように説明した。</p>
<p>より厳密な議論のためには、カーネル関数の連続性や二乗可積分性などの性質が必要になるが、これらの議論は別の専門書に譲ることとする。一例として、以下の教科書が詳しい。</p>
<p>赤穂 昭太郎 著、『カーネル多変量解析 -非線形データ解析の新しい展開-』、岩波書店、2008年</p>
</div>
<hr class="docutils" />
<p>カーネル関数の例としては、前述の多項式カーネルの他、RBF (radial basis function)カーネル、シグモイドカーネルなどがよく使われる。</p>
<ul class="simple">
<li><p>多項式カーネル: <span class="math notranslate nohighlight">\(k(\mathbf{x}_i, \mathbf{x}_j) = (c + \gamma \mathbf{x}_i^\top \mathbf{x}_j)^n\)</span></p></li>
<li><p>RBFカーネル: <span class="math notranslate nohighlight">\(k(\mathbf{x}_i, \mathbf{x}_j) = \exp(-\gamma \| \mathbf{x}_i - \mathbf{x}_j \|^2)\)</span></p></li>
<li><p>シグモイドカーネル: <span class="math notranslate nohighlight">\(k(\mathbf{x}_i, \mathbf{x}_j) = \tanh (\gamma \mathbf{x}_i^\top \mathbf{x}_j + c)\)</span></p></li>
<li><p>コサインカーネル: <span class="math notranslate nohighlight">\(k(\mathbf{x}_i, \mathbf{x}_j) = \frac{\mathbf{x}_i^\top \mathbf{x}_j}{\| \mathbf{x}_i \| \| \mathbf{x}_j \|}\)</span></p></li>
<li><p>カイ二乗カーネル: <span class="math notranslate nohighlight">\(k(\mathbf{x}_i, \mathbf{x}_j) = \exp\left( -\gamma \sum_{k=1}^d \frac{(x_{i, k} - x_{j, k})^2}{x_{i, k} - x_{j, k}} \right)\)</span></p></li>
</ul>
<p>なお、これらのカーネル関数に対応する<span class="math notranslate nohighlight">\(\phi\)</span>は必ずしも解析的に書けるものばかりではなく、多項式カーネルは各次元が元のベクトルの要素からなる単項式となっており、RBFカーネルについては、元のベクトルのHermite多項式 (無限級数)となることが知られている。</p>
<p>以下では、先ほどの2リングのサンプルについて、RBFカーネルを用いたサポートベクトルマシンを試してみる。なお、上記のカーネル関数のリストにおいて<span class="math notranslate nohighlight">\(c\)</span>と書いたパラメータは<code class="docutils literal notranslate"><span class="pre">SVC</span></code>においては<code class="docutils literal notranslate"><span class="pre">coef0=...</span></code> (初期値は0)で、<span class="math notranslate nohighlight">\(\gamma\)</span>と書いたパラメータは<code class="docutils literal notranslate"><span class="pre">gamma=...</span></code>によって指定することができる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.0e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_circ</span><span class="p">,</span> <span class="n">y_circ</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-8" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(gamma=0.5, max_iter=20, tol=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-12" type="checkbox" checked><label for="sk-estimator-id-12" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(gamma=0.5, max_iter=20, tol=0.0001)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">clf</span><span class="p">,</span>
    <span class="n">X_circ</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">(),</span>
    <span class="n">colors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span>
    <span class="n">plot_method</span><span class="o">=</span><span class="s2">&quot;contour&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">linestyles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot;--&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_circ</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;$0$&quot;</span><span class="p">,</span> <span class="s2">&quot;$1$&quot;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_circ</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_circ</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/e7aa8530e3531176db123d29f88783e2b14eef426819769beda1f5ceb6355d07.png" src="../../_images/e7aa8530e3531176db123d29f88783e2b14eef426819769beda1f5ceb6355d07.png" />
</div>
</div>
<p>図の通り、カーネル関数を用いることにより、必ずしも超平面では分割できないような対象に対しても、正しく分類ができていることが分かる。</p>
<hr class="docutils" />
<p>カーネル関数の効果が確認できたところで、MNISTの分類にこれを利用してみる。プログラムは先ほどからほとんど変更する必要はない。</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練モデルの構築</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.0e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;ksvm_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;ksvm_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Kernel SVM&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Kernel SVM&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>結果: カーネルSVMによる分類</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">82.26</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">81.21</span>%</p></li>
</ul>
<p>すると、カーネル法を用いたSVMが線形SVMよりも精度が劣っていることが分かる。特にRBFを用いることで訓練の精度は上がっているが、過学習が起こり、テストデータに対する精度が大幅に低下していることが分かるだろう。</p>
</section>
<section id="id11">
<h3><span class="section-number">7.2.9. </span>ここまでの手法の比較<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h3>
<p>最後にここまでの手法をグラフで比較すると、以下のようになる。手法選びの参考にしてほしい。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Method&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Phase&quot;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">result_df</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">errwidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar_label</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">105</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/f6cdb5cf00c99a6e97a8a01f44806dd227e418557dcce1fb75c3066ca1a6a1e2.png" src="../../_images/f6cdb5cf00c99a6e97a8a01f44806dd227e418557dcce1fb75c3066ca1a6a1e2.png" />
</div>
</div>
</section>
</section>
<section id="id12">
<h2><span class="section-number">7.3. </span>ハイパーパラメータの調整<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h2>
<p>上記のサポートベクトルマシンの例では、おそらくテストデータに対する判別性能がそれほど高くならないはずである。カーネル法を用いたサポートベクトルマシンは強力で、線形SVMよりも高い性能を出すことが可能だが、ハイパーパラメータの設定によっては、訓練データに過剰適合するなどして、パフォーマンスが上がらないことがある。</p>
<p>このような時には、何らかの方法で適切なハイパーパラメータ (SVMの例では<code class="docutils literal notranslate"><span class="pre">C</span></code>や<code class="docutils literal notranslate"><span class="pre">gamma</span></code>)を見つける必要がある。</p>
<section id="id13">
<h3><span class="section-number">7.3.1. </span>ホールドアウト検証<a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h3>
<p>広く用いられるハイパーパラメータの決定法はデータセットを訓練、検証、テストの三つのデータに分けて、検証用データに対するパフォーマンスが高くなるようなハイパーパラメータを設定する方法である。このような方法を<strong>ホールドアウト検証</strong>と呼ぶ。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># データセットを3つに分割</span>
<span class="c1"># 訓練: 50000, 検証: 10000, テスト: 10000</span>
<span class="n">X</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_org</span><span class="p">,</span> <span class="n">y_org</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mi">60000</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># 計算量を落とすため、訓練データの数を絞る</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">],</span> <span class="n">y</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
<span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">X_val</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">],</span> <span class="n">y_val</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">],</span> <span class="n">y_test</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>検証用のデータが用意できたら、検証するハイパーパラメータの範囲を設定し、グリッドサーチと呼ばれる方法で、あらゆる組み合わせのパラメータについて検証用データに対する性能を比較する。ハイパーパラメータの組み合わせの中で、検証用データに対する性能が高かったものを最終的なパラメータとして設定する。</p>
<p>なお、グリッドサーチはハイパーパラメータの組み合わせ数によっては、非常に時間がかかるため、モデルの訓練に必要な最適化の繰り返し回数(<code class="docutils literal notranslate"><span class="pre">max_iter</span></code>)や許容誤差(<code class="docutils literal notranslate"><span class="pre">tol</span></code>)を甘めに設定しておくと良い。</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="c1"># グリッドサーチによる最適パラメータを探索</span>
<span class="n">max_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">C_range</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]</span>
<span class="n">gamma_range</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="n">C_range</span><span class="p">,</span> <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="n">gamma_range</span><span class="p">}</span>
<span class="n">gs_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">param_grid</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">]))</span>

<span class="n">best_index</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">param_sets</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">param_sets</span><span class="p">)):</span>
    <span class="n">param_dict</span> <span class="o">=</span> <span class="p">{</span><span class="nb">list</span><span class="p">(</span><span class="n">param_grid</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="n">i</span><span class="p">]:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">params</span><span class="p">)}</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.0e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="o">**</span><span class="n">param_dict</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># 精度の計算</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
    <span class="n">acc_val</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_val</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_val</span><span class="p">)</span>

    <span class="c1"># データを追加</span>
    <span class="n">new_row</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">param_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">new_row</span><span class="p">[</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc_val</span>
    <span class="n">gs_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">gs_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">new_row</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="c1"># ベスト・パラメータの更新</span>
    <span class="k">if</span> <span class="n">max_acc</span> <span class="o">&lt;</span> <span class="n">acc_val</span><span class="p">:</span>
        <span class="n">best_index</span> <span class="o">=</span> <span class="n">i</span>
        <span class="n">max_acc</span> <span class="o">=</span> <span class="n">acc_val</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="n">param_dict</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "6d49d1bbba054461badc7d7083fb2c2f", "version_major": 2, "version_minor": 0}</script></div>
</details>
</div>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_e182a_row3_col0, #T_e182a_row3_col1, #T_e182a_row3_col2 {
  background-color: pink;
  font-weight: bold;
}
</style>
<table id="T_e182a">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_e182a_level0_col0" class="col_heading level0 col0" >C</th>
      <th id="T_e182a_level0_col1" class="col_heading level0 col1" >gamma</th>
      <th id="T_e182a_level0_col2" class="col_heading level0 col2" >Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_e182a_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_e182a_row0_col0" class="data row0 col0" >0.010000</td>
      <td id="T_e182a_row0_col1" class="data row0 col1" >0.100000</td>
      <td id="T_e182a_row0_col2" class="data row0 col2" >62.950000</td>
    </tr>
    <tr>
      <th id="T_e182a_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_e182a_row1_col0" class="data row1 col0" >0.010000</td>
      <td id="T_e182a_row1_col1" class="data row1 col1" >1.000000</td>
      <td id="T_e182a_row1_col2" class="data row1 col2" >71.400000</td>
    </tr>
    <tr>
      <th id="T_e182a_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_e182a_row2_col0" class="data row2 col0" >0.010000</td>
      <td id="T_e182a_row2_col1" class="data row2 col1" >10.000000</td>
      <td id="T_e182a_row2_col2" class="data row2 col2" >76.900000</td>
    </tr>
    <tr>
      <th id="T_e182a_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_e182a_row3_col0" class="data row3 col0" >1.000000</td>
      <td id="T_e182a_row3_col1" class="data row3 col1" >0.100000</td>
      <td id="T_e182a_row3_col2" class="data row3 col2" >82.940000</td>
    </tr>
    <tr>
      <th id="T_e182a_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_e182a_row4_col0" class="data row4 col0" >1.000000</td>
      <td id="T_e182a_row4_col1" class="data row4 col1" >1.000000</td>
      <td id="T_e182a_row4_col2" class="data row4 col2" >70.540000</td>
    </tr>
    <tr>
      <th id="T_e182a_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_e182a_row5_col0" class="data row5 col0" >1.000000</td>
      <td id="T_e182a_row5_col1" class="data row5 col1" >10.000000</td>
      <td id="T_e182a_row5_col2" class="data row5 col2" >77.000000</td>
    </tr>
    <tr>
      <th id="T_e182a_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_e182a_row6_col0" class="data row6 col0" >100.000000</td>
      <td id="T_e182a_row6_col1" class="data row6 col1" >0.100000</td>
      <td id="T_e182a_row6_col2" class="data row6 col2" >79.910000</td>
    </tr>
    <tr>
      <th id="T_e182a_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_e182a_row7_col0" class="data row7 col0" >100.000000</td>
      <td id="T_e182a_row7_col1" class="data row7 col1" >1.000000</td>
      <td id="T_e182a_row7_col2" class="data row7 col2" >48.500000</td>
    </tr>
    <tr>
      <th id="T_e182a_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_e182a_row8_col0" class="data row8 col0" >100.000000</td>
      <td id="T_e182a_row8_col1" class="data row8 col1" >10.000000</td>
      <td id="T_e182a_row8_col2" class="data row8 col2" >69.760000</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>最適なパラメータが決定できたら、繰り返し回数や許容誤差を正しく設定して、再度モデルを学習する。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 最適パラメータでの再学習</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.0e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">best_params</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-10" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(gamma=0.1, max_iter=100, tol=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-14" type="checkbox" checked><label for="sk-estimator-id-14" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(gamma=0.1, max_iter=100, tol=0.0001)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;ho_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;ho_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Holdout K-SVM&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Holdout K-SVM&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>結果: ホールドアウト検証の結果</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">99.94</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">95.70</span>%</p></li>
</ul>
<p>この通り、ホールドアウト検証を実行したことで、より高い分類精度が得られていることが分かる。</p>
</section>
<section id="id14">
<h3><span class="section-number">7.3.2. </span>交差検証 (クロス・バリデーション)<a class="headerlink" href="#id14" title="Permalink to this heading">#</a></h3>
<p>もう一つのよく用いられるハイパーパラメータの調整方法に交差検証(クロス・バリデーション)がある。交差検証は訓練データをいくつかのグループに分けて、そのグループのうち1つを除いたデータを訓練に用い、除いておいた1グループを検証に用いる、というものである。</p>
<p>交差検証は、グループが<span class="math notranslate nohighlight">\(G\)</span>個あるとき、1つのパラメータセットについて<span class="math notranslate nohighlight">\(G\)</span>回の訓練と<span class="math notranslate nohighlight">\(G\)</span>回の検証が必要になるため、非常に計算量が大きい。</p>
<p>ここでは、scikit-learnに用意されている<code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> (grid search cross validation)を用いて交差検証によるハイパーパラメータ調整を試してみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">C_range</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]</span>
<span class="n">gamma_range</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="n">C_range</span><span class="p">,</span> <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="n">gamma_range</span><span class="p">}</span>

<span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.0e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ret</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 4 folds for each of 9 candidates, totalling 36 fits
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">ret</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="mi">4</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;params&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>param_C</th>
      <th>param_gamma</th>
      <th>split0_test_score</th>
      <th>split1_test_score</th>
      <th>split2_test_score</th>
      <th>split3_test_score</th>
      <th>mean_test_score</th>
      <th>std_test_score</th>
      <th>rank_test_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.01</td>
      <td>0.1</td>
      <td>0.6940</td>
      <td>0.7104</td>
      <td>0.6580</td>
      <td>0.7060</td>
      <td>0.6921</td>
      <td>0.020582</td>
      <td>7</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.01</td>
      <td>1.0</td>
      <td>0.7144</td>
      <td>0.7652</td>
      <td>0.7084</td>
      <td>0.6844</td>
      <td>0.7181</td>
      <td>0.029419</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.01</td>
      <td>10.0</td>
      <td>0.7724</td>
      <td>0.7740</td>
      <td>0.7652</td>
      <td>0.7572</td>
      <td>0.7672</td>
      <td>0.006657</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>0.1</td>
      <td>0.8216</td>
      <td>0.8624</td>
      <td>0.7596</td>
      <td>0.8016</td>
      <td>0.8113</td>
      <td>0.037028</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.7588</td>
      <td>0.7100</td>
      <td>0.6520</td>
      <td>0.6156</td>
      <td>0.6841</td>
      <td>0.054712</td>
      <td>8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.0</td>
      <td>10.0</td>
      <td>0.7732</td>
      <td>0.7756</td>
      <td>0.7668</td>
      <td>0.7576</td>
      <td>0.7683</td>
      <td>0.006965</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>100.0</td>
      <td>0.1</td>
      <td>0.7724</td>
      <td>0.7424</td>
      <td>0.7876</td>
      <td>0.7508</td>
      <td>0.7633</td>
      <td>0.017793</td>
      <td>4</td>
    </tr>
    <tr>
      <th>7</th>
      <td>100.0</td>
      <td>1.0</td>
      <td>0.4260</td>
      <td>0.4212</td>
      <td>0.4420</td>
      <td>0.3448</td>
      <td>0.4085</td>
      <td>0.037575</td>
      <td>9</td>
    </tr>
    <tr>
      <th>8</th>
      <td>100.0</td>
      <td>10.0</td>
      <td>0.7072</td>
      <td>0.7016</td>
      <td>0.6968</td>
      <td>0.6688</td>
      <td>0.6936</td>
      <td>0.014784</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1.0e-4</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">ret</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-11" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(gamma=0.1, max_iter=100, tol=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-15" type="checkbox" checked><label for="sk-estimator-id-15" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(gamma=0.1, max_iter=100, tol=0.0001)</pre></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 訓練時の識別精度の確認</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;cv_acc_train&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># テストデータに対する識別精度の計算</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;cv_acc_test&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 結果をDataFrameに追加</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;CV K-SVM&quot;</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="s2">&quot;Train&quot;</span><span class="p">]</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">result_df</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;CV K-SVM&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="s2">&quot;Test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p><strong>結果: 交差検証の結果</strong></p>
<ul class="simple">
<li><p>訓練時精度: <span class="pasted-text">99.94</span>%</p></li>
<li><p>評価時精度: <span class="pasted-text">95.70</span>%</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">fil</span> <span class="o">=</span> <span class="n">result_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&quot;SVM&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Method&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Phase&quot;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">result_df</span><span class="p">[</span><span class="n">fil</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">errwidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ax</span><span class="o">.</span><span class="n">containers</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar_label</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">105</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">borderpad</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ee8bac6d34cf9f72c425a232e43a84911ed7766ceab97673d1b475517be677b3.png" src="../../_images/ee8bac6d34cf9f72c425a232e43a84911ed7766ceab97673d1b475517be677b3.png" />
</div>
</div>
</section>
</section>
<section id="id15">
<h2><span class="section-number">7.4. </span>学習済みデータの保存<a class="headerlink" href="#id15" title="Permalink to this heading">#</a></h2>
<p>ハイパーパラメータの調整が完了したら、学習済みのモデルをファイルに保存し、再学習なしで、テストに入れるようにしておこう。</p>
<p>通常、モデルは複数のパラメータから構成されており、これらをファイルに保存できるような「文字列」や「バイト列」の集合に変換する操作を<strong>シリアライズ</strong>と呼ぶ。また、このようなシリアライズを行うプログラムを<strong>シリアライザ</strong>と呼ぶ。</p>
<p>Pythonで標準使用できるシリアライザには<code class="docutils literal notranslate"><span class="pre">pickle</span></code>がある。<code class="docutils literal notranslate"><span class="pre">pickle</span></code>はPythonの標準的なオブジェクト (例えば<code class="docutils literal notranslate"><span class="pre">list</span></code>や<code class="docutils literal notranslate"><span class="pre">dict</span></code>や、その他のオブジェクト)をシリアライズしたバイトデータを作成してくれるので、それをファイルに保存すれば良い。</p>
<p>先ほどハイパーパラメータを調整したSVMのモデルを保存し、それを再度読み込んで精度が保たれていることを確認してみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># バイト列を得る</span>
<span class="n">serials</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>

<span class="c1"># バイト列の確認 (長いので最初の10バイトのみ確認)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">serials</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b&#39;\x80\x04\x95\xd00\x00\x00\x00\x00\x00&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ファイルへの保存</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;rbf_svm.pickle&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">serials</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 再読み込みとテスト</span>
<span class="n">clf2</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;rbf_svm.pickle&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">clf2</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>

<span class="n">acc_test</span> <span class="o">=</span> <span class="n">clf2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CV: acc(test)=</span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CV: acc(test)=0.96%
</pre></div>
</div>
</div>
</div>
<p>このように、保存しておいたファイルから全く同じテスト精度が得られることが確認できた。</p>
</section>
<section id="id16">
<h2><span class="section-number">7.5. </span>分類問題の評価方法<a class="headerlink" href="#id16" title="Permalink to this heading">#</a></h2>
<p>ここまで、分類の精度を「どの程度正しく分類ができたか」について評価してきたが、この評価方法は必ずしも、分類器の性能を正しく評価するとは言い切れない。例えば、数字の識別問題において、データセットに含まれる数字の90%が0で、残りの10%が1-9であったとする。</p>
<p>この場合、識別器がどんな画像が入力されても「0」だと認識するようになれば、90%の識別精度が得られることになるが、これは全ての数字を正しく識別しているとは言いがたい。</p>
<section id="id17">
<h3><span class="section-number">7.5.1. </span>2クラス分類の場合<a class="headerlink" href="#id17" title="Permalink to this heading">#</a></h3>
<p>多クラス識別の問題について考える前に、2クラスの分類問題について考えてみる。例えば、とあるデータからある人が病気なのか、そうでないのかを識別するとしよう。</p>
<p>この場合、以下の4つの場合が考えられる。</p>
<ul class="simple">
<li><p>正陽性 (true positive): 病気の人を、正しく病気と判別した</p></li>
<li><p>偽陽性 (false positive): 病気でない人を、間違って病気と判別した</p></li>
<li><p>正陰性 (true negative): 病気でない人を、正しく病気と判別した</p></li>
<li><p>偽陰性 (false negative: 病気の人を、間違って病気でないと判別した</p></li>
</ul>
<p>表にまとめると、以下のようになる。</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<table style="width: 80%;">
    <thead>
        <tr>
            <th></th>
            <th></th>
            <th style="text-align:center;" colspan="2">正解</td>
        </tr>
    </thead>
    <tr>
        <td style="width: 25%; text-align: center;"></td>
        <td style="width: 25%; text-align: center;"></td>
        <td style="width: 25%; text-align: center;">病気である</td>
        <td style="width: 25%; text-align: center;">病気でない</td>
    </tr>
    <tr>
        <td rowspan="2" style="background: white; text-align: center;">
            <span style="font-weight: bold;">予想</span>
        </td>
        <td style="width: 25%; text-align: center;">病気である</td>
        <td style="width: 25%; text-align: center;">正陽性 (TP)</td>
        <td style="width: 25%; text-align: center;">偽陽性 (FP)</td>
    </tr>
    <tr>
        <td style="width: 25%; text-align: center;">病気でない</td>
        <td style="width: 25%; text-align: center;">偽陰性 (FN)</td>
        <td style="width: 25%; text-align: center;">偽陽性 (TN)</td>
    </tr>
</table>
</div></div>
</div>
<p>この表記を用いた場合、ここまで用いてきた「精度 (Accuracy)」は以下のように定義できる。</p>
<div class="math notranslate nohighlight">
\[
\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}
\]</div>
<p>この精度は前述の通り、データに偏りがある場合には必ずしも正しい評価指標とは言えない。多くの場合、病気である人と、病気でない人は病気でない人の方が多数派だと考えられる。仮に分類器が全ての人に対して「病気でない」と判別したとすれば、かなり高い精度が得られるが、これは分類器としては失格で、本来見つけたい病気の人を見つけることができない。</p>
<p>精度の問題を解決する考え方には、<strong>適合率</strong>(precision)と<strong>再現率</strong>(recall)がある。</p>
<p>適合率とは、正しい識別が行えたもの(正陽性 (TP)と正陰性 (FN)の和)に対する正陽性(TP)の割合を指し、識別すべき対象をどれだけ正しく分類できたかを表す。</p>
<div class="math notranslate nohighlight">
\[
\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{TN}}
\]</div>
<p>再現性とは、陽性であると識別したもの(正陽性 (TP)と偽陽性 (FP)の和)に対する正陽性(TP)の割合を指し、陽性であると判別された人が、本当はどの程度の割合で陽性なのかを表わす。</p>
<div class="math notranslate nohighlight">
\[
\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FP}}
\]</div>
<p>適合率と再現度を用いる場合、全ての人を病気でない、と分類する分類器はPrecision, Recallともに0となることが分かるので改善が必要である。</p>
<p>一方で、仮に識別器が全ての人を病気である、と分類すればPrecisionは1になる一方、仮に病気になる人の割合が1%であれば、TPが全体の1%, FPが全体の99%となるのでRecallは0.01となる。従って、このような分類器も適合率・再現率の観点からは適切な分類器とは言えない。</p>
<p>実際のところ、適合率と再現率は互いに相反する関係にあり、適合率を上げるように意図的に判別を偏らせれば再現率が下がり、逆に再現率を上げるように意図的に判別を偏らせれば適合率が下がる。よって、両者がバランス良く高いことを示す指標としてF1値がある。</p>
<p>F1値は適合率と再現率の調和平均 (「逆数の平均」の逆数)によって、以下のように表せる。</p>
<div class="math notranslate nohighlight">
\[
\text{F}_1 = \left[ \frac{1}{2} \left( \frac{1}{\text{Accuracy}} + \frac{1}{\text{Recall}} \right) \right]^{-1} = \frac{2 \cdot \text{Accuracy} \cdot \text{Recall}}{\text{Accuracy} + \text{Recall}}
\]</div>
<p>この指標は適合率と再現率の両方が1に近い時に、より1に近い値を取るような指標で、適合率のみ、再現率のみを用いた評価の問題点を上手く解決している。</p>
<div class="admonition note">
<p class="admonition-title">注釈</p>
<p>F1値の名前にある「1」は適合率と再現率を等しい重要度として評価していることを示している。F1値を適合率の重要度を係数<span class="math notranslate nohighlight">\(\beta^2\)</span>で重み付けして、調和平均を取った指標に<span class="math notranslate nohighlight">\(F_\beta\)</span>値がある。<span class="math notranslate nohighlight">\(F_\beta\)</span>値は次の式で表せる。</p>
<div class="math notranslate nohighlight">
\[
\text{F}_\beta = \left[ \frac{1}{1 + \beta^2} \left( \beta^2 \frac{1}{\text{Accuracy}} + \frac{1}{\text{Recall}} \right) \right]^{-1} = \frac{(1 + \beta^2) \cdot \text{Accuracy} \cdot \text{Recall}}{\beta^2 \text{Accuracy} + \text{Recall}}
\]</div>
</div>
</section>
<section id="id18">
<h3><span class="section-number">7.5.2. </span>多クラス分類の場合<a class="headerlink" href="#id18" title="Permalink to this heading">#</a></h3>
<p>多クラス分類に対しても、精度(accuracy)、適合率(precision)、再現率(recall)、ならびにF1値と類似した指標を計算することができる。</p>
<p>本題に入る前に、先ほど学習しておいたSVMの性能を、混合行列により可視化してみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/85ef2b79a14b22119f355cc02f9b6cbd77598ac30fa9134696ee13da76058364.png" src="../../_images/85ef2b79a14b22119f355cc02f9b6cbd77598ac30fa9134696ee13da76058364.png" />
</div>
</div>
<p>上記の混同行列は、2クラス分類の場合に示した2x2の表を拡張したものである。混同行列の各行を横に見ると、例えば0と判別したもののうち、実際に0で合ったものの割合が計算でき、これが再現率(recall)に対応する。反対に、混同行列の各列を縦に見ると正解が0であったもののうち、正しく0と分類した物の割合を計算でき、これが適合率(precision)に対応する。</p>
<p>ここで<span class="math notranslate nohighlight">\(K\)</span>クラスの識別問題に対する混同行列を<span class="math notranslate nohighlight">\(\mathbf{C} \in \mathbb{R}^{K \times K}\)</span>と表わす。すると、各クラス<span class="math notranslate nohighlight">\(k \in \{ 1, \ldots, K \}\)</span>に対する適合率<span class="math notranslate nohighlight">\(P_k\)</span>と再現率<span class="math notranslate nohighlight">\(R_k\)</span>ならびにF1値<span class="math notranslate nohighlight">\(F_k\)</span>は以下の式で計算できる。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
P_k &amp;= \frac{C_{kk}}{\sum_{i=1}^{K} C_{ik}} \\
R_k &amp;= \frac{C_{kk}}{\sum_{i=1}^{K} C_{ki}} \\
F_k &amp;= \frac{2 P_k R_k}{P_k + R_k}
\end{align*}
\end{split}\]</div>
<p>このように、各クラスに対して計算された指標をクラス全体で平均した指標を<strong>マクロ平均</strong>と呼び、以下のように定義できる。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\text{macro-Precision} &amp;= \frac{1}{K} \sum_{k=1}^K P_k \\
\text{marco-Recall} &amp;= \frac{1}{K} \sum_{k=1}^K R_k \\
\text{marco-F}_1 &amp;= \frac{1}{K} \sum_{k=1}^K F_k
\end{align*}
\end{split}\]</div>
<p>一方で、マクロ平均は、病気の例の時と同様に、各クラスに属するサンプル数に偏りがある場合には、よりサンプル数が多いクラスの識別結果から強く影響を受けることになる。</p>
<p>そこで、クラスの違いを考慮せずに適合率、再現率であるマイクロ平均を以下のように計算する (結果的には同じ値になるが、考え方として分母の<span class="math notranslate nohighlight">\(\mathbf{C}\)</span>に対する添え字<span class="math notranslate nohighlight">\(k\)</span>と<span class="math notranslate nohighlight">\(l\)</span>の順序が異なる)。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\text{micro-Precision} &amp;= \frac{\sum_{k=1}^K C_{kk}}{\sum_{k=1}^K \sum_{l=1}^K C_{lk}} \\
\text{micro-Recall} &amp;= \frac{\sum_{k=1}^K C_{kk}}{\sum_{k=1}^K \sum_{l=1}^K C_{kl}}
\end{align*}
\end{split}\]</div>
<p>このように、マイクロ平均では、適合率も再現率も同じ値になるので、F1値のマイクロ平均も同じ値になる。</p>
<p>これらの値をscikit-learnを用いて計算してみよう。先ほどは分類器を<code class="docutils literal notranslate"><span class="pre">ConfusionMatrixDisplay</span></code>に渡して、直接、混同行列を可視化していたが<code class="docutils literal notranslate"><span class="pre">confusion_matrix</span></code>関数を用いると、行列の値を取り出すことができる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># 混同行列の計算</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># マクロ平均の計算</span>
<span class="n">P_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">C</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">R_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">C</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">F_k</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">P_k</span> <span class="o">*</span> <span class="n">R_k</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">P_k</span> <span class="o">+</span> <span class="n">R_k</span><span class="p">)</span>
<span class="n">macro_P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">P_k</span><span class="p">)</span>
<span class="n">macro_R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">R_k</span><span class="p">)</span>
<span class="n">macro_F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">F_k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
</div>
<p><strong>結果: マクロ平均の値</strong></p>
<ul class="simple">
<li><p>macro-P: <span class="pasted-text">0.957</span></p></li>
<li><p>macro-R: <span class="pasted-text">0.956</span></p></li>
<li><p>macro-F: <span class="pasted-text">0.956</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># マイクロ平均の計算</span>
<span class="n">micro_avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">C</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove-input docutils container">
</div>
<p><strong>結果: マイクロ平均の値</strong></p>
<ul class="simple">
<li><p>maicro-avg: <span class="pasted-text">0.957</span></p></li>
</ul>
</section>
</section>
<section id="id19">
<h2><span class="section-number">7.6. </span>練習問題<a class="headerlink" href="#id19" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>マクロ平均ならびにマイクロ平均を用いて、本節で紹介した分類手法の性能を比較せよ。</p></li>
<li><p>scikit-learnの<code class="docutils literal notranslate"><span class="pre">SVC</span></code>には<code class="docutils literal notranslate"><span class="pre">kernel=...</span></code>の引数に直接カーネル関数を渡すことができる。これを用いて、コサイン・カーネルならびにカイ二乗カーネルについて性能を評価せよ。</p></li>
</ol>
</section>
<section id="id20">
<h2><span class="section-number">7.7. </span>参考文献<a class="headerlink" href="#id20" title="Permalink to this heading">#</a></h2>
<div class="docutils container" id="id21">
<dl class="citation">
<dt class="label" id="id23"><span class="brackets"><a class="fn-backref" href="#id7">CG16</a></span></dt>
<dd><p>Tianqi Chen and Carlos Guestrin. XGBoost: a scalable tree boosting system. In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 785–794. ACM, aug 2016. <a class="reference external" href="https://doi.org/10.1145/2939672.2939785">doi:10.1145/2939672.2939785</a>.</p>
</dd>
<dt class="label" id="id24"><span class="brackets"><a class="fn-backref" href="#id8">KMF+17</a></span></dt>
<dd><p>Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. LightGBM: a highly efficient gradient boosting decision tree. <em>Advances in Neural Information Processing Systems</em>, 2017. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf</a>.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./contents/sec1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="figure-detection.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">前へ</p>
        <p class="prev-next-title"><span class="section-number">6. </span>図形の検出</p>
      </div>
    </a>
    <a class="right-next"
       href="exercise-sudoku.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">次へ</p>
        <p class="prev-next-title"><span class="section-number">8. </span>演習1 - 画像入力式数独ソルバーを作る</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> 目次
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification">7.1. 分類問題 (classification)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">7.2. データのスケーリング</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">7.2.1. 最近傍探索による分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">7.2.2. ロジスティック回帰による分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">7.2.3. バギングによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">7.2.4. ランダム・フォレストによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaboost">7.2.5. AdaBoostによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">7.2.6. 勾配ブースティングによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ssec-support-vector-machine">7.2.7. サポートベクトルマシンによる分類</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">7.2.8. カーネル法を用いたサポートベクトルマシン</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">7.2.9. ここまでの手法の比較</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">7.3. ハイパーパラメータの調整</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">7.3.1. ホールドアウト検証</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">7.3.2. 交差検証 (クロス・バリデーション)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">7.4. 学習済みデータの保存</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">7.5. 分類問題の評価方法</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">7.5.1. 2クラス分類の場合</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">7.5.2. 多クラス分類の場合</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">7.6. 練習問題</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">7.7. 参考文献</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
著者 Tatsuya Yatagawa
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright CC BY-NC-SA 4.0, 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>