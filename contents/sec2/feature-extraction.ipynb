{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(sec:feature-extraction)=\n",
    "# 特徴量抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "下準備のコード\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from myst_nb import glue\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# SGDに用いるバッチサイズ\n",
    "batch_size = 128\n",
    "\n",
    "# 一部の警告を無視\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "\n",
    "# シードの固定\n",
    "random.seed(31415)\n",
    "np.random.seed(31415)\n",
    "\n",
    "# グラフの設定\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 150\n",
    "sns.set(style=\"white\", palette=\"colorblind\")\n",
    "\n",
    "# 結果を格納しておくDataFrame\n",
    "result_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Method\": pd.Series([], dtype=\"string\"),\n",
    "        \"Accuracy\": pd.Series([], dtype=\"float64\"),\n",
    "        \"Phase\": pd.Series([], dtype=\"string\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "さて、今回からは数字ではなく「ひらがな」のデータセットを用いて、より複雑な識別問題に取り組む。\n",
    "\n",
    "データセットは国立国会図書館の[NDLラボ](https://lab.ndl.go.jp/)が公開している文字画像データセットを使用する。\n",
    "\n",
    "- 文字画像データセット: <https://github.com/ndl-lab/hiragana_mojigazo>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "実際のデータセットは、以下のURLにホストされているので、ここからダウンロードする。\n",
    "\n",
    "**文字画像データセット(平仮名73文字版) (zip形式)** \n",
    "\n",
    "- <http://lab.ndl.go.jp/dataset/hiragana73.zip>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "平仮名73文字データセットの準備\n",
    "\"\"\"\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://lab.ndl.go.jp/dataset/hiragana73.zip\"\n",
    "filename = os.path.basename(url)\n",
    "\n",
    "# HTTPリクエストを送ってデータサイズを取得\n",
    "r = requests.get(url, stream=True)\n",
    "total_size = int(r.headers.get(\"content-length\", 0))\n",
    "chunk_size = 65535\n",
    "\n",
    "# \"hiragana73\"フォルダが存在し、その中身が空でないことを確認\n",
    "if not os.path.exists(\"./hiragana73\") or len(os.listdir(\"./hiragana73\")) == 0:\n",
    "    # 実際のファイルのダウンロード\n",
    "    pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for data in r.iter_content(chunk_size):\n",
    "            f.write(data)\n",
    "            pbar.update(chunk_size)\n",
    "\n",
    "    # ダウンロードが完了したらZIPを展開する\n",
    "    with zipfile.ZipFile(filename, \"r\") as f:\n",
    "        f.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## データセットの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "このデータセットは濁音、半濁音を含むひらがな73文字に対して、そのUnicode値のフォルダの中に、48×48の画像がPNG形式で保存されている。\n",
    "\n",
    "各ひらがなのUnicode値を調べるには、`ord`関数を用いてUnicode値に変換した後に、それを`hex`関数を用いて16進数表記の文字列に変換すれば良い。\n",
    "\n",
    "一例として「あ」であれば、以下のようにUnicode値を得ることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x3042\n"
     ]
    }
   ],
   "source": [
    "text_a = \"あ\"\n",
    "hex_a = hex(ord(text_a))\n",
    "print(hex_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "逆に、あいうえお順で文字を取得したければ、「あ」に対応するUnicode値である`0x3042`からスタートして、1ずつ値を上げていきながら、その数字を`chr`関数を用いて文字に変換すれば良い。\n",
    "\n",
    "なお、16進数の文字列を整数に直したいときには、`int(hex_a)`と単に文字列を渡すだけではダメで、第2引数に何進数の数字なのかを与えて `int(hex_a, 16)` のようにする必要があることに注意すること。\n",
    "\n",
    "上記のひらがなデータセットは「ゃ」や「っ」などの小文字を含まない73文字から構成されているが、「あ」から「ん」までは、小文字を含め82文字なので、これを列挙してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもゃやゅゆょよらりるれろゎわゐゑをん"
     ]
    }
   ],
   "source": [
    "for i in range(82):\n",
    "    print(chr(int(hex_a, 16) + i), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ひらがなデータセットのフォルダ名は16進数を表わす`0x`の代わりに`U`が接頭辞になっているので、フォルダ名の`U`を`0x`に置換して、どの文字がデータセットに含まれているかをチェックしてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73 folders in \"hiragana73\".\n",
      "あいうえおかがきぎくぐけげこごさざしじすずせぜそぞただちぢつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽまみむめもやゆよらりるれろわゐゑをん"
     ]
    }
   ],
   "source": [
    "# サブフォルダの数を調べる\n",
    "dirname = \"hiragana73\"\n",
    "folders = sorted([d for d in os.listdir(dirname)])\n",
    "print('There are {:d} folders in \"{:s}\".'.format(len(folders), dirname))\n",
    "\n",
    "# フォルダに対応する文字を列挙\n",
    "for d in folders:\n",
    "    x = d.replace(\"U\", \"0x\")\n",
    "    print(chr(int(x, 16)), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "さらに、各文字に何個ずつ画像が含まれているかもチェックしておこう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_67fab_row0_col0, #T_67fab_row0_col2, #T_67fab_row0_col4, #T_67fab_row0_col6, #T_67fab_row0_col8, #T_67fab_row0_col10, #T_67fab_row0_col12, #T_67fab_row0_col14, #T_67fab_row1_col0, #T_67fab_row1_col2, #T_67fab_row1_col4, #T_67fab_row1_col6, #T_67fab_row1_col8, #T_67fab_row1_col10, #T_67fab_row1_col12, #T_67fab_row1_col14, #T_67fab_row2_col0, #T_67fab_row2_col2, #T_67fab_row2_col4, #T_67fab_row2_col6, #T_67fab_row2_col8, #T_67fab_row2_col10, #T_67fab_row2_col12, #T_67fab_row2_col14, #T_67fab_row3_col0, #T_67fab_row3_col2, #T_67fab_row3_col4, #T_67fab_row3_col6, #T_67fab_row3_col8, #T_67fab_row3_col10, #T_67fab_row3_col12, #T_67fab_row3_col14, #T_67fab_row4_col0, #T_67fab_row4_col2, #T_67fab_row4_col4, #T_67fab_row4_col6, #T_67fab_row4_col8, #T_67fab_row4_col10, #T_67fab_row4_col12, #T_67fab_row4_col14, #T_67fab_row5_col0, #T_67fab_row5_col2, #T_67fab_row5_col4, #T_67fab_row5_col6, #T_67fab_row5_col8, #T_67fab_row5_col10, #T_67fab_row5_col12, #T_67fab_row5_col14, #T_67fab_row6_col0, #T_67fab_row6_col2, #T_67fab_row6_col4, #T_67fab_row6_col6, #T_67fab_row6_col8, #T_67fab_row6_col10, #T_67fab_row6_col12, #T_67fab_row6_col14, #T_67fab_row7_col0, #T_67fab_row7_col2, #T_67fab_row7_col4, #T_67fab_row7_col6, #T_67fab_row7_col8, #T_67fab_row7_col10, #T_67fab_row7_col12, #T_67fab_row7_col14, #T_67fab_row8_col0, #T_67fab_row8_col2, #T_67fab_row8_col4, #T_67fab_row8_col6, #T_67fab_row8_col8, #T_67fab_row8_col10, #T_67fab_row8_col12, #T_67fab_row8_col14, #T_67fab_row9_col0, #T_67fab_row9_col2, #T_67fab_row9_col4, #T_67fab_row9_col6, #T_67fab_row9_col8, #T_67fab_row9_col10, #T_67fab_row9_col12, #T_67fab_row9_col14 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_67fab\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_67fab_level0_col0\" class=\"col_heading level0 col0\" ></th>\n",
       "      <th id=\"T_67fab_level0_col1\" class=\"col_heading level0 col1\" ></th>\n",
       "      <th id=\"T_67fab_level0_col2\" class=\"col_heading level0 col2\" ></th>\n",
       "      <th id=\"T_67fab_level0_col3\" class=\"col_heading level0 col3\" ></th>\n",
       "      <th id=\"T_67fab_level0_col4\" class=\"col_heading level0 col4\" ></th>\n",
       "      <th id=\"T_67fab_level0_col5\" class=\"col_heading level0 col5\" ></th>\n",
       "      <th id=\"T_67fab_level0_col6\" class=\"col_heading level0 col6\" ></th>\n",
       "      <th id=\"T_67fab_level0_col7\" class=\"col_heading level0 col7\" ></th>\n",
       "      <th id=\"T_67fab_level0_col8\" class=\"col_heading level0 col8\" ></th>\n",
       "      <th id=\"T_67fab_level0_col9\" class=\"col_heading level0 col9\" ></th>\n",
       "      <th id=\"T_67fab_level0_col10\" class=\"col_heading level0 col10\" ></th>\n",
       "      <th id=\"T_67fab_level0_col11\" class=\"col_heading level0 col11\" ></th>\n",
       "      <th id=\"T_67fab_level0_col12\" class=\"col_heading level0 col12\" ></th>\n",
       "      <th id=\"T_67fab_level0_col13\" class=\"col_heading level0 col13\" ></th>\n",
       "      <th id=\"T_67fab_level0_col14\" class=\"col_heading level0 col14\" ></th>\n",
       "      <th id=\"T_67fab_level0_col15\" class=\"col_heading level0 col15\" ></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row0\" class=\"row_heading level0 row0\" ></th>\n",
       "      <td id=\"T_67fab_row0_col0\" class=\"data row0 col0\" >あ</td>\n",
       "      <td id=\"T_67fab_row0_col1\" class=\"data row0 col1\" >1208</td>\n",
       "      <td id=\"T_67fab_row0_col2\" class=\"data row0 col2\" >ぐ</td>\n",
       "      <td id=\"T_67fab_row0_col3\" class=\"data row0 col3\" >1043</td>\n",
       "      <td id=\"T_67fab_row0_col4\" class=\"data row0 col4\" >ず</td>\n",
       "      <td id=\"T_67fab_row0_col5\" class=\"data row0 col5\" >1046</td>\n",
       "      <td id=\"T_67fab_row0_col6\" class=\"data row0 col6\" >づ</td>\n",
       "      <td id=\"T_67fab_row0_col7\" class=\"data row0 col7\" >1080</td>\n",
       "      <td id=\"T_67fab_row0_col8\" class=\"data row0 col8\" >は</td>\n",
       "      <td id=\"T_67fab_row0_col9\" class=\"data row0 col9\" >1247</td>\n",
       "      <td id=\"T_67fab_row0_col10\" class=\"data row0 col10\" >べ</td>\n",
       "      <td id=\"T_67fab_row0_col11\" class=\"data row0 col11\" >1109</td>\n",
       "      <td id=\"T_67fab_row0_col12\" class=\"data row0 col12\" >や</td>\n",
       "      <td id=\"T_67fab_row0_col13\" class=\"data row0 col13\" >1285</td>\n",
       "      <td id=\"T_67fab_row0_col14\" class=\"data row0 col14\" >ゑ</td>\n",
       "      <td id=\"T_67fab_row0_col15\" class=\"data row0 col15\" >1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row1\" class=\"row_heading level0 row1\" ></th>\n",
       "      <td id=\"T_67fab_row1_col0\" class=\"data row1 col0\" >い</td>\n",
       "      <td id=\"T_67fab_row1_col1\" class=\"data row1 col1\" >1122</td>\n",
       "      <td id=\"T_67fab_row1_col2\" class=\"data row1 col2\" >け</td>\n",
       "      <td id=\"T_67fab_row1_col3\" class=\"data row1 col3\" >1155</td>\n",
       "      <td id=\"T_67fab_row1_col4\" class=\"data row1 col4\" >せ</td>\n",
       "      <td id=\"T_67fab_row1_col5\" class=\"data row1 col5\" >1165</td>\n",
       "      <td id=\"T_67fab_row1_col6\" class=\"data row1 col6\" >て</td>\n",
       "      <td id=\"T_67fab_row1_col7\" class=\"data row1 col7\" >1213</td>\n",
       "      <td id=\"T_67fab_row1_col8\" class=\"data row1 col8\" >ば</td>\n",
       "      <td id=\"T_67fab_row1_col9\" class=\"data row1 col9\" >1105</td>\n",
       "      <td id=\"T_67fab_row1_col10\" class=\"data row1 col10\" >ぺ</td>\n",
       "      <td id=\"T_67fab_row1_col11\" class=\"data row1 col11\" >268</td>\n",
       "      <td id=\"T_67fab_row1_col12\" class=\"data row1 col12\" >ゆ</td>\n",
       "      <td id=\"T_67fab_row1_col13\" class=\"data row1 col13\" >1282</td>\n",
       "      <td id=\"T_67fab_row1_col14\" class=\"data row1 col14\" >を</td>\n",
       "      <td id=\"T_67fab_row1_col15\" class=\"data row1 col15\" >1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row2\" class=\"row_heading level0 row2\" ></th>\n",
       "      <td id=\"T_67fab_row2_col0\" class=\"data row2 col0\" >う</td>\n",
       "      <td id=\"T_67fab_row2_col1\" class=\"data row2 col1\" >1148</td>\n",
       "      <td id=\"T_67fab_row2_col2\" class=\"data row2 col2\" >げ</td>\n",
       "      <td id=\"T_67fab_row2_col3\" class=\"data row2 col3\" >1058</td>\n",
       "      <td id=\"T_67fab_row2_col4\" class=\"data row2 col4\" >ぜ</td>\n",
       "      <td id=\"T_67fab_row2_col5\" class=\"data row2 col5\" >1115</td>\n",
       "      <td id=\"T_67fab_row2_col6\" class=\"data row2 col6\" >で</td>\n",
       "      <td id=\"T_67fab_row2_col7\" class=\"data row2 col7\" >1178</td>\n",
       "      <td id=\"T_67fab_row2_col8\" class=\"data row2 col8\" >ぱ</td>\n",
       "      <td id=\"T_67fab_row2_col9\" class=\"data row2 col9\" >262</td>\n",
       "      <td id=\"T_67fab_row2_col10\" class=\"data row2 col10\" >ほ</td>\n",
       "      <td id=\"T_67fab_row2_col11\" class=\"data row2 col11\" >1115</td>\n",
       "      <td id=\"T_67fab_row2_col12\" class=\"data row2 col12\" >よ</td>\n",
       "      <td id=\"T_67fab_row2_col13\" class=\"data row2 col13\" >1166</td>\n",
       "      <td id=\"T_67fab_row2_col14\" class=\"data row2 col14\" >ん</td>\n",
       "      <td id=\"T_67fab_row2_col15\" class=\"data row2 col15\" >1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row3\" class=\"row_heading level0 row3\" ></th>\n",
       "      <td id=\"T_67fab_row3_col0\" class=\"data row3 col0\" >え</td>\n",
       "      <td id=\"T_67fab_row3_col1\" class=\"data row3 col1\" >1077</td>\n",
       "      <td id=\"T_67fab_row3_col2\" class=\"data row3 col2\" >こ</td>\n",
       "      <td id=\"T_67fab_row3_col3\" class=\"data row3 col3\" >1115</td>\n",
       "      <td id=\"T_67fab_row3_col4\" class=\"data row3 col4\" >そ</td>\n",
       "      <td id=\"T_67fab_row3_col5\" class=\"data row3 col5\" >1285</td>\n",
       "      <td id=\"T_67fab_row3_col6\" class=\"data row3 col6\" >と</td>\n",
       "      <td id=\"T_67fab_row3_col7\" class=\"data row3 col7\" >1184</td>\n",
       "      <td id=\"T_67fab_row3_col8\" class=\"data row3 col8\" >ひ</td>\n",
       "      <td id=\"T_67fab_row3_col9\" class=\"data row3 col9\" >1074</td>\n",
       "      <td id=\"T_67fab_row3_col10\" class=\"data row3 col10\" >ぼ</td>\n",
       "      <td id=\"T_67fab_row3_col11\" class=\"data row3 col11\" >1044</td>\n",
       "      <td id=\"T_67fab_row3_col12\" class=\"data row3 col12\" >ら</td>\n",
       "      <td id=\"T_67fab_row3_col13\" class=\"data row3 col13\" >1114</td>\n",
       "      <td id=\"T_67fab_row3_col14\" class=\"data row3 col14\" ></td>\n",
       "      <td id=\"T_67fab_row3_col15\" class=\"data row3 col15\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row4\" class=\"row_heading level0 row4\" ></th>\n",
       "      <td id=\"T_67fab_row4_col0\" class=\"data row4 col0\" >お</td>\n",
       "      <td id=\"T_67fab_row4_col1\" class=\"data row4 col1\" >1283</td>\n",
       "      <td id=\"T_67fab_row4_col2\" class=\"data row4 col2\" >ご</td>\n",
       "      <td id=\"T_67fab_row4_col3\" class=\"data row4 col3\" >1078</td>\n",
       "      <td id=\"T_67fab_row4_col4\" class=\"data row4 col4\" >ぞ</td>\n",
       "      <td id=\"T_67fab_row4_col5\" class=\"data row4 col5\" >1066</td>\n",
       "      <td id=\"T_67fab_row4_col6\" class=\"data row4 col6\" >ど</td>\n",
       "      <td id=\"T_67fab_row4_col7\" class=\"data row4 col7\" >1134</td>\n",
       "      <td id=\"T_67fab_row4_col8\" class=\"data row4 col8\" >び</td>\n",
       "      <td id=\"T_67fab_row4_col9\" class=\"data row4 col9\" >1045</td>\n",
       "      <td id=\"T_67fab_row4_col10\" class=\"data row4 col10\" >ぽ</td>\n",
       "      <td id=\"T_67fab_row4_col11\" class=\"data row4 col11\" >261</td>\n",
       "      <td id=\"T_67fab_row4_col12\" class=\"data row4 col12\" >り</td>\n",
       "      <td id=\"T_67fab_row4_col13\" class=\"data row4 col13\" >1244</td>\n",
       "      <td id=\"T_67fab_row4_col14\" class=\"data row4 col14\" ></td>\n",
       "      <td id=\"T_67fab_row4_col15\" class=\"data row4 col15\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row5\" class=\"row_heading level0 row5\" ></th>\n",
       "      <td id=\"T_67fab_row5_col0\" class=\"data row5 col0\" >か</td>\n",
       "      <td id=\"T_67fab_row5_col1\" class=\"data row5 col1\" >1259</td>\n",
       "      <td id=\"T_67fab_row5_col2\" class=\"data row5 col2\" >さ</td>\n",
       "      <td id=\"T_67fab_row5_col3\" class=\"data row5 col3\" >1261</td>\n",
       "      <td id=\"T_67fab_row5_col4\" class=\"data row5 col4\" >た</td>\n",
       "      <td id=\"T_67fab_row5_col5\" class=\"data row5 col5\" >1285</td>\n",
       "      <td id=\"T_67fab_row5_col6\" class=\"data row5 col6\" >な</td>\n",
       "      <td id=\"T_67fab_row5_col7\" class=\"data row5 col7\" >1233</td>\n",
       "      <td id=\"T_67fab_row5_col8\" class=\"data row5 col8\" >ぴ</td>\n",
       "      <td id=\"T_67fab_row5_col9\" class=\"data row5 col9\" >126</td>\n",
       "      <td id=\"T_67fab_row5_col10\" class=\"data row5 col10\" >ま</td>\n",
       "      <td id=\"T_67fab_row5_col11\" class=\"data row5 col11\" >1285</td>\n",
       "      <td id=\"T_67fab_row5_col12\" class=\"data row5 col12\" >る</td>\n",
       "      <td id=\"T_67fab_row5_col13\" class=\"data row5 col13\" >1190</td>\n",
       "      <td id=\"T_67fab_row5_col14\" class=\"data row5 col14\" ></td>\n",
       "      <td id=\"T_67fab_row5_col15\" class=\"data row5 col15\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row6\" class=\"row_heading level0 row6\" ></th>\n",
       "      <td id=\"T_67fab_row6_col0\" class=\"data row6 col0\" >が</td>\n",
       "      <td id=\"T_67fab_row6_col1\" class=\"data row6 col1\" >1200</td>\n",
       "      <td id=\"T_67fab_row6_col2\" class=\"data row6 col2\" >ざ</td>\n",
       "      <td id=\"T_67fab_row6_col3\" class=\"data row6 col3\" >1070</td>\n",
       "      <td id=\"T_67fab_row6_col4\" class=\"data row6 col4\" >だ</td>\n",
       "      <td id=\"T_67fab_row6_col5\" class=\"data row6 col5\" >1116</td>\n",
       "      <td id=\"T_67fab_row6_col6\" class=\"data row6 col6\" >に</td>\n",
       "      <td id=\"T_67fab_row6_col7\" class=\"data row6 col7\" >1260</td>\n",
       "      <td id=\"T_67fab_row6_col8\" class=\"data row6 col8\" >ふ</td>\n",
       "      <td id=\"T_67fab_row6_col9\" class=\"data row6 col9\" >1285</td>\n",
       "      <td id=\"T_67fab_row6_col10\" class=\"data row6 col10\" >み</td>\n",
       "      <td id=\"T_67fab_row6_col11\" class=\"data row6 col11\" >1142</td>\n",
       "      <td id=\"T_67fab_row6_col12\" class=\"data row6 col12\" >れ</td>\n",
       "      <td id=\"T_67fab_row6_col13\" class=\"data row6 col13\" >1238</td>\n",
       "      <td id=\"T_67fab_row6_col14\" class=\"data row6 col14\" ></td>\n",
       "      <td id=\"T_67fab_row6_col15\" class=\"data row6 col15\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row7\" class=\"row_heading level0 row7\" ></th>\n",
       "      <td id=\"T_67fab_row7_col0\" class=\"data row7 col0\" >き</td>\n",
       "      <td id=\"T_67fab_row7_col1\" class=\"data row7 col1\" >1121</td>\n",
       "      <td id=\"T_67fab_row7_col2\" class=\"data row7 col2\" >し</td>\n",
       "      <td id=\"T_67fab_row7_col3\" class=\"data row7 col3\" >1285</td>\n",
       "      <td id=\"T_67fab_row7_col4\" class=\"data row7 col4\" >ち</td>\n",
       "      <td id=\"T_67fab_row7_col5\" class=\"data row7 col5\" >1052</td>\n",
       "      <td id=\"T_67fab_row7_col6\" class=\"data row7 col6\" >ぬ</td>\n",
       "      <td id=\"T_67fab_row7_col7\" class=\"data row7 col7\" >1093</td>\n",
       "      <td id=\"T_67fab_row7_col8\" class=\"data row7 col8\" >ぶ</td>\n",
       "      <td id=\"T_67fab_row7_col9\" class=\"data row7 col9\" >1149</td>\n",
       "      <td id=\"T_67fab_row7_col10\" class=\"data row7 col10\" >む</td>\n",
       "      <td id=\"T_67fab_row7_col11\" class=\"data row7 col11\" >1058</td>\n",
       "      <td id=\"T_67fab_row7_col12\" class=\"data row7 col12\" >ろ</td>\n",
       "      <td id=\"T_67fab_row7_col13\" class=\"data row7 col13\" >1069</td>\n",
       "      <td id=\"T_67fab_row7_col14\" class=\"data row7 col14\" ></td>\n",
       "      <td id=\"T_67fab_row7_col15\" class=\"data row7 col15\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row8\" class=\"row_heading level0 row8\" ></th>\n",
       "      <td id=\"T_67fab_row8_col0\" class=\"data row8 col0\" >ぎ</td>\n",
       "      <td id=\"T_67fab_row8_col1\" class=\"data row8 col1\" >1091</td>\n",
       "      <td id=\"T_67fab_row8_col2\" class=\"data row8 col2\" >じ</td>\n",
       "      <td id=\"T_67fab_row8_col3\" class=\"data row8 col3\" >1099</td>\n",
       "      <td id=\"T_67fab_row8_col4\" class=\"data row8 col4\" >ぢ</td>\n",
       "      <td id=\"T_67fab_row8_col5\" class=\"data row8 col5\" >1132</td>\n",
       "      <td id=\"T_67fab_row8_col6\" class=\"data row8 col6\" >ね</td>\n",
       "      <td id=\"T_67fab_row8_col7\" class=\"data row8 col7\" >1126</td>\n",
       "      <td id=\"T_67fab_row8_col8\" class=\"data row8 col8\" >ぷ</td>\n",
       "      <td id=\"T_67fab_row8_col9\" class=\"data row8 col9\" >112</td>\n",
       "      <td id=\"T_67fab_row8_col10\" class=\"data row8 col10\" >め</td>\n",
       "      <td id=\"T_67fab_row8_col11\" class=\"data row8 col11\" >1233</td>\n",
       "      <td id=\"T_67fab_row8_col12\" class=\"data row8 col12\" >わ</td>\n",
       "      <td id=\"T_67fab_row8_col13\" class=\"data row8 col13\" >1283</td>\n",
       "      <td id=\"T_67fab_row8_col14\" class=\"data row8 col14\" ></td>\n",
       "      <td id=\"T_67fab_row8_col15\" class=\"data row8 col15\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_67fab_level0_row9\" class=\"row_heading level0 row9\" ></th>\n",
       "      <td id=\"T_67fab_row9_col0\" class=\"data row9 col0\" >く</td>\n",
       "      <td id=\"T_67fab_row9_col1\" class=\"data row9 col1\" >1266</td>\n",
       "      <td id=\"T_67fab_row9_col2\" class=\"data row9 col2\" >す</td>\n",
       "      <td id=\"T_67fab_row9_col3\" class=\"data row9 col3\" >1282</td>\n",
       "      <td id=\"T_67fab_row9_col4\" class=\"data row9 col4\" >つ</td>\n",
       "      <td id=\"T_67fab_row9_col5\" class=\"data row9 col5\" >1142</td>\n",
       "      <td id=\"T_67fab_row9_col6\" class=\"data row9 col6\" >の</td>\n",
       "      <td id=\"T_67fab_row9_col7\" class=\"data row9 col7\" >1160</td>\n",
       "      <td id=\"T_67fab_row9_col8\" class=\"data row9 col8\" >へ</td>\n",
       "      <td id=\"T_67fab_row9_col9\" class=\"data row9 col9\" >1114</td>\n",
       "      <td id=\"T_67fab_row9_col10\" class=\"data row9 col10\" >も</td>\n",
       "      <td id=\"T_67fab_row9_col11\" class=\"data row9 col11\" >1187</td>\n",
       "      <td id=\"T_67fab_row9_col12\" class=\"data row9 col12\" >ゐ</td>\n",
       "      <td id=\"T_67fab_row9_col13\" class=\"data row9 col13\" >1053</td>\n",
       "      <td id=\"T_67fab_row9_col14\" class=\"data row9 col14\" ></td>\n",
       "      <td id=\"T_67fab_row9_col15\" class=\"data row9 col15\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150cdad90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "\n",
    "chars = [chr(int(d.replace(\"U\", \"0x\"), 16)) for d in folders]\n",
    "dir_paths = [os.path.join(dirname, d) for d in folders]\n",
    "num_images = [len(os.listdir(d)) for d in dir_paths]\n",
    "\n",
    "df = pd.DataFrame([(c, n) for c, n in zip(chars, num_images)])\n",
    "sub_dfs = [df[i : i + 10].reset_index(drop=True) for i in range(0, len(df.index), 10)]\n",
    "df = pd.concat(sub_dfs, axis=1).fillna(\"\")\n",
    "\n",
    "df.index = [i for i in range(len(df.index))]\n",
    "df.columns = [j for j in range(len(df.columns))]\n",
    "\n",
    "\n",
    "def custom_style(df):\n",
    "    index = df.index\n",
    "    columns = df.columns\n",
    "    styles = []\n",
    "    for i in range(len(index)):\n",
    "        s = []\n",
    "        for j in range(len(columns)):\n",
    "            if columns[j] % 2 == 0:\n",
    "                s.append(\"font-weight: bold;\")\n",
    "            else:\n",
    "                s.append(None)\n",
    "        styles.append(s)\n",
    "\n",
    "    return np.array(styles, dtype=\"object\")\n",
    "\n",
    "\n",
    "df.style.format(precision=0).format_index(\"\", axis=1).format_index(\"\", axis=0).apply(\n",
    "    custom_style, axis=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "このように、ひらがなについて、おおよそ1000程度の画像が含まれていることが確認できる。なお、半濁音のひらがなは全体的に少なめで100-200程度となっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 分類用のデータ加工"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "MNISTでは手書き文字の画像が28x28=576次元ベクトル、ラベルが10種類の数字のいずれかを表わす0-9の数字であった。\n",
    "\n",
    "このようなデータ形式をひらがなデータセットに対しても作成しておく。なお、今回は分類の難易度を上げるため、**画像をランダムに回転したり、拡大縮小したりして、データのばらつきを大きくしておく**。また、今回のデータセットは画像が一度JPEGで圧縮されているようで、ブロックノイズを多く含むため、最初にバイラテラル・フィルタを書けてノイズを低減しておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 文字への整数の割り当て\n",
    "n_chars = len(chars)\n",
    "char2num = {c: i for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3a33f9ea7d4a60b6e131bd2d79ba52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "n_total = sum(num_images)\n",
    "pbar = tqdm(total=n_total)\n",
    "\n",
    "# 画像の読み取り\n",
    "X = []  # 画像データ\n",
    "y = []  # ラベルデータ\n",
    "for d in dir_paths:\n",
    "    # 文字に対する数字を計算\n",
    "    char = os.path.basename(d).replace(\"U\", \"0x\")\n",
    "    char = chr(int(char, 16))\n",
    "    num = char2num[char]\n",
    "    # 画像の読み込み\n",
    "    image_files = [os.path.join(d, f) for f in os.listdir(d)]\n",
    "    image_files = [f for f in image_files if f.endswith(\".png\")]\n",
    "    for f in image_files:\n",
    "        image = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "        if image is None:\n",
    "            raise IOError(\"Failed to load image: {:s}\".format(f))\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # ランダム輝度変更\n",
    "        factor = np.random.uniform(0.9, 1.1)\n",
    "        image = (((image / 255.0) ** factor) * 255.0).astype(\"uint8\")\n",
    "\n",
    "        # データのランダム回転、ランダムスケール\n",
    "        height, width = image.shape\n",
    "        center = (width // 2, height // 2)\n",
    "        scale = np.random.uniform(0.9, 1.1)\n",
    "        angle = np.random.uniform(-60, 60)\n",
    "        trans = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "        image = cv2.warpAffine(image, trans, (width, height), borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "        # 細かなノイズの除去\n",
    "        image = cv2.bilateralFilter(image, -1, 15.0, 5.0)\n",
    "\n",
    "        X.append(image.flatten())\n",
    "        y.append(num)\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "X = np.stack(X, axis=0)\n",
    "y = np.stack(y, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "読み込みが完了したら例のごとく訓練データとテストデータに分割しておく。今回は画像が80000枚あるので、60000枚を訓練画像、10000枚を検証用データ (今回は使わない)、10000枚をテスト画像とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X, X_test, y, y_test = model_selection.train_test_split(\n",
    "    X, y, train_size=70000, test_size=10000, shuffle=True\n",
    ")\n",
    "\n",
    "X, X_val, y, y_val = model_selection.train_test_split(\n",
    "    X, y, train_size=60000, test_size=10000, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "データセットの先頭数枚の画像は次のようになっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x720 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "axs = axs.flatten()\n",
    "for i in range(6):\n",
    "    img = X[i].reshape((48, 48))\n",
    "    axs[i].imshow(img, cmap=\"gray\", vmin=0, vmax=255, interpolation=None)\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 実験: SVMによる分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "まずは、MNISTの時と同様にscikit-learnによる分類を試してみる。この時、[scikit-learnの節](sec:scikit-learn)で紹介したように、予め入力データを正規化しておく処理である`StandardScaler`を使用する。\n",
    "\n",
    "また、scikit-learnには`make_pipeline`というメソッドがあり、これを利用することで、「データの正規化」+「分類器の学習」を連続で行ってくれる仕組みも存在する。\n",
    "\n",
    "ただし、今回は、サポートベクトルマシンの学習が低速である問題を解決するために、`SGDClassifier`というクラスに用意された`pertial_fit`というメソッドを使って、データセットの一部だけを分類器のパラメータ更新に用いる**確率的最急降下法** (SGD=Stochastic Gradienct Descent)により学習を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "`partial_fit`メソッドは、`make_pipeline`には対応していないため、自前で`StandardScaler`によるデータの正規化と`partial_fit`によるパラメータ更新を連続で行うクラスを用意する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "StandardScaler+SGDClassifierの実行クラス\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class MySGDClassifier(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.preprocess = StandardScaler()\n",
    "        self.classifier = SGDClassifier(*args, **kwargs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 前処理の学習\n",
    "        self.preprocess.fit(X)\n",
    "\n",
    "        # バッチを用いたトレーニング\n",
    "        pbar = tqdm(total=len(X))\n",
    "        rand_idx = np.random.permutation(np.arange(len(X)))\n",
    "        for b in range(0, len(X), batch_size):\n",
    "            if b + batch_size >= len(X):\n",
    "                idx = rand_idx[b:]\n",
    "            else:\n",
    "                idx = rand_idx[b : b + batch_size]\n",
    "\n",
    "            X_norm = self.preprocess.transform(X[idx])\n",
    "            self.classifier.partial_fit(X_norm, y[idx], self.y)\n",
    "\n",
    "            score = self.classifier.score(X_norm, y[idx])\n",
    "            pbar.set_description(\"score={:.3f}\".format(score))\n",
    "            pbar.update(len(idx))\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_norm = self.preprocess.transform(X)\n",
    "        return self.classifier.predict(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "なお、`SGDClassier`は、 `loss=\"hinge\"` とすることで、内部の分類器が線形SVMになる。また、`partial_fit`で分類器のパラメータ更新を行う際は、`learning_rate=...`ならびに更新率を`eta0=...`の設定で学習の進行度が変化する。以下のコードでは`learning_rate=\"optimal\"`を指定して、適当な学習率を自動で与えている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da09e0c244a49d2896239a32713db9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m sgd_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhinge\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m clf \u001b[38;5;241m=\u001b[39m MySGDClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msgd_params)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mMySGDClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m X_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess\u001b[38;5;241m.\u001b[39mtransform(X[idx])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mpartial_fit(X_norm, y[idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m---> 32\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore=\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(score))\n\u001b[1;32m     34\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(idx))\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sds-adv-ml-kOzjjOMa-py3.9/lib/python3.9/site-packages/sklearn/base.py:705\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sds-adv-ml-kOzjjOMa-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sds-adv-ml-kOzjjOMa-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:433\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 433\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sds-adv-ml-kOzjjOMa-py3.9/lib/python3.9/site-packages/sklearn/utils/extmath.py:193\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    191\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    196\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m ):\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sgd_params = {\n",
    "    \"loss\": \"hinge\",\n",
    "    \"learning_rate\": \"optimal\",\n",
    "    \"penalty\": \"l2\",\n",
    "    \"alpha\": 1.0e-4,\n",
    "    \"shuffle\": False,\n",
    "    \"max_iter\": 10000,\n",
    "    \"n_jobs\": 1,\n",
    "}\n",
    "\n",
    "clf = MySGDClassifier(**sgd_params)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練時の識別精度の確認\n",
    "y_pred = clf.predict(X)\n",
    "acc_train = 100.0 * np.sum(y_pred == y) / len(y)\n",
    "glue(\"naive_acc_train\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"Image\", acc_train, \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テストデータに対する識別精度の計算\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_test = 100.0 * np.sum(y_pred == y_test) / len(y_test)\n",
    "glue(\"naive_acc_test\", acc_test, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"Image\", acc_test, \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**結果: 画像をそのまま入力**\n",
    "\n",
    "- 訓練時精度: {glue}`naive_acc_train:.2f`%\n",
    "- 評価時精度: {glue}`naive_acc_test:.2f`%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "このように、今回は分類問題の難易度が上がっており、SVMを用いても十分な精度が得られていないことが分かる。また、単に画像をベクトルとして扱うのは、(特に入力画像が大きい場合には)計算効率の観点からも好ましいとは言いがたい。加えて、必ずしもデータセット中の画像の大きさが揃っていることばかりではないので、画像の大きさに依存しないように画像を特徴ベクトル化できることが好ましいと言える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 主成分分析による次元圧縮"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "まずは、前項の[次元圧縮](sec:data-visualization)を参考に、主成分分析を用いて、画像データを低次元ベクトルに変換し、それを学習に用いる方策を考えてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf0 = MySGDClassifier(**sgd_params)\n",
    "clf0.fit(X_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練時の識別精度の確認\n",
    "y_pred = clf0.predict(X_pca)\n",
    "acc_train = 100.0 * np.sum(y_pred == y) / len(y)\n",
    "glue(\"pca_acc_train\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"PCA\", acc_train, \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テストデータに対する識別精度の計算\n",
    "X_pca_test = pca.transform(X_test)\n",
    "y_pred = clf0.predict(X_pca_test)\n",
    "acc_test = 100.0 * np.sum(y_pred == y_test) / len(y_test)\n",
    "glue(\"pca_acc_test\", acc_test, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"PCA\", acc_test, \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**結果: 主成分分析による次元圧縮**\n",
    "\n",
    "- 訓練時精度: {glue}`pca_acc_train`%\n",
    "- 評価時精度: {glue}`pca_acc_test`%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 輝度によるヒストグラム化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "まず、非常に単純なアイディアとして画像の輝度を基準としたヒストグラム化を考えてみる。今、画像は256階調の輝度で表わされているので、輝度のヒストグラムを作ることで、どれほど大きな画像であっても256次元のベクトルにすることができる。\n",
    "\n",
    "一例として、データセットの先頭の画像に対して、輝度ヒストグラムを計算した結果が以下である (分かりやすさのためにヒストグラムのbin数を32としてある)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "img = X[0].reshape((48, 48))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "gs = GridSpec(1, 2, width_ratios=[1, 1], figure=fig)\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "\n",
    "ax1.imshow(img, cmap=\"gray\", vmin=0, vmax=255, interpolation=None)\n",
    "ax1.set(title=\"Input image\", xticks=[], yticks=[])\n",
    "\n",
    "ax2.hist(img.flatten(), bins=32, density=True)\n",
    "ax2.set(title=\"Histogram of image intensities\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "このヒストグラムを画像全体に対する特徴ベクトルとみなし、SVMによる文字分類を試してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_hist = []\n",
    "for x in tqdm(X):\n",
    "    h = np.histogram(x, bins=255, density=True)\n",
    "    X_hist.append(h[0])\n",
    "\n",
    "X_hist = np.stack(X_hist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf2 = MySGDClassifier(**sgd_params)\n",
    "clf2.fit(X_hist, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練時の識別精度の確認\n",
    "y_pred = clf2.predict(X_hist)\n",
    "acc_train = 100.0 * np.sum(y_pred == y) / len(y)\n",
    "glue(\"hist_acc_train\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"Hist\", acc_train, \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_hist_test = []\n",
    "for x in tqdm(X_test):\n",
    "    h = np.histogram(x, bins=255, density=True)\n",
    "    X_hist_test.append(h[0])\n",
    "\n",
    "X_hist_test = np.stack(X_hist_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テストデータに対する識別精度の計算\n",
    "y_pred = clf2.predict(X_hist_test)\n",
    "acc_test = 100.0 * np.sum(y_pred == y_test) / len(y_test)\n",
    "glue(\"hist_acc_test\", acc_test, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"Hist\", acc_test, \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**結果: 輝度ヒストグラムの利用**\n",
    "\n",
    "- 訓練時精度: {glue}`hist_acc_train`%\n",
    "- 評価時精度: {glue}`hist_acc_test`%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "しかし、実際に試してみると上記のように満足な精度が得られるには至っていない。これは、ほとんどの画像がほぼ同じ割合の白と黒の領域でできていて、それをヒストグラム化してしまうと、文字の分類が難しくなるためである。\n",
    "\n",
    "また、輝度のヒストグラムは写真を写した時の周囲の明るさなどにも影響を受けるため、たとえ写真に写っている物が同じであったとしても、周囲の環境によって、ヒストグラムが変化してしまうなど、一貫性に乏しい。\n",
    "\n",
    "従って、もう少し気の利いた方法を考える必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Local Binary Pattern (LBP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Local Binary Pattern (LBP)は、とある画素を中心とした3x3の領域について、中心画素と周りの画素の輝度の大小を数値化する手法である {cite}`ojala1996comparative`。\n",
    "\n",
    "一例として、とある中心画素周辺の画素値が以下のようになっている場合を考えよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_frame(problem, fig, ax):\n",
    "    mask = (problem == 0).astype(\"float32\")\n",
    "    frame = []\n",
    "    ax.set_xticks(np.arange(0, 9))\n",
    "    ax.set_yticks(np.arange(0, 9))\n",
    "    ax.set_xticklabels(np.arange(1, 10))\n",
    "    ax.set_yticklabels(np.arange(1, 10))\n",
    "\n",
    "    ax.set_xticks(np.arange(1, 10) - 0.5, minor=True)\n",
    "    ax.set_yticks(np.arange(1, 10) - 0.5, minor=True)\n",
    "    ax.set_xticks(np.arange(3, 10, 3) - 0.5)\n",
    "    ax.set_yticks(np.arange(3, 10, 3) - 0.5)\n",
    "\n",
    "    ims = plt.imshow(mask * 0.2, cmap=\"Blues\", vmin=0.0, vmax=1.0)\n",
    "    frame.append(ims)\n",
    "    for (i, j), z in np.ndenumerate(problem):\n",
    "        txt = ax.text(j, i, \"{:d}\".format(z), ha=\"center\", va=\"center\", color=\"k\", fontsize=15)\n",
    "        frame.append(txt)\n",
    "\n",
    "    ax.grid(which=\"minor\", color=\"k\", linestyle=\"-\", linewidth=0.5)\n",
    "    ax.grid(which=\"major\", color=\"k\", linestyle=\"-\", linewidth=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "m = rng.randint(0, 256, size=(3, 3))\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "draw_frame(m, fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "このとき、中心画素と周囲の8画素の大小を見比べて、大きいものを1, 小さいものを0に置き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = m[1, 1]\n",
    "b = (m > c).astype(\"int32\")\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "draw_frame(b, fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "この周囲の8画素に割り当てられた0, 1のパターンが8ビットの符号なし整数であると考えて数値を求める。このとき、以下のような時計回りに2のべき乗が並んだ画像を用いると良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = 2 ** np.array([[6, 7, 0], [5, 0, 1], [4, 3, 2]])\n",
    "p[1, 1] = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "draw_frame(p, fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "lbp_val = np.sum(b * p)\n",
    "glue(\"lbp_val\", lbp_val, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "すると、上記の3x3の領域に対しては、LBPの値として**{glue}`lbp_val`**が求まる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "この計算を先ほどと同様にデータセットの先頭画像の各画素に対して計算すると、その結果と、LBP値のヒストグラムは以下のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "img = X[0].reshape((48, 48))\n",
    "\n",
    "lbp = np.zeros_like(img).astype(\"uint8\")\n",
    "for j in range(1, img.shape[0] - 1):\n",
    "    for i in range(1, img.shape[1] - 1):\n",
    "        c = img[i, j]\n",
    "        m = img[i - 1 : i + 2, j - 1 : j + 2]\n",
    "        b = (m > c).astype(\"int32\")\n",
    "        lbp[i, j] = np.sum(p * b)\n",
    "\n",
    "# 輪郭の画素では計算できないので、輪郭を除いておく\n",
    "lbp = lbp[1:-1, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "gs = GridSpec(1, 2, width_ratios=[1, 1], figure=fig)\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "\n",
    "ax1.imshow(lbp, cmap=\"gray\", vmin=0, vmax=255, interpolation=None)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title(\"LBP image\")\n",
    "\n",
    "ax2.hist(lbp.flatten(), bins=32, density=True)\n",
    "ax2.set_title(\"Histogram of LBP values\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "LBPを用いることの利点は画像の相対的な輝度だけを見ている点にあり、仮に画像の輝度が2倍になったりしても求まるLBPの値は全く変化しない。そのため、同じ対象を異なる光源下で計算した場合などに一貫した特徴を得られる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "\n",
    "def calc_lbp(x):\n",
    "    pat = (2 ** np.array([[0, 1, 2], [7, 0, 3], [6, 5, 4]])).astype(\"int32\")\n",
    "\n",
    "    patches = extract_patches_2d(x, (3, 3))\n",
    "    centers = patches[:, 1, 1].reshape((-1, 1, 1))\n",
    "    binary = (patches > centers).astype(\"int32\")\n",
    "\n",
    "    return np.sum(binary * pat.reshape((1, 3, 3)), axis=(1, 2))\n",
    "\n",
    "\n",
    "def calc_lbp_hist(x):\n",
    "    lbp = calc_lbp(x)\n",
    "    return np.histogram(lbp, bins=255, density=True)[0]\n",
    "\n",
    "\n",
    "X_lbp = [calc_lbp_hist(x.reshape((48, 48))) for x in tqdm(X)]\n",
    "X_lbp = np.stack(X_lbp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf3 = MySGDClassifier(**sgd_params)\n",
    "clf3.fit(X_lbp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練時の識別精度の確認\n",
    "y_pred = clf3.predict(X_lbp)\n",
    "acc_train = 100.0 * np.sum(y_pred == y) / len(y)\n",
    "glue(\"lbp_acc_train\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"LBP\", acc_train, \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_lbp_test = [calc_lbp_hist(x.reshape((48, 48))) for x in tqdm(X_test)]\n",
    "X_lbp_test = np.stack(X_lbp_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テストデータに対する識別精度の計算\n",
    "y_pred = clf3.predict(X_lbp_test)\n",
    "acc_test = 100.0 * np.sum(y_pred == y_test) / len(y_test)\n",
    "glue(\"lbp_acc_test\", acc_test, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"LBP\", acc_test, \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**結果: Local Binary Patternの利用**\n",
    "\n",
    "- 訓練時精度: {glue}`lbp_acc_train`%\n",
    "- 評価時精度: {glue}`lbp_acc_test`%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "先ほどの単純な輝度ヒストグラムに比べれば、精度は改善しているものの、画像をそのまま入力したSVMには劣る結果となっている。\n",
    "\n",
    "今、データセットに含まれるデータはひらがながランダムに回転したりスケールしたりしている。LBPは上記の計算方法からも分かるとおり、物体が回転してしまうと得られる値が変わってしまう性質がある。従って、今回のようにデータセット中でひらがながランダムに回転しているような場合には、もう少し工夫をする必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Uniform LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "元々のLBPが持つ回転に対して変化してしまう問題を解決した手法の一つに**Uniform LBP** {cite}`ojala2002multiresolution` がある。\n",
    "\n",
    "Uniform LBPの基本的なアイディアは、注目画素を中心に**円状に配置された点の輝度**を調べて、その輝度の大小関係のパターン (つまり, 0, 1の列)が回転したときに一致するものを同じ物であると見なすという部分にある。\n",
    "\n",
    "より具体的には、円状に配置された0, 1の列を1周する間に何回0から1あるいは1から0への変化が起こるかを考える。例えば、12時方向を視点として反時計回りに `(0, 0, 1, 0, 1, 1, 1, 0)` というパターンが現れたとすると、0→1 / 1→0の遷移回数は4回である。\n",
    "\n",
    "Uniform LBPでは、この遷移回数が0回のものと2回のものを特別視する。遷移の回数が0回、ということは、全ての要素が0か1かのいずれかで2通りが考えられる。また、遷移の回数が2回、ということは、0と1が両方含まれているものの、0と1が連続して現れているようなパターンで、これは要素の数が$N$個であれば、$N-1$通りのパターンが考えられる。\n",
    "\n",
    "以上より、遷移の回数が0回のものと2回のものの総数は$N+1$個ある。これ以外のパターンは全て同じものであると見なすと、パターンの総数は$N+2$個である。\n",
    "\n",
    "以下ではscikit-imageの`local_binary_pattern`を用いて、$N=36$とした場合のLBP画像を見てみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "n_angles = 36\n",
    "lbp = local_binary_pattern(X[0].reshape((48, 48)), n_angles, 1.0, method=\"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "gs = GridSpec(1, 2, width_ratios=[1, 1], figure=fig)\n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "\n",
    "ax1.imshow(lbp, cmap=\"gray\", interpolation=None)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title(\"There are {:d} values\".format(int(np.max(lbp)) + 1))\n",
    "\n",
    "ax2.hist(lbp.flatten(), bins=n_angles + 1, density=True)\n",
    "ax2.set_title(\"Histogram of Uniform LBP\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "すると、上記の通り、輝度のパターン数は36 + 2 = 38通りになることが分かる (画像の輝度が0から37の38通りになっている)。\n",
    "\n",
    "また、画像の見た目から、文字がある部分の周りが一様に近いグレーで表現されており、回転に対してある程度の不変性を持っていそうなことも確認できる。\n",
    "\n",
    "では、このUniform LBPを用いて、再度SVMによる文字の分類を試してみる。Uniform LBPを使う場合、画像の拡大縮小への対応力を上げるために、**中心画素からどのくらい離れたところの画素をLBPの計算に使うか**を変えつつ、LBPを取得して、それらを結合した特徴量を使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_ulbp_hist(x):\n",
    "    n_angles = [8, 16, 32]\n",
    "    radii = [1.0, 2.0, 4.0]\n",
    "    hists = []\n",
    "    for i in range(len(n_angles)):\n",
    "        lbp = local_binary_pattern(x, n_angles[i], radii[i], method=\"uniform\")\n",
    "        hist = np.histogram(lbp, bins=n_angles[i] + 1, density=True)[0]\n",
    "        hists.append(hist)\n",
    "    return np.concatenate(hists)\n",
    "\n",
    "\n",
    "X_ulbp = [calc_ulbp_hist(x.reshape((48, 48))) for x in tqdm(X)]\n",
    "X_ulbp = np.stack(X_ulbp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf4 = MySGDClassifier(**sgd_params)\n",
    "clf4.fit(X_ulbp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練時の識別精度の確認\n",
    "y_pred = clf4.predict(X_ulbp)\n",
    "acc_train = 100.0 * np.sum(y_pred == y) / len(y)\n",
    "glue(\"ulbp_acc_train\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"Uniform LBP\", acc_train, \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_ulbp_test = [calc_ulbp_hist(x.reshape((48, 48))) for x in tqdm(X_test)]\n",
    "X_ulbp_test = np.stack(X_ulbp_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テストデータに対する識別精度の計算\n",
    "y_pred = clf4.predict(X_ulbp_test)\n",
    "acc_test = 100.0 * np.sum(y_pred == y_test) / len(y_test)\n",
    "glue(\"ulbp_acc_test\", acc_test, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"Uniform LBP\", acc_test, \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**結果: 輝度ヒストグラムの利用**\n",
    "\n",
    "- 訓練時精度: {glue}`ulbp_acc_train`%\n",
    "- 評価時精度: {glue}`ulbp_acc_test`%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "すると、今度は訓練のスコアが悪化した代わりにテストスコアが上昇していることが分かる。しかしながら、これでも識別精度としては十分ではなく、回転対称性を考慮したことで精度が改善したとは言いがたい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Histogram of Oriented Gradient (HOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Histogram of Oriented Gradient (HOG)が広く知られるようになったのは2005年のことで、コンピュータ・ビジョンの国際会議であるCVPRで発表された論文{cite}`dalal2005histograms`がきっかけとなっている。\n",
    "\n",
    "特にHOGは人物の全身といった特定の物体を見つける性能に優れており、一般物体認識や物体追跡等の多数の応用が生まれた。\n",
    "\n",
    "HOGは画像を、互いに重ならない小さなパッチに分割して計算を行う。今回用いるひらがな画像は48×48の大きさなので、これを8×8のパッチに区切ってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "im = X[0].reshape((48, 48))\n",
    "s = 8\n",
    "patches = [im[y : y + 8, x : x + 8] for y in range(0, 48, s) for x in range(0, 48, s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 4))\n",
    "gs = GridSpec(6, 6, figure=fig)\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        ax = plt.subplot(gs[i, j])\n",
    "        ax.imshow(patches[i * 6 + j], cmap=\"gray\", vmin=0, vmax=255, interpolation=None)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "次に、この各画像に対して、勾配強度と勾配方向を画素ごとに計算する。以下の実装では、x方向の勾配$d_x$とy方向の勾配$d_y$をSobelフィルタを使って求め、勾配強度$g$と勾配方向$\\theta$を以下のように定義する。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    g &= \\sqrt{ d_x^2 + d_y^2 } \\\\\n",
    "    \\theta &= \\text{arctan} \\frac{|d_y|}{d_x}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "なお、今回は向きのない方向 (= orientation, 0°から180°)を求めるため、上記の$\\theta$の式において$d_y$に絶対値がかかっていることに注意すること。\n",
    "\n",
    "今、各パッチは8×8の大きさなので、勾配強度と勾配方向がそれぞれ64個ずつ求まる。求まった勾配方向をいくつかの方向に量子化 (今回は20°刻みで9方向)し、ヒストグラムを作成する。各画素の方向に対応するビンには勾配強度を足して、ヒストグラムを計算する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_hist(p, n_angles=9):\n",
    "    dx = cv2.Sobel(p, cv2.CV_8U, 1, 0)\n",
    "    dy = cv2.Sobel(p, cv2.CV_8U, 0, 1)\n",
    "    dx, dy = dx.astype(\"float32\"), dy.astype(\"float32\")\n",
    "\n",
    "    g = np.sqrt(dx * dx + dy * dy)\n",
    "    theta = 180.0 * np.arctan(np.abs(dy), dx) / np.pi\n",
    "    t = (theta * n_angles / 180.0).astype(\"int32\")\n",
    "\n",
    "    h = np.zeros((n_angles), dtype=\"float32\")\n",
    "    for g_, t_ in zip(g.flatten(), t.flatten()):\n",
    "        h[t_] += g_\n",
    "\n",
    "    return h\n",
    "\n",
    "\n",
    "n_angles = 9\n",
    "hists = np.array([calc_hist(p, n_angles) for p in patches])\n",
    "print(f\"{hists.shape[0]:d} histograms with {hists.shape[1]:d} bins are obtained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "これにより6×6=36個のヒストグラムが求まった。ここで注意したいのは、これらのヒストグラムは勾配強度で計算されており、場所によって、ヒストグラムのスケールが異なっているという点である。\n",
    "\n",
    "そこで、HOGでは、この6×6個のパッチを3×3のブロックごとに走査し、そのブロック内で連結したヒストグラムを正規化して用いる。今、勾配方向は9つに離散化されており、ブロック内のパッチが3×3=9個なので、1ブロックが持つヒストグラムの次元は9×9=81次元である。この81次元ベクトルをノルムが1になるように正規化しておく。\n",
    "\n",
    "最終的に、81次元のヒストグラムが複数 (今回の場合は(6-3+1)×(6-3+1)=16個)求まるので、これらを連結して、画像の特徴量として用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 3\n",
    "hists = hists.reshape((6, 6, -1))\n",
    "\n",
    "# ブロックの取り出し\n",
    "blocks = np.array(\n",
    "    [hists[i : i + bs, j : j + bs] for i in range(6 - bs + 1) for j in range(6 - bs + 1)]\n",
    ")\n",
    "hog = blocks.reshape((-1, n_angles * bs * bs))\n",
    "\n",
    "# ブロックごとのヒストグラムのノルムが1となるように正規化\n",
    "hog = hog / np.sqrt(np.sum(hog * hog, axis=1, keepdims=True))\n",
    "hog = hog.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "以上をまとめると、HOGを計算する関数を以下のように定義できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_hog(im):\n",
    "    h, w = im.shape\n",
    "    s = 8  # patch size\n",
    "    bs = 3  # block size\n",
    "    n_angles = 9  # number of angle bins\n",
    "\n",
    "    ph = h // s  # number of vertical patches\n",
    "    pw = w // s  # number of horizontal patches\n",
    "\n",
    "    # Divide image into patches, then compute orientation histogram for each patch\n",
    "    patches = [im[y : y + s, x : x + s] for y in range(0, h, s) for x in range(0, w, s)]\n",
    "    hists = np.array([calc_hist(p, n_angles) for p in patches])\n",
    "    hists = hists.reshape((ph, pw, -1))\n",
    "\n",
    "    # Normalize histogram within each block of patches\n",
    "    blocks = np.array(\n",
    "        [hists[i : i + bs, j : j + bs] for i in range(ph - bs + 1) for j in range(pw - bs + 1)]\n",
    "    )\n",
    "    hog = blocks.reshape((-1, n_angles * bs * bs))\n",
    "    hog = hog / (np.sqrt(np.sum(hog * hog, axis=1, keepdims=True)) + 1.0e-8)\n",
    "    hog = hog.flatten()\n",
    "\n",
    "    return hog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "計算されたHOGを用いて、再度SVMを用いた分類を試してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_hog = [calc_hog(x.reshape((48, 48))) for x in tqdm(X)]\n",
    "X_hog = np.stack(X_hog, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf5 = MySGDClassifier(**sgd_params)\n",
    "clf5.fit(X_hog, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練時の識別精度の確認\n",
    "y_pred = clf5.predict(X_hog)\n",
    "acc_train = 100.0 * np.sum(y_pred == y) / len(y)\n",
    "glue(\"hog_acc_train\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"HOG\", acc_train, \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_hog_test = [calc_hog(x.reshape((48, 48))) for x in tqdm(X_test)]\n",
    "X_hog_test = np.stack(X_hog_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テストデータに対する識別精度の計算\n",
    "y_pred = clf5.predict(X_hog_test)\n",
    "acc_test = 100.0 * np.sum(y_pred == y_test) / len(y_test)\n",
    "glue(\"hog_acc_test\", acc_test, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"HOG\", acc_test, \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**結果: Histogram of Oriented Gradientの利用**\n",
    "\n",
    "- 訓練時精度: {glue}`hog_acc_train`%\n",
    "- 評価時精度: {glue}`hog_acc_test`%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Bag of Visual Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ここまでの特徴量は、画素の情報を元にして何らかのヒストグラムを得る、という方法であったが、続いては、画像に内在する画像の構造としての特徴を疎に抽出し、その特徴の集合をヒストグラム化する手法である**Bag of Visual Words** (BoVW, Bag of Featuresとも呼ばれる)について見ていく。\n",
    "\n",
    "\n",
    "BoVWは、自然言語処理分野の**Bag of Words**から着想を得たもので、元のBag of Wordsは辞書に登録された各単語が文書の中に何回登場するかをヒストグラムとして表わした物である。\n",
    "\n",
    "これに対してBag of Visual Wordsは、画像データセットから抽出された疎な特徴量の集合を単語の集まりだと見なす。ただし、画像から得られる特徴量は通常連続的であるため、特徴量をあらかじめクラスタ分割しておき、各特徴が属するクラスタを単語、クラスタの集まりを辞書と見なすことでBag of Wordsと同様の処理を可能にする。\n",
    "\n",
    "以下では、画像に対する疎な特徴量の代表格である**Scale-Invariant Feature Transform** (SIFT)について、BoVWによる画像認識を試みる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Scale-Invariant Feature Transform (SIFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Scale-Invariant Feature Transform (SIFT)は、深層学習以前の画像認識における金字塔的な技術で、2000年前後にRoweらによって提案された{cite}`lowe1999object`, {cite}`lowe2004distinctive`。SIFTは画像の中に映り込む物体のスケールや回転に対して不変な特徴量を与えることができる。\n",
    "\n",
    "SIFT特徴量の抽出処理は、少々複雑だが、大まかに分けて\n",
    "\n",
    "- 特徴点の抽出\n",
    "- 特徴点に対する特徴量の計算\n",
    "\n",
    "の二つの処理に分けられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### 特徴点の抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**特徴点の抽出**に置いては、Difference of Gaussian (DoG)というフィルタを用いて、特徴点のスケールを計算する。DoGは二つの異なる$\\sigma_1$, $\\sigma_2$ (ただし$\\sigma_1 < \\sigma_2$とする)を用いて、\n",
    "\n",
    "$$\n",
    "\\text{DoG}(I) = G_{\\sigma_1} \\otimes I - G_{\\sigma_2} \\otimes I\n",
    "$$\n",
    "\n",
    "のように書ける。ただし$G_\\sigma$は$\\sigma$を標準偏差のパラメータとするGauss関数とする。例えば、以下のような画像になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.resize(X[0].reshape((48, 48)), (256, 256))\n",
    "img = (img / 255.0).astype(\"float32\")\n",
    "B1 = cv2.GaussianBlur(img, None, sigmaX=2.0)\n",
    "B2 = cv2.GaussianBlur(img, None, sigmaX=4.0)\n",
    "DoG = B1 - B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(img, cmap=\"gray\", vmin=0.0, vmax=1.0)\n",
    "axs[0].set(title=\"Input image\", xticks=[], yticks=[])\n",
    "axs[1].imshow(DoG, cmap=\"coolwarm\")\n",
    "axs[1].set(title=\"Difference of Gaussian\", xticks=[], yticks=[])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "DoGの抽出を初期のパラメータ$\\sigma$とスケールパラメータ$k$を用いて、$k^n\\sigma$と$k^{n+1}\\sigma$の間で$n=0, 1, 2, ...$の順で計算をしていく。この計算の過程でDoGの値が極値を取っていたら、そこをキーポイントの候補点として選ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "選ばれた候補点が実際に特徴点になるかどうかは、DoG値が極値を取るスケールにおいて、DoG画像$D$のその画素における勾配情報を参考にして決定する。具体的には、画像$D$から有限差分を用いて、ヘッセ行列\n",
    "\n",
    "$$\n",
    "\\mathbf{H} = \\begin{bmatrix}\n",
    "    D_{xx} & D_{xy} \\\\\n",
    "    D_{yx} & D_{yy} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "を計算し、$\\mathbf{H}$のトレースと行列式の比、\n",
    "\n",
    "$$\n",
    "\\rho = \\frac{(\\text{tr} \\mathbf{H})^2}{\\text{det}\\mathbf{H}}\n",
    "$$ (eq:ratio-tr-det)\n",
    "\n",
    "の値が一定の閾値$t$以下であれば、その候補特徴点を実際の特徴点として採用する。行列$\\mathbf{H}$の固有値を$\\lambda_1$, $\\lambda_2$ (ただし$\\lambda_1 > \\lambda_2$とするとき、トレースと行列式は、それぞれ$\\lambda_1 + \\lambda_2$, $\\lambda_1 \\lambda_2$と表せるので、{eq}`eq:ratio-tr-det`は、\n",
    "\n",
    "$$\n",
    "\\rho = \\frac{\\left( \\lambda_1 + \\lambda_2 \\right)^2}{\\lambda_1 \\lambda_2} = \\frac{\\left( 1 + \\frac{\\lambda_2}{\\lambda_1} \\right)^2}{\\frac{\\lambda_2}{\\lambda_1}} = \\frac{(1 + r)^2}{r^2}\n",
    "$$\n",
    "\n",
    "のように書き直せる。原論文では、$r = (\\lambda_2 / \\lambda_1) = 10$を用いて、閾値$t$を\n",
    "\n",
    "$$\n",
    "t = \\frac{(r + 1)^2}{r}\n",
    "$$\n",
    "\n",
    "のように定義している。$t$の値は$r$の変化に対して、以下のグラフのように、ほぼ線形に変化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "r = np.linspace(1.0, 50.0, 100, endpoint=True)\n",
    "t = (r + 1) ** 2 / r\n",
    "ax.plot(r, t)\n",
    "ax.set(title=\"$r$ vs $t$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "以上の処理を、直感的に述べれば、前半のDoGの処理は画像中の勾配がある箇所を検出し、さらに、その**勾配がどの程度の鮮鋭度を持つのかをスケールとして定量化**しようとしている。\n",
    "\n",
    "後半の処理、勾配の強さ (鮮鋭度は盛り上がりの角度であり、強さとは異なる)を見ており、$r = 10$とした場合に{eq}`eq:ratio-tr-det`が$t$より小さい、ということは、即ち**ヘッセ行列の2つの固有値の比が一定以下** (10:1以下)かを検証している。\n",
    "\n",
    "なお、この$r$の値は以下のOpenCVのコードでは`edgeThreshold`という変数に対応する。もし、各画像から検出される特徴点が少なすぎるようであれば、この値を少し上げると、固有値の差が小さい(=エッジがそれほど先鋭ではない)特徴点も残されるようになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "また、詳細は割愛するが、各特徴点には、勾配方向も同時に計算される。これは特徴点周りの画素に対して計算された勾配方向のヒストグラムの中で、いくつかの支配的な方向を特徴点に与えるものである。従って、各特徴点には2つ以上の勾配方向が割り当てられる可能性がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "では、実際にOpenCVを用いて画像からSIFT特徴点と特徴量を計算する。以下では、特徴量の抽出結果を分かりやすくするために、48×48画素の画像を256×256画素にリサイズして特徴量を計算している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# 画像のリサイズ\n",
    "img = X[0].reshape((48, 48)).copy()\n",
    "img = cv2.resize(img, (256, 256))\n",
    "\n",
    "# 特徴量抽出器の準備\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# 特徴点の検出\n",
    "keypoints = sift.detect(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "前述の通り、SIFT特徴点の検出では、位置、スケール、勾配方向が計算されるので、それらを`cv2.drawKeypoints`で可視化してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 特徴点の描画 (画像に書き込みをするだけで表示はしない)\n",
    "img_sift = cv2.drawKeypoints(\n",
    "    img,\n",
    "    keypoints,\n",
    "    None,\n",
    "    flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axs[0].set(title=\"Input image\", xticks=[], yticks=[])\n",
    "axs[1].imshow(img_sift)\n",
    "axs[1].set(\n",
    "    title=\"{:d} keypoints detected\".format(len(keypoints)),\n",
    "    xticks=[],\n",
    "    yticks=[],\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "画像中では、円の中心が特徴点の位置を、円の大きさが特徴点のスケールを、そして円の中心から弧に向かって伸びる線分が勾配方向をそれぞれ表わしている。この際、文字の輪郭線のぼけ具合と円の大きさに相関があり、なおかつ勾配方向が輪郭線とおよそ直交する方向となっていることに注目してほしい。また、特徴点の中には2つ以上の勾配方向を持つものが存在することにも注目してほしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### 特徴量の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "特徴量の計算には、特徴点の計算で得られたスケールと方向を用いる。特徴量の計算には4×4のグリッドを用いるのだが、このグリッドの大きさを特徴点のスケールに応じて拡大縮小し、また勾配方向に応じてグリッドの向きを変更する。\n",
    "\n",
    "このグリッドは上記の特徴点の可視化に現れる特徴点のスケールを表わす円に外接するように配置される。この円の大きさは、より具体的には極大のDoG値が検出された時に用いたGauss関数の$\\sigma$の大きさに対応している。\n",
    "\n",
    "グリッドの姿勢が計算できたら、4×4=16個のグリッドのそれぞれについて、特徴点の勾配方向ヒストグラムを45°刻みの8方向について計算する。この8個のビンの値を16個分連結することで、SIFT特徴量としての128次元ベクトルが得られる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "では、先ほど求めた特徴点に対して、OpenCVを用いて特徴量(記述子=descriptorとも言う)を計算する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 特徴量の計算\n",
    "_, features = sift.compute(img, keypoints)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "このように特徴量 (`features`)は「特徴点の数」×「特徴量の次元=128」で与えられることが確認できる。なお、特徴点の抽出と特徴量の計算は`sift.detectAndCompute`を用いることで同時に行うこともできる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    ":::{admonition} 技術と特許\n",
    ":class: note\n",
    "\n",
    "新しい技術を開発して「特許」を取得すると、その技術の詳細を明細書として公開する代わりに、その技術に関わる権利を得ることができる。この特許は、一見、他の会社が当該の技術を使う障壁を上げており、技術の進歩にとってはマイナスな一面もある。\n",
    "\n",
    "その一方、特許が取られていたがために、その技術を回避する目的で技術が進歩することもある。先に紹介したSIFTは当初2000年に特許が取得された(2020年に失効)が、それに変わる技術として、Speeded-Up Robust Features (SURF) {cite}`bay2006surf`などの多くの特徴量が提案された (SURFは2006年に特許が取得されており、こちらはまだ特許が切れていない)。\n",
    "\n",
    "このような例は他の分野でも、たびたび見られるもので、CT画像から物体の表面形状を抽出するMarching Cubes法も、その特許権を回避する目的で、ほとんど同等なMarching Tetrahedra法が開発されたりした。このように、物事には表と裏とがあるのが常である。\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 特徴量のクラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "BoVWを計算するためには、訓練データに含まれる全ての画像について、特徴量を計算し、それをクラスタリングする必要がある。以下のコードでは、48×48という比較的小さな画像を扱うために`edgeThreshold`を調整して、検出される特徴点の数を増やしている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "extractor = cv2.SIFT_create(edgeThreshold=20, contrastThreshold=0.0)\n",
    "\n",
    "features = []\n",
    "for x in tqdm(X):\n",
    "    img = x.reshape((48, 48))\n",
    "    keypoints, feature = extractor.detectAndCompute(img, None)\n",
    "    assert len(keypoints) > 0, \"No keypoints detected!\"\n",
    "    features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_features = np.concatenate(features, axis=0)\n",
    "print(\"SIFT: {:d} keypoints are detected!\".format(len(all_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "特徴量が得られたら、これをk平均法 (k-means法)によってクラスタリングする。今回は、scikit-learnの`MiniBatchKMeans`を用いてクラスタリングを行う (`KMeans`というクラスもあるが、こちらは計算にかなり時間がかかる)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans as KMeans\n",
    "\n",
    "cb_size = 64\n",
    "cls = KMeans(n_clusters=cb_size, max_iter=1000, tol=1.0e-4)\n",
    "cls.fit(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_bovw = []\n",
    "for feature in tqdm(features):\n",
    "    distances = cls.transform(feature)\n",
    "    ids = np.argmin(distances, axis=1)\n",
    "    hist = np.bincount(ids, minlength=cb_size)\n",
    "    X_bovw.append(hist)\n",
    "\n",
    "X_bovw = np.stack(X_bovw, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf6 = MySGDClassifier(**sgd_params)\n",
    "clf6.fit(X_bovw, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練時の識別精度の確認\n",
    "y_pred = clf6.predict(X_bovw)\n",
    "acc_train = 100.0 * np.sum(y_pred == y) / len(y)\n",
    "glue(\"bovw_acc_train\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"BoVW\", acc_train, \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_bovw_test = []\n",
    "for x in tqdm(X_test):\n",
    "    img = x.reshape((48, 48))\n",
    "    keypoints, feature = extractor.detectAndCompute(img, None)\n",
    "    assert len(keypoints) > 0, \"No keypoints detected!\"\n",
    "    distances = cls.transform(feature)\n",
    "    ids = np.argmin(distances, axis=1)\n",
    "    hist = np.bincount(ids, minlength=cb_size)\n",
    "    X_bovw_test.append(hist)\n",
    "\n",
    "X_bovw_test = np.stack(X_bovw_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テスト時の識別精度の確認\n",
    "y_pred = clf6.predict(X_bovw_test)\n",
    "acc_test = 100.0 * np.sum(y_pred == y_test) / len(y)\n",
    "glue(\"bovw_acc_test\", acc_test, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"BoVW\", acc_test, \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**結果: Bag of Visual Wordsの利用**\n",
    "\n",
    "- 訓練時精度: {glue}`bovw_acc_train`%\n",
    "- 評価時精度: {glue}`bovw_acc_test`%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Gauss混合モデルを用いた改良"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "上記の例では、離散的に特徴量をクラスタ分割して、**最も近いクラスタ**に対して、各特量を割り当てることでヒストグラムを作成した。ただし、複数のクラスタの境界に特徴量が存在している可能性もあるため、その情報を捨てて、一番近いクラスタに特徴量を割り当てるのは、あまり適切とは言えない。\n",
    "\n",
    "そこで、クラスタリングを用いる代わりに、特徴量の分布をGauss混合モデルによって近似しておき、各ガウス分布への寄与 (小数で表わされる)の和を画像の特徴ベクトルとして与えることを考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Gauss混合モデル**とは、複数のGauss分布を和が1となるような正の重みによって重み付けたものであり、確率密度関数$P(\\mathbf{x} | \\boldsymbol\\Theta)$, $\\mathbf{x} \\in \\mathbb{R}^D$が以下の形で書ける。\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x} | \\boldsymbol\\Theta) = \\sum_{k=1}^K \\frac{\\alpha_k}{(2 \\pi)^{D / 2} \\left| \\boldsymbol\\Sigma_k \\right|^{1/2}} \\exp \\left( - \\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu}_k)^\\top \\boldsymbol\\Sigma_k^{-1}  (\\mathbf{x} - \\boldsymbol{\\mu}_k) \\right)\n",
    "$$ (eq:gaussian-mixture)\n",
    "\n",
    "のように書ける。この式で$\\boldsymbol\\Theta$はパラメータの集合 $\\{ \\alpha_k, \\boldsymbol\\mu_k, \\boldsymbol\\Sigma_k : k = 1, \\ldots, K \\}$を表わし、$\\alpha_k \\in [0, 1)$, $\\boldsymbol\\mu_k \\in \\mathbb{R}^D$, $\\boldsymbol\\Sigma_k \\in \\mathbb{R}^{D \\times D}$は、それぞれ$k$番目のGauss分布に対する混合率、分布中心、共分散行列を表わす。\n",
    "\n",
    "ガウス混合分布を用いると、とある特徴量$\\mathbf{x}$が$k$個のGauss分布のそれぞれにどの程度の寄与率$\\gamma_k(\\mathbf{x})$を持つかを以下のように計算できる。\n",
    "\n",
    "$$\n",
    "\\gamma_k(\\mathbf{x}) = \\frac{\\alpha_k}{(2\\pi)^{D/2} \\left| \\boldsymbol\\Sigma_k \\right|^{1/2}}\\frac{\\exp \\left( - \\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu}_k)^\\top \\boldsymbol\\Sigma_k^{-1}  (\\mathbf{x} - \\boldsymbol{\\mu}_k) \\right) }{P(\\mathbf{x})}\n",
    "$$ (eq:membership)\n",
    "\n",
    "これにより、特徴量$\\mathbf{x}$に対する、特徴表現として、\n",
    "\n",
    "$$\n",
    "\\boldsymbol\\gamma = (\\gamma_1(\\mathbf{x}), \\ldots, \\gamma_K(\\mathbf{x})^\\top\n",
    "$$\n",
    "\n",
    "が得られる。これを画像に含まれる特徴量の集合$\\mathcal{X} = \\{ \\mathbf{x}_i : i = 1, \\ldots, N \\}$に対して計算し、その平均値を画像の特徴ベクトルとする。\n",
    "\n",
    "$$\n",
    "\\mathbf{f}(\\mathcal{X}) = \\frac{1}{N} \\sum_{i=1}^N \\boldsymbol\\gamma(\\mathbf{x}_i)\n",
    "$$\n",
    "\n",
    "ここまでの議論を踏まえて、BoVWを改善したコードが以下になる。ここではscikit-learnの`GaussianMixture`を用いてGauss混合モデルのフィッティングを行う。ただし、Gauss混合モデルのフィッティングは、かなり時間のかかる処理であるため、計算時間を短縮するために、最初に主成分分析で特徴量の次元を減らしておき、そのデータに対してGauss混合モデルをフィッティングする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "sub_features = pca.fit_transform(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(\n",
    "    n_components=cb_size,\n",
    "    covariance_type=\"diag\",\n",
    "    init_params=\"k-means++\",\n",
    "    reg_covar=1.0e-1,\n",
    "    max_iter=20,\n",
    "    tol=1.0e-3,\n",
    "    n_init=1,\n",
    ")\n",
    "gmm.fit(sub_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_bovw2 = []\n",
    "for feature in tqdm(features):\n",
    "    sub_f = pca.transform(feature)\n",
    "    probs = gmm.predict_proba(sub_f)\n",
    "    X_bovw2.append(probs.mean(axis=0))\n",
    "\n",
    "X_bovw2 = np.stack(X_bovw2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf7 = MySGDClassifier(**sgd_params)\n",
    "clf7.fit(X_bovw2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練時の識別精度の確認\n",
    "y_pred = clf7.predict(X_bovw2)\n",
    "acc_train = 100.0 * np.sum(y_pred == y) / len(y)\n",
    "glue(\"bovwg_acc_train\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"GMM-BoVW\", acc_train, \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_bovw2_test = []\n",
    "for x in tqdm(X_test):\n",
    "    img = x.reshape((48, 48))\n",
    "    _, feature = extractor.detectAndCompute(img, None)\n",
    "    sub_f = pca.transform(feature)\n",
    "    probs = gmm.predict_proba(sub_f)\n",
    "    X_bovw2_test.append(probs.mean(axis=0))\n",
    "\n",
    "X_bovw2_test = np.stack(X_bovw2_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テスト時の識別精度の確認\n",
    "y_pred = clf7.predict(X_bovw2_test)\n",
    "acc_test = 100.0 * np.sum(y_pred == y_test) / len(y)\n",
    "glue(\"bovwg_acc_test\", acc_test, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"GMM-BoVW\", acc_test, \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**結果: GMM-BoVW**\n",
    "\n",
    "- 訓練時精度: {glue}`bovwg_acc_train`%\n",
    "- 評価時精度: {glue}`bovwg_acc_test`%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Fisherベクトルの利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "BoVWの改良としてFisherベクトルを利用する手法は2007年にPerronninらによって提案された{cite}`perronnin2007fisher`。Fisherベクトルは、統計学等でも用いられるFisher情報量に基づく特徴表現である。とある確率密度分布が$\\mathbf{x} \\in \\mathcal{X}$のパラメータ (母数)$\\boldsymbol\\Theta$に関する事後分布として $P(\\mathbf{x} | \\boldsymbol\\Theta)$のように与えられる場合を考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Fisherベクトルの導出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Fisher情報量を求めるに当たり、Fisherベクトル$V(\\mathbf{x}; \\boldsymbol\\Theta)$を\n",
    "\n",
    "$$\n",
    "V(\\mathbf{x}; \\boldsymbol\\Theta) = \\nabla_{\\boldsymbol\\Theta} \\log P(\\mathbf{x} | \\boldsymbol\\Theta)\n",
    "$$\n",
    "\n",
    "のように表わす。なお、確率密度関数が連続関数であるとき、このFisherベクトルの平均はゼロベクトルになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Fisher情報量は上記のFisherベクトルの分散として定義される。この際、Fisherベクトルの平均が$\\mathbf{0}$であることを用いると次の式で与えられる。\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{\\mathbf{x} \\sim \\mathcal{X}} \\left[ \\nabla_{\\boldsymbol\\Theta} \\log P(\\mathbf{x} | \\boldsymbol\\Theta)) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "さて、ここで、$P(\\mathbf{x} | \\boldsymbol\\Theta)$が{eq}`eq:gaussian-mixture`のガウス混合分布で与えられる場合を考える。以後、計算を簡単にするために、共分散行列は対角成分を$\\boldsymbol\\sigma_k$とする対角行列であるとする。\n",
    "\n",
    "とあるパラメータ$\\theta$に関する$\\ln P(\\mathbf{x} | \\boldsymbol\\Theta)$の微分は、\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log P(\\mathbf{x}| \\boldsymbol\\Theta)}{\\partial \\theta} = \\frac{1}{P(\\mathbf{x} | \\boldsymbol\\Theta)} \\frac{\\partial P}{\\partial\\theta}\n",
    "$$\n",
    "\n",
    "と書けることは言うまでもない。また、$P(\\mathbf{x} | \\boldsymbol\\Theta)$の$\\pi_k$, $\\mu_{k,d}$, $\\sigma_{k,d}$に関する偏微分はそれぞれ以下のように書ける。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial P(\\mathbf{x} | \\boldsymbol\\Theta)}{\\partial \\alpha_k}\n",
    "&= \\frac{\\exp \\left( -\\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu}_k)^\\top \\boldsymbol\\Sigma_k^{-1}  (\\mathbf{x} - \\boldsymbol{\\mu}_k) \\right)}{(2\\pi)^{D/2} | \\boldsymbol\\Sigma_k |^{1/2}} = \\frac{\\mathcal{N}(\\mathbf{x} | \\boldsymbol\\mu_{k}, \\boldsymbol\\sigma_k)}{\\alpha_k} \\\\\n",
    "%\n",
    "\\frac{\\partial P(\\mathbf{x} | \\boldsymbol\\Theta)}{\\partial \\mu_{k,d}}\n",
    "&= \\alpha_k \\frac{x_d - \\mu_{k,d}}{\\sigma_{k,d}^2} \\mathcal{N}(\\mathbf{x} | \\boldsymbol\\mu_{k}, \\boldsymbol\\sigma_k) \\\\\n",
    "%\n",
    "\\frac{\\partial P(\\mathbf{x} | \\boldsymbol\\Theta)}{\\partial \\sigma_{k,d}}\n",
    "&= \\alpha_k \\left[ \\frac{(x_d - \\mu_{k,d})^2}{\\sigma_{k,d}^3} - \\frac{1}{\\sigma_{k,d}} \\right] \\mathcal{N}(\\mathbf{x} | \\boldsymbol\\mu_{k}, \\boldsymbol\\sigma_k)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "したがって、{eq}`eq:membership`の寄与率$\\gamma_k$を用いると、フィッシャーベクトルの各次元は以下のように書き直せる。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\log P(\\mathbf{x}| \\boldsymbol\\Theta)}{\\partial \\alpha_k}\n",
    "&= \\frac{\\gamma_k(\\mathbf{x})}{\\alpha_k} \\\\\n",
    "%\n",
    "\\frac{\\partial \\log P(\\mathbf{x}| \\boldsymbol\\Theta)}{\\partial \\mu_{k,d}}\n",
    "&= \\gamma_k(\\mathbf{x}) \\left[ \\frac{x_d - \\mu_{k,d}}{\\sigma_{k,d}^2} \\right] \\\\\n",
    "%\n",
    "\\frac{\\partial \\log P(\\mathbf{x}| \\boldsymbol\\Theta)}{\\partial \\sigma_{k,d}}\n",
    "&= \\gamma_k(\\mathbf{x}) \\left[ \\frac{(x_d - \\mu_{k,d})^2}{\\sigma_{k,d}^3}  - \\frac{1}{\\sigma_{k,d}} \\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ここで、$\\mathcal{X} = \\{ \\mathbf{x}_1, \\ldots, \\mathbf{x}_N \\}$として、これらの同時分布$P(\\mathcal{X} | \\boldsymbol\\Theta)$を考える。$\\mathbf{x}_i$は互いに独立なサンプルであるので、\n",
    "\n",
    "$$\n",
    "P(\\mathcal{X} | \\boldsymbol\\Theta) = \\prod_{i=1}^N P(\\mathbf{x}_i | \\boldsymbol\\Theta)\n",
    "$$\n",
    "\n",
    "故に、この対数尤度$L(\\mathcal{X} | \\boldsymbol\\Theta)$は、\n",
    "\n",
    "$$\n",
    "L(\\mathcal{X} | \\boldsymbol\\Theta) = \\sum_{i=1}^N \\log P(\\mathbf{x}_i | \\boldsymbol\\Theta)\n",
    "$$\n",
    "\n",
    "となることが分かる。この尤度関数のパラメータに関する偏微分からFisherベクトルを求めると、以下のようになる。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(\\mathcal{X} | \\boldsymbol\\Theta)}{\\partial \\alpha_k}\n",
    "= \\sum_{i=1}^N \\left[ \\frac{\\gamma_k(\\mathbf{x}_i)}{\\alpha_k} - \\frac{\\gamma_1(\\mathbf{x}_i)}{\\alpha_1}  \\right] \\quad \\text{for} ~ k \\geq 2  $$ (eq:deriv-alpha)\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(\\mathcal{X} | \\boldsymbol\\Theta)}{\\partial \\mu_{k,d}}\n",
    "= \\sum_{i=1}^N \\gamma_k(\\mathbf{x}_i) \\left[ \\frac{x_d - \\mu_{k,d}}{\\sigma_{k,d}^2} \\right] \\\\\n",
    "$$ (eq:deriv-mu)\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(\\mathcal{X} | \\boldsymbol\\Theta)}{\\partial \\sigma_{k,d}}\n",
    "= \\sum_{i=1}^N \\gamma_k(\\mathbf{x}_i) \\left[ \\frac{(x_d - \\mu_{k,d})^2}{\\sigma_{k,d}^3} - \\frac{1}{\\sigma_{k,d}} \\right]\n",
    "$$ (eq:deriv-sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ただし、{eq}`eq:deriv-alpha`では、$\\sum_{k} \\alpha_k = 1$であることを用いて、自由度を一つ減らしてある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ここまでの式から、Fisherベクトルの次元は$\\alpha_k$に関する成分が$K - 1$次元、$\\mu_{k,d}$に関する成分が$DK$次元、$\\sigma_{k,d}$に関する成分が$DK$次元あるので、合計で$(2D + 1) K - 1$次元となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Fisherベクトルの意味"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "上記の通り、Fisherベクトルはとあるデータ集合$\\mathcal{X}$を近似的に表わすGauss混合モデルについて、そのパラメータ$\\boldsymbol\\Theta$に関する勾配を要素に持つ。この意味を考えてみよう。\n",
    "\n",
    "とある確率密度関数をサンプルにフィッティングする問題を考えるとき、その確率密度関数の対数尤度が最大になるようにパラメータを最適化する。従って、**Fisherベクトルの各要素は、そのパラメータの変化が、どの程度尤度に影響を与えるかを示している**、と言い換えられる。\n",
    "\n",
    "この影響を大きさの期待値を表わしているのがFisher情報量であり、各パラメータに関するFisher情報両はFisherベクトルの各要素の二乗平均により与えられる。Fisher情報量は、推定するパラメータを正しく推定するために、どの程度十分な情報(=サンプル)が得られているかを示しており、**情報量が大きければ大きいほど、サンプルから求まるパラメータの最尤推定量が真の値に近づくことが期待される** (推定量の分散とFisher情報量の逆数の関係はCramér-Raoの不等式で与えられる)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "従って、とある画像に対して計算されるFisherベクトルは、**その画像(から得られた特徴量の集合)が、画像全体(のGauss混合分布)から見て、どのようなの意外性を持つか、と言い換えても良い**。その画像が全体のGauss混合分布にとって十分尤もらしいものであれば、尤度の勾配から定まるFisherベクトルの要素は小さな値(特に意外ではない)を取り、そうでなければ、大きな値(意外である)を取る、という訳である。\n",
    "\n",
    "ただし、画像の分類の観点から言えば、Fisherベクトルがどのような意味を持つか、ということよりも、それ自体が、単なるクラスタへの所属や、Gauss混合モデル以上に画像を上手く表現できるような特徴を与えるということに価値がある。\n",
    "\n",
    "実際、{eq}`eq:deriv-alpha`は画像が含む特徴量に関して、どの分布にどのくらいの割合で属するかを表わす0次統計量であるのに対し、{eq}`eq:deriv-mu`ならびに{eq}`eq:deriv-sigma`は、それぞれ1次統計量、2次統計量を表わしている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Fisherベクトルを用いた画像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "それでは、実際に全画像から取得したSIFT特徴量を用いて、各画像に対応するFisherベクトルを求めてみよう。Perronninらの元論文 {cite}`perronnin2007fisher`では、計算量を削減するために、得られたSIFT特徴量を主成分分析によって50次元減らした後、Gauss混合モデルをフィッティングしてFisherベクトルを求めている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "X_fv = []\n",
    "for feature in tqdm(features):\n",
    "    sub_f = pca.transform(feature)  # (N, D)\n",
    "    gamma = gmm.predict_proba(sub_f)  # (N, K)\n",
    "    alpha = gmm.weights_  # (K)\n",
    "    mu = gmm.means_  # (K, D)\n",
    "    sigma = gmm.covariances_  # (K, D)\n",
    "\n",
    "    g_over_a = gamma / alpha\n",
    "    dLda = np.sum(g_over_a[:, 1:] - g_over_a[:, 0:1], axis=0)\n",
    "\n",
    "    tmp0 = (sub_f[:, None, :] - mu[None, :, :]) / (sigma[None, :, :] ** 2)\n",
    "    dLdm = np.sum(gamma[:, :, None] * tmp0, axis=0)\n",
    "\n",
    "    tmp0 = (sub_f[:, None, :] - mu[None, :, :]) ** 2 / (sigma[None, :, :] ** 3)\n",
    "    tmp1 = 1.0 / sigma[None, :, :]\n",
    "    dLds = np.sum(gamma[:, :, None] * (tmp0 - tmp1), axis=0)\n",
    "\n",
    "    fv = np.concatenate([dLda, dLdm.reshape((-1)), dLds.reshape((-1))])\n",
    "    X_fv.append(fv)\n",
    "\n",
    "X_fv = np.stack(X_fv, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf8 = MySGDClassifier(**sgd_params)\n",
    "clf8.fit(X_fv, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 訓練時の識別精度の確認\n",
    "y_pred = clf8.predict(X_fv)\n",
    "acc_train = 100.0 * np.sum(y_pred == y) / len(y)\n",
    "glue(\"fisher_acc_train\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"Fisher-BoVW\", acc_train, \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_fv_test = []\n",
    "for x in tqdm(X_test):\n",
    "    img = x.reshape((48, 48))\n",
    "    _, feature = extractor.detectAndCompute(img, None)\n",
    "\n",
    "    sub_f = pca.transform(feature)  # (N, D)\n",
    "    gamma = gmm.predict_proba(sub_f)  # (N, K)\n",
    "    alpha = gmm.weights_  # (K)\n",
    "    mu = gmm.means_  # (K, D)\n",
    "    sigma = gmm.covariances_  # (K, D)\n",
    "\n",
    "    g_over_a = gamma / alpha\n",
    "    dLda = np.sum(g_over_a[:, 1:] - g_over_a[:, 0:1], axis=0)\n",
    "\n",
    "    tmp0 = (sub_f[:, None, :] - mu[None, :, :]) / (sigma[None, :, :] ** 2)\n",
    "    dLdm = np.sum(gamma[:, :, None] * tmp0, axis=0)\n",
    "\n",
    "    tmp0 = (sub_f[:, None, :] - mu[None, :, :]) ** 2 / (sigma[None, :, :] ** 3)\n",
    "    tmp1 = 1.0 / sigma[None, :, :]\n",
    "    dLds = np.sum(gamma[:, :, None] * (tmp0 - tmp1), axis=0)\n",
    "\n",
    "    fv = np.concatenate([dLda, dLdm.reshape((-1)), dLds.reshape((-1))])\n",
    "    X_fv_test.append(fv)\n",
    "\n",
    "X_fv_test = np.stack(X_fv_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テスト時の識別精度の確認\n",
    "y_pred = clf8.predict(X_fv_test)\n",
    "acc_test = 100.0 * np.sum(y_pred == y_test) / len(y)\n",
    "glue(\"fisher_acc_test\", acc_train, display=False)\n",
    "result_df.loc[len(result_df), :] = [\"Fisher-BoVW\", acc_test, \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**結果: FisherベクトルによるBoVW**\n",
    "\n",
    "- 訓練時精度: {glue}`fisher_acc_train:.2f`%\n",
    "- 評価時精度: {glue}`fisher_acc_test:.2f`%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 手法の比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ここまでの手法の訓練時、ならびにテスト時のスコアを"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "ax = sns.barplot(\n",
    "    x=\"Method\",\n",
    "    y=\"Accuracy\",\n",
    "    hue=\"Phase\",\n",
    "    data=result_df.round(2),\n",
    "    errwidth=0,\n",
    ")\n",
    "\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 練習問題\n",
    "\n",
    "1. LBPとUniform LBPについて、文字の画像の輝度を増減したり、画像を回転させたときに、その特徴量がどのように変化するかを調べよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 参考文献\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    ":style: alpha\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
