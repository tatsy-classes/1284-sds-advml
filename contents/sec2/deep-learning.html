

<!DOCTYPE html>


<html lang="ja" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>3. 深層学習による物体認識 &#8212; 機械学習発展 (実践)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/custom.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'contents/sec2/deep-learning';</script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="検索" href="../../search.html" />
    <link rel="next" title="4. 演習2 - 百人一首エージェントを作る" href="exercise-ogura.html" />
    <link rel="prev" title="2. 特徴量抽出" href="feature-extraction.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ja"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">機械学習発展 (実践)</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">第1部 画像読み取り式数独ソルバの実装</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../sec1/setup-python.html">1. Python環境の設定</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec1/numpy.html">2. NumPyの基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec1/matplotlib.html">3. Matplotlibの基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec1/pandas.html">4. Pandasの基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec1/opencv.html">5. OpenCVの基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec1/figure-detection.html">6. 図形の検出</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec1/scikit-learn.html">7. scikit-learnによる機械分類の基本</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec1/exercise-sudoku.html">8. 演習1 - 画像入力式数独ソルバーを作る</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">第2部 ひらがなOCRソフトと百人一首エージェントの実装</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data-visualization.html">1. データ可視化と次元圧縮</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature-extraction.html">2. 特徴量抽出</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">3. 深層学習による物体認識</a></li>
<li class="toctree-l1"><a class="reference internal" href="exercise-ogura.html">4. 演習2 - 百人一首エージェントを作る</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">第3部 強化学習の基礎とリバーシエージェントの実装</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../sec3/reinforcement-learning.html">1. 強化学習の基礎</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec3/q-learning.html">2. Q学習</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec3/othello-agent.html">3. オセロAIの作成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec3/deep-reinforcement-learning.html">4. 深層強化学習</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sec3/exercise-othello.html">5. 演習3 - オセロエージェントを作る</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendix/notation.html">資料中の表記について</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/tatsy/1284-sds-ml-advanced/blob/master/./contents/sec2/deep-learning.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/tatsy/1284-sds-ml-advanced" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="ソースリポジトリ"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tatsy/1284-sds-ml-advanced/issues/new?title=Issue%20on%20page%20%2Fcontents/sec2/deep-learning.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="問題を報告"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="このページをダウンロード">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/contents/sec2/deep-learning.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="ソースファイルをダウンロード"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="PDFに印刷"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="全画面モード"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="検索" aria-label="検索" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>深層学習による物体認識</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> 目次 </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.1. 深層学習の歴史</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch">3.2. PyTorchの基本</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torch-tensor">3.2.1. torch.Tensor</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">torch.Tensorを使う</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">torch.tensorを使う</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#torch-from-numpy">torch.from_numpy</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">3.2.2. torch.Tensorからの値の取り出し</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">3.3. 自動微分</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">3.3.1. 自動微分の仕組み</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">3.3.2. 自動微分の利用</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">3.3.3. 自動微分可能な演算の定義</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">3.3.4. 二階微分の計算</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">3.3.5. 多変数関数の微分</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">3.4. ニュートン法の実装</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">3.5. 深層学習</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">3.5.1. データローダの作成</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ssec-network-architecture">3.5.2. ネットワークの構築</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">3.5.3. 学習の準備</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">3.5.4. 最適化手法の設定</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id21">3.5.5. 誤差関数の設定</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id22">3.6. 畳み込みニューラルネット</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id23">3.7. 練習問題</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id24">3.8. 参考文献</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="sec-deep-learning">
<span id="id1"></span><h1><span class="section-number">3. </span>深層学習による物体認識<a class="headerlink" href="#sec-deep-learning" title="Permalink to this heading">#</a></h1>
<p>前回、<a class="reference internal" href="feature-extraction.html#sec-feature-extraction"><span class="std std-ref">特徴量抽出</span></a>では、画像から特徴量を検出し、それを画像認識に利用する方法を見てきた。</p>
<p>2000年台まで、画像認識の分野では、<strong>画像を如何に特徴化するか</strong>と<strong>得られた特徴からどのように物体を認識するか</strong>という二つの研究が中心となってきた。</p>
<p>そのために、SIFTを始めとする特徴量の改善や、カーネル法を用いたSVMの性能改善などが試みられてきたが、その性能は徐々に頭打ちになっていく。</p>
<section id="id2">
<h2><span class="section-number">3.1. </span>深層学習の歴史<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>そんな折、彗星のごとく現れた技術がニューラルネットワークを多層化した深層学習である。実は、ニューラルネット自体は人間の脳のシナプス同士の結合を模したモデルとして1950年代から研究されていた。</p>
<p>最初にニューラルネットが日の目を見たのは1980年代で、この頃には、入力層、隠れ層、出力層の三層を持つニューラルネットがある程度の性能を出せることが知られていた。当然ながら、その当時も、より多層のニューラルネットワークを利用しようという考え自体はあり、検討が試みられたが、ニューラルネットワークの持つ多数のパラメータを上手く最適化する手法がなく、その時代には実現が難しいと考えられていた。</p>
<p>なお、多層のニューラルネットの考え方を最初に提唱したのは、当時NHKの放送技術研究所の研究員であった福島邦彦氏であるとされており、その論文は、驚くべきことに1980年に出版されている <span id="id3">[<a class="reference internal" href="#id34" title="Kunihiko Fukushima. Neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological Cybernetics, 36(4):193–202, apr 1980. doi:10.1007/bf00344251.">Fukushima, 1980</a>]</span>。</p>
<p>2010年代に入ると、それまで下火だったニューラルネットが再び注目を集めることになる。それまで細々と続けられていたニューラルネットワークの研究の中で、パラメータの過学習や、最適化時の勾配消失といった問題が徐々に解決されるとともに、GPUを用いた汎用計算であるGPGPU (General Purpose Computing on GPU)により並列計算の公立が大幅に上昇するなど、ニューラルネットワークを取り巻く環境が徐々に変化してくる。そして、2012年に事件が起こる。</p>
<p>ImageNetと呼ばれる大規模画像データセットの識別チャレンジであるILSVRC (ImageNet Large Scale Visual Recognition Challenge)において、トロント大学のGeoffrey Hintonらの研究チームが、AlexNet (筆頭著者のfirst nameから)と呼ばれる二股のニューラルネットを用いて、2位のエラー率26.2%に大差をつけ、エラー率わずか17.0％を達成し、優勝する <span id="id4">[<a class="reference internal" href="#id33" title="Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Proceedings of the 25th International Conference on Neural Information Processing Systems, 1097–1105. 2012. doi:10.1145/3065386.">Krizhevsky <em>et al.</em>, 2012</a>]</span>。この時の2位のチームが用いた手法はSIFT, Fisher Vector, SVMを組み合わせたものであった。</p>
<p>この優勝を皮切りに、2013年の大会ではオックスフォード大学のチームがVGGというネットワークで2位に入り、以後、2014年はGoogleのチームがGoogLeNetというネットワークで2位、2015年はMicrosoftのチームがResNetというネットワークで優勝する。</p>
<p>こうして、2016年くらいになると、現在のニューラルネットワークの構築において一般的になっている諸技術、例えば、</p>
<ul class="simple">
<li><p>Rectified Linear Unit (ReLU)</p></li>
<li><p>Max Pooling</p></li>
<li><p>Dropout</p></li>
<li><p>Batch Normalization</p></li>
<li><p>Skip Connection (Residual Block)</p></li>
<li><p>Adaptive Momentum Estimation (Adam)</p></li>
</ul>
<p>などの技術が、一通り出そろう。</p>
<p>さらには、この頃になるとNVIDIAのCaffeや、モントリオール大学のtheano、FacebookのTorch、そしてPreferred NetworkのChainerといった汎用の深層学習用ライブラリが多数登場する。これによって、深層学習の研究が一気に花開き、現在に至る。</p>
<hr class="docutils" />
<p><strong>Google Colab用の準備</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">IN_COLAB</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">google.colab</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You are running the code in Google Colab.&quot;</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">IN_COLAB</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You are running the code in the local computer.&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">IN_COLAB</span><span class="p">:</span>
    <span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>torchaudio
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>You are running the code in the local computer.
</pre></div>
</div>
</div>
</div>
<p><strong>下準備のコード</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">glue</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">_</span>

<span class="c1"># 実験に使うサンプル数</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">30000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;n_samples&quot;</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># グラフの設定</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.dpi&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;colorblind&quot;</span><span class="p">)</span>
<span class="n">color_palette</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;colorblind&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>平仮名73文字データセットの準備</strong></p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">zipfile</span>

<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;http://lab.ndl.go.jp/dataset/hiragana73.zip&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="c1"># HTTPリクエストを送ってデータサイズを取得</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">total_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;content-length&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">65535</span>

<span class="c1"># &quot;hiragana73&quot;フォルダが存在し、その中身が空でないことを確認</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;./hiragana73&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;./hiragana73&quot;</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># 実際のファイルのダウンロード</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">total_size</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">iter_content</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">)</span>

    <span class="c1"># ダウンロードが完了したらZIPを展開する</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "b05f88339f4744169dbb5a7dd465d522"}</script></div>
</details>
</div>
</section>
<section id="pytorch">
<h2><span class="section-number">3.2. </span>PyTorchの基本<a class="headerlink" href="#pytorch" title="Permalink to this heading">#</a></h2>
<p>PyTorchには、いくつかのモジュールが用意されており、代表的なものが、</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn.functional</span></code></p></li>
</ul>
<p>の3つである。慣例的に、これらをこのような形でエイリアスを与えてインポートする。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorchのモジュール群</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch</span></code>モジュールがテンソルデータそのもの(<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>等)や、データに対する操作 (<code class="docutils literal notranslate"><span class="pre">torch.exp</span></code>や<code class="docutils literal notranslate"><span class="pre">torch.transpose</span></code>等)が含まれる。</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn</span></code>モジュールには、ニューラルネットワークを構成するレイヤー (<code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code>や<code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code>等)や損失関数 (<code class="docutils literal notranslate"><span class="pre">nn.CrossEntropyLoss</span></code>や<code class="docutils literal notranslate"><span class="pre">nn.MSELoss</span></code>等)が含まれる。</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.functional</span></code>モジュールには、<code class="docutils literal notranslate"><span class="pre">torch.nn</span></code>モジュールに含まれるクラス定義に対応する関数が用意されている。例えば<code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code>に対応する関数として<code class="docutils literal notranslate"><span class="pre">F.linear</span></code>、<code class="docutils literal notranslate"><span class="pre">nn.MSELoss</span></code>に対応する関数として<code class="docutils literal notranslate"><span class="pre">F.mse_loss</span></code>、といった具合である。</p>
<p>また、インストールすることは必須ではないが、PyTorchに付属するライブラリにTorchVisionがある。TorchVisionは、主にコンピュータ・ビジョンへの応用を目的とした補助関数が多数用意されている。</p>
<p>これ以外にも、有名ネットワークモデルの学習済み重みなどが提供されており、<code class="docutils literal notranslate"><span class="pre">AlexNet</span></code>や<code class="docutils literal notranslate"><span class="pre">ResNet50</span></code>等のほか、<code class="docutils literal notranslate"><span class="pre">ViT</span></code>などの比較的新しいものも含まれている。</p>
<p>本資料では、画像の前処理に使う<code class="docutils literal notranslate"><span class="pre">transforms</span></code>モジュールだけを用いる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># TorchVision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
</pre></div>
</div>
</div>
</div>
<section id="torch-tensor">
<h3><span class="section-number">3.2.1. </span>torch.Tensor<a class="headerlink" href="#torch-tensor" title="Permalink to this heading">#</a></h3>
<p>PyTorchの中で変数を扱う場合、スカラーであってもベクトルであっても、はたまた行列であっても、共通で<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>という型を用いる。これは、NumPyの<code class="docutils literal notranslate"><span class="pre">np.array</span></code>とほとんど同じように使うことができる。</p>
<p>初期化をする方法には、いくつかあるが、大きく分けて、</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>のコンストラクタを呼び出す</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>関数を用いて<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>を作る</p></li>
<li><p>NumPyの配列を最初に用意して<code class="docutils literal notranslate"><span class="pre">torch.from_numpy</span></code>関数を使う</p></li>
</ul>
<p>の3つの方法がある。順に見ていこう。</p>
<section id="id5">
<h4>torch.Tensorを使う<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h4>
<p>まず、<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>を用いる場合には、通常のPythonやNumPyの配列を指定して初期化する。この時、配列がどのような型であっても、PyTorchの<code class="docutils literal notranslate"><span class="pre">default_dtype</span></code>に指定された型 (初期値は<code class="docutils literal notranslate"><span class="pre">float32</span></code>)の型にキャストされる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_npy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NumPy&#39;s dtype:&quot;</span><span class="p">,</span> <span class="n">x_npy</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x_npy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Torch&#39;s dtype:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NumPy&#39;s dtype: int64
Torch&#39;s dtype: torch.float32
</pre></div>
</div>
</div>
</div>
<p>このように、NumPyの配列としての型は<code class="docutils literal notranslate"><span class="pre">int64</span></code>型であるにも関わらず、<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>を用いることで、型が<code class="docutils literal notranslate"><span class="pre">float32</span></code>に変更されていることが分かる。なお、この初期の型は<code class="docutils literal notranslate"><span class="pre">torch.set_default_dtyoe</span></code>で変更することもできる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x_npy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Torch&#39;s dtype:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Torch&#39;s dtype: torch.float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h4>torch.tensorを使う<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>と関数が似ており、非常に紛らわしいが、厳密に言えば<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>はコンストラクタであり、<code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>は初期化用のユーティリティ関数である。<code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>にも、PythonやNumPyの配列を指定して<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>型の多次元配列を作ることができる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_npy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_npy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Torch&#39;s dtype:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Torch&#39;s dtype: torch.int64
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>は先ほどとは異なり、PythonやNumPyの配列で定義されている要素の型を引き継ぐ。そのため、上記の例では<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>の<code class="docutils literal notranslate"><span class="pre">dtype</span></code>が<code class="docutils literal notranslate"><span class="pre">int64</span></code>になっている。また、<code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>関数は、型を指定して<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>を作ることもできる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_npy</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Torch&#39;s dtype:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Torch&#39;s dtype: torch.float32
</pre></div>
</div>
</div>
</div>
<p>また、詳細については後述するが、PyTorchの自動微分の機能を使うために必要な<code class="docutils literal notranslate"><span class="pre">requires_grad</span></code>パラメータを指定することもできる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_npy</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float32,
       requires_grad=True)
</pre></div>
</div>
</div>
</div>
<p>このように<code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>関数は<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>のコンストラクタを呼び出す場合と比べて圧倒的に使い勝手が良い。</p>
</section>
<section id="torch-from-numpy">
<h4>torch.from_numpy<a class="headerlink" href="#torch-from-numpy" title="Permalink to this heading">#</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">torch.from_numpy</span></code>関数は<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>と仕様はかなり似ているが、</p>
<ul class="simple">
<li><p>引数としてNumPyの配列しか取ることができない</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dtype</span></code>はNumPyのものを引き継ぐ</p></li>
</ul>
<p>の2点が大きく異なる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_npy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_npy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Torch&#39;s dtype:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Torch&#39;s dtype: torch.int64
</pre></div>
</div>
</div>
</div>
<p>また<code class="docutils literal notranslate"><span class="pre">torch.from_numpy</span></code>は元のNumPyの配列とデータを共有しており、元の配列の値を書き換えるとそれが反映されるという違いがある。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># torch.Tensorの場合</span>
<span class="n">x_npy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x_npy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">x_npy</span> <span class="o">*=</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; After:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before: tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])
 After: tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># torch.from_numpyの場合</span>
<span class="n">x_npy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_npy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">x_npy</span> <span class="o">*=</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; After:&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
 After: tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])
</pre></div>
</div>
</div>
</div>
<p>正直なことを言えば、この違いを意識すべき場面は少ないが、時に問題が生じることがあるので、特段の理由がない限りは<code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>を使うのが、多くの場合で問題を引き起こす危険性が低い。</p>
</section>
</section>
<section id="id7">
<h3><span class="section-number">3.2.2. </span>torch.Tensorからの値の取り出し<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<p>また<code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>型で何らかの演算を行った後で、それをPythonやNumPyの配列に戻したいと思うこともあるだろう。この場合には、Pythonの配列なら<code class="docutils literal notranslate"><span class="pre">tolist</span></code>関数、NumPyの配列なら<code class="docutils literal notranslate"><span class="pre">numpy</span></code>関数を用いる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Pythonの配列に直す</span>
<span class="n">x_list</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">x_list</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_list</span><span class="p">)</span>

<span class="c1"># NumPyの配列に直す</span>
<span class="n">x_npy</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">x_npy</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_npy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Type: &lt;class &#39;list&#39;&gt;
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Type: &lt;class &#39;numpy.ndarray&#39;&gt;
[0 1 2 3 4 5 6 7 8 9]
</pre></div>
</div>
</div>
</div>
<p>また、配列の値が1つである場合に限り、<code class="docutils literal notranslate"><span class="pre">item</span></code>関数を使って、その1つの値をPythonの数値型として取り出すこともできる。この<code class="docutils literal notranslate"><span class="pre">item</span></code>関数は、要素が2つ以上ある配列に対して呼び出すと例外になるので注意すること。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id8">
<h2><span class="section-number">3.3. </span>自動微分<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h2>
<p>PyTorchに限らず、深層学習を支える重要な技術に<strong>自動微分</strong>がある。関数の微分は、損失関数の最小化といった最適化問題にとって重要な情報であり、例えば、最急降下法やニュートン法といったアルゴリズムは、それぞれ関数の1階微分 (勾配)と、2階微分 (Hesse行列)を用いる。</p>
<p>しかし、このような微分を求めるには、数学的に関数の微分を求めておく必要があり、特に関数が複雑な場合には、それを求めることは困難である (が、従来はMathematicaなどのソフトを使って、勾配を求めるコードを書き出していた)。</p>
<p>また、1階微分であれば、差分法によって近似をすることも可能ではあるが、数値精度の問題は残る。2階微分以上になると差分計算の誤差が蓄積していくため、数値的に満足な結果を得ることは非常に難しくなる。</p>
<section id="id9">
<h3><span class="section-number">3.3.1. </span>自動微分の仕組み<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h3>
<p><strong>自動微分</strong>は、プログラム的に、とある演算とその微分計算がペアとして定義されており、演算の列によって表される関数の微分は、各演算の微分から、合成関数の微分としての連鎖率 (chain rule)により計算される。</p>
<p>一例として、ここでは、</p>
<div class="math notranslate nohighlight">
\[
f(x) = \cos(x^2)
\]</div>
<p>の微分を例にとって見てみよう。</p>
<p>ここで、<span class="math notranslate nohighlight">\(g(x) = x^2\)</span>, <span class="math notranslate nohighlight">\(h(x) = \cos x\)</span>とすると、<span class="math notranslate nohighlight">\(f\)</span>は<span class="math notranslate nohighlight">\(g\)</span>と<span class="math notranslate nohighlight">\(h\)</span>の合成関数として<span class="math notranslate nohighlight">\(f = h \circ g\)</span>と表せる。言うまでもなく、<span class="math notranslate nohighlight">\(f\)</span>の微分<span class="math notranslate nohighlight">\(f'\)</span>は、<span class="math notranslate nohighlight">\(h\)</span>と<span class="math notranslate nohighlight">\(g\)</span>の微分を用いて、</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f'(x) &amp;= \frac{\text{d}f}{\text{d}x} = \frac{\text{d}h}{\text{d}g} \frac{\text{d}g}{\text{d}x} \\
&amp;= -\sin (g(x)) \cdot 2 x \\
&amp;= -2x \sin (x^2)
\end{aligned}
\end{split}\]</div>
<p>となる。ここで注目してほしいのは、計算の順序が、</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span>の値が与えられる</p></li>
<li><p><span class="math notranslate nohighlight">\(y = x^2\)</span>の値を計算する</p></li>
<li><p><span class="math notranslate nohighlight">\(z = \cos(y)\)</span>の値を計算する</p></li>
</ol>
<p>となっているということである。導関数<span class="math notranslate nohighlight">\(f\)</span>の微分を計算するときには、この逆順に、</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(z\)</span>の<span class="math notranslate nohighlight">\(z\)</span>に関する微分として<span class="math notranslate nohighlight">\(\text{d}z/\text{d}z=1\)</span>が与えられる</p></li>
<li><p>既知の<span class="math notranslate nohighlight">\(y\)</span>から<span class="math notranslate nohighlight">\(\text{d}z/\text{d}y = (\text{d}z/\text{d}z) \cdot (\text{d}z/\text{d}y) = 1 \cdot (-\sin(y)) = -\sin(y)\)</span>を計算する</p></li>
<li><p>既知の<span class="math notranslate nohighlight">\(x\)</span>から<span class="math notranslate nohighlight">\(\text{d}z/\text{d}x = (\text{d}z/\text{d}y) \cdot (\text{d}y/ \text{d}x) = (-\sin(y)) \cdot (2 x) = -2x \sin(x^2)\)</span>を計算する</p></li>
</ol>
<p>という流れになっている。従って、各演算<span class="math notranslate nohighlight">\(y=f(x)\)</span>において、</p>
<ul class="simple">
<li><p>演算の入力<span class="math notranslate nohighlight">\(x\)</span>を保持しておく</p></li>
<li><p>演算の導関数<span class="math notranslate nohighlight">\(\text{d}y/\text{d}x\)</span>を定義しておく</p></li>
</ul>
<p>という準備をしておけば、最終出力<span class="math notranslate nohighlight">\(z\)</span>の<span class="math notranslate nohighlight">\(y\)</span>に関する微分<span class="math notranslate nohighlight">\(\text{d}z/\text{d}y\)</span>が与えられれば、連鎖率を用いて<span class="math notranslate nohighlight">\(\text{d}z/\text{d}x\)</span>が求まる、という訳である。</p>
</section>
<section id="id10">
<h3><span class="section-number">3.3.2. </span>自動微分の利用<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
<p>では、上記の議論をPyTorchを用いて実験してみる。前述の通り、<code class="docutils literal notranslate"><span class="pre">torch.tensor</span></code>関数に<code class="docutils literal notranslate"><span class="pre">requires_grad</span></code>パラメータを指定することで、自動微分により勾配が計算される変数を作ることができる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 変数を作成</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>なお、一度、作成した<code class="docutils literal notranslate"><span class="pre">Tensor</span></code>に対して自動微分を有効にしたい場合には<code class="docutils literal notranslate"><span class="pre">requires_grad_</span></code>関数に<code class="docutils literal notranslate"><span class="pre">True</span></code>を渡す。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>それでは、ここで定義した<span class="math notranslate nohighlight">\(x\)</span>を用いて変数を用いて、<span class="math notranslate nohighlight">\(z = \cos(x^2)\)</span>を段階的に計算してみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># y = g(x) = x^2の計算</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y = g(x) = </span><span class="si">{:.1f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>

<span class="c1"># z = cos(y)の計算</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;z = h(y) = </span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>y = g(x) = 4.0
z = h(y) = -0.65364
</pre></div>
</div>
</div>
</div>
<p>最終的な<span class="math notranslate nohighlight">\(z\)</span>の<span class="math notranslate nohighlight">\(x\)</span>に関する微分を求めるには、<code class="docutils literal notranslate"><span class="pre">z.backward()</span></code>という関数を呼び出せば良い。ただし、この関数は単純にはスカラーの出力にしか使えないので注意が必要。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 微分の計算</span>
<span class="n">z</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>すると、予め自動微分を有効にしておいた変数には<code class="docutils literal notranslate"><span class="pre">grad</span></code>というメンバが追加され、そこに微分の値が代入される。<strong>なお、<code class="docutils literal notranslate"><span class="pre">backward</span></code>関数は、デフォルトでは、一度呼び出すと同じ変数に対して再度呼び出すことはできないようになっている(メモリをできるだけ削減するため)</strong>。同じ関数に対して、何度も<code class="docutils literal notranslate"><span class="pre">backward</span></code>を呼び出したい場合には、<code class="docutils literal notranslate"><span class="pre">backward</span></code>関数のパラメータに<code class="docutils literal notranslate"><span class="pre">retain_graph=True</span></code>を渡すこと (例外のメッセージにも同様のことが書かれている)。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">z</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exception:&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dzdx_autograd</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;autograd: dz/dx = </span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dzdx_autograd</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>

<span class="n">dzdx_analytic</span> <span class="o">=</span> <span class="o">-</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;analytic: dz/dx = </span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dzdx_analytic</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>autograd: dz/dx = 3.02721
analytic: dz/dx = 3.02721
</pre></div>
</div>
</div>
</div>
<p>以上から、自動微分によって、正しく演算の微分が計算できていることが確認できた。</p>
<p>上記と同等の計算は、単に入力となっている<span class="math notranslate nohighlight">\(x\)</span>に関する勾配を求めたいだけであれば <code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code>を用いて、以下のように書くこともできる。なお、<code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code>関数の戻り値は、配列になっているので注意すること。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
<span class="n">dzdx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;autograd.grad: dz/dz = </span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dzdx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>autograd.grad: dz/dz = 3.02721
</pre></div>
</div>
</div>
</div>
<div class="important admonition">
<p class="admonition-title">計算グラフ</p>
<p>上記の計算では、<span class="math notranslate nohighlight">\(y = x^2\)</span>, <span class="math notranslate nohighlight">\(z = \cos(y)\)</span>として、連鎖律を用いて微分の計算を行った。このように、「ある計算の結果」を「次の計算で用いる」というような、計算の繋がりによって作られるグラフ構造のことを<strong>計算グラフ</strong>と呼ぶ。通常、四則演算や関数の計算などの多くの計算は単項演算 (変数1つに対して行われる演算、<span class="math notranslate nohighlight">\(x^2\)</span>や<span class="math notranslate nohighlight">\(\cos(x)\)</span>など)と二項演算 (変数2つに対して行われる演算、<span class="math notranslate nohighlight">\(x + y\)</span>や<span class="math notranslate nohighlight">\(x^y\)</span>など)に分けられ、3つ以上の変数が絡む演算も基本的には単項演算と二項演算の組み合わせによって表現できる。</p>
<p>自動微分においては、計算の過程でこのような計算グラフをライブラリが内部的に構築しており、グラフを遡っていくことで、「最終的な出力」の「グラフ中に現れた変数」に関する微分を計算している。PyTorchの<code class="docutils literal notranslate"><span class="pre">backward</span></code>等の関数に渡せるパラメータの中にも<code class="docutils literal notranslate"><span class="pre">retain_graph</span></code>や<code class="docutils literal notranslate"><span class="pre">create_graph</span></code>など、「グラフ」という言葉を含むものがあるのはこのためである。</p>
</div>
</section>
<section id="id11">
<h3><span class="section-number">3.3.3. </span>自動微分可能な演算の定義<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h3>
<p>PyTorchを使うと、自分で微分可能な演算を定義することもできる。関数を定義するための一般的な方法は、<code class="docutils literal notranslate"><span class="pre">torch.autograd.Function</span></code>を継承したクラスを定義し、そこに静的メソッドとして<code class="docutils literal notranslate"><span class="pre">forward</span></code>と<code class="docutils literal notranslate"><span class="pre">backward</span></code>の二つの関数を実装するというものである。</p>
<p><code class="docutils literal notranslate"><span class="pre">forward</span></code>内で計算済みの変数で、<code class="docutils literal notranslate"><span class="pre">backward</span></code>の計算でも使うものは<code class="docutils literal notranslate"><span class="pre">ctx.save_for_backward(...)</span></code>を用いて<code class="docutils literal notranslate"><span class="pre">backward</span></code>関数に渡すことができる。変数の取り出しには<code class="docutils literal notranslate"><span class="pre">ctx.saved_tensors</span></code>を用いる。以下の例では、<span class="math notranslate nohighlight">\(\cos(x)\)</span>を例にとって、実際に微分可能な演算を定義してみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Function</span>


<span class="k">class</span> <span class="nc">MyCosine</span><span class="p">(</span><span class="n">Function</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="k">return</span> <span class="n">grad_output</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>この実装では、<code class="docutils literal notranslate"><span class="pre">forward</span></code>の中で、<span class="math notranslate nohighlight">\(y = \cos(x)\)</span>として、戻り値を計算した後に、入力の<span class="math notranslate nohighlight">\(x\)</span>と出力の<span class="math notranslate nohighlight">\(y\)</span>の値を<code class="docutils literal notranslate"><span class="pre">save_for_backward(x,</span> <span class="pre">y)</span></code>として<code class="docutils literal notranslate"><span class="pre">backward</span></code>側でも使えるようにしている。今回の計算では、<span class="math notranslate nohighlight">\(\cos(x)\)</span>の微分が<span class="math notranslate nohighlight">\(-\sin(x)\)</span>であるため、必ずしも<span class="math notranslate nohighlight">\(y\)</span>を<code class="docutils literal notranslate"><span class="pre">backward</span></code>側で使えるようにしておく必要はない。しかし、例えば<span class="math notranslate nohighlight">\(\exp(x)\)</span>やシグモイド関数<span class="math notranslate nohighlight">\(1 / (1 + \exp(x))\)</span>のように、導関数のなかに自分自身を含むようなものも多く、計算量の観点から、<code class="docutils literal notranslate"><span class="pre">forward</span></code>での出力を<code class="docutils literal notranslate"><span class="pre">backward</span></code>側で使えるようにしておくことが多い。</p>
<p>この<code class="docutils literal notranslate"><span class="pre">Function</span></code>型のサブクラスは<code class="docutils literal notranslate"><span class="pre">MyCosine.apply</span></code>のように呼び出すことで関数の<code class="docutils literal notranslate"><span class="pre">forward</span></code>が呼び出されて、その計算結果が使われた出力において<code class="docutils literal notranslate"><span class="pre">backward</span></code>が呼び出されると、自動的に<code class="docutils literal notranslate"><span class="pre">MyCosine</span></code>の<code class="docutils literal notranslate"><span class="pre">backward</span></code>のその計算の中で呼び出されるようになる。</p>
<p>PyTorch内部の実装においては、上記のような<code class="docutils literal notranslate"><span class="pre">Function</span></code>のサブクラスを内部で呼び出すような関数を定義している場合が多く、それに従って<code class="docutils literal notranslate"><span class="pre">my_cos</span></code>関数を定義しておく。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_cos</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">MyCosine</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>これを用いて、再度 <span class="math notranslate nohighlight">\(\cos(x^2)\)</span>の微分を計算してみると、以下のように正しく計算が行えていることが分かる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">my_cos</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">z</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;my cosine: dzdx = </span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>my cosine: dzdx = 3.02721
</pre></div>
</div>
</div>
</div>
</section>
<section id="id12">
<h3><span class="section-number">3.3.4. </span>二階微分の計算<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h3>
<p>続いて、前述の<span class="math notranslate nohighlight">\(f(x) = \cos(x^2)\)</span>の二階微分<span class="math notranslate nohighlight">\(f^{''}(x) = -2 \sin(x^2) - 4x^2 \cos(x^2)\)</span>の計算を自動微分で行ってみる。</p>
<p>実は、自動微分を使えば、高階微分を計算することも容易で、二階導関数を求めたい場合、一階導関数の計算中に計算グラフを遡っていく計算に対して、別の計算グラフを構築すれば良い。この計算グラフを再度遡って微分を求めることで二階微分が求まる、というわけである。</p>
<p>例えば、先ほどの計算であれば、連鎖律の途中で、<span class="math notranslate nohighlight">\(2x\)</span>の計算や<span class="math notranslate nohighlight">\(-\sin(x)\)</span>の計算が発生していたが、これらの計算について、途中結果を保存し、その微分計算が行えるように計算グラフを構築することができる。なお、二階微分を計算するときには<code class="docutils literal notranslate"><span class="pre">backward</span></code>関数の代わりに、<code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code>を使わないと警告メッセージが出るので注意すること (計算自体はできる)。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">dzdx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ddz_ddx_auto</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">dzdx</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="n">ddz_ddx_analy</span> <span class="o">=</span> <span class="o">-</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span> <span class="o">-</span> <span class="mf">4.0</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;autograd: ddz_ddx = </span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ddz_ddx_auto</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;analytic: ddz_ddx = </span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ddz_ddx_analy</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>autograd: ddz_ddx = 11.97190
analytic: ddz_ddx = 11.97190
</pre></div>
</div>
</div>
</div>
<p>このように、二階微分の場合も正しく計算できていることが分かる。以後、より高階な微分であっても<code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code>の引数で<code class="docutils literal notranslate"><span class="pre">create_graph=True</span></code>を指定する限りは計算し続けることができる。</p>
</section>
<section id="id13">
<h3><span class="section-number">3.3.5. </span>多変数関数の微分<a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h3>
<p>続いては、変数が2つ以上の場合の微分 (勾配)について見てみる。今回は例としてReosenbrock関数と呼ばれる、以下の関数について微分を計算してみる。</p>
<div class="math notranslate nohighlight">
\[
f(x, y) = a (x - 1)^2 + b(y - x^2)^2
\]</div>
<p>この関数において<span class="math notranslate nohighlight">\(a = 1\)</span>, <span class="math notranslate nohighlight">\(b = 100\)</span>とするとして、二次元平面上に値をプロットすると以下のようになる (カラーバーは対数の値に対して計算されている)。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">LogNorm</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="n">extent</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>
<span class="n">rosen</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">xs</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span> <span class="o">+</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">ys</span> <span class="o">-</span> <span class="n">xs</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">mappable</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">rosen</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">LogNorm</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0e4</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Rosenbrock function&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">rosen</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;white&quot;</span><span class="p">],</span> <span class="n">linewidths</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">norm</span><span class="o">=</span><span class="n">LogNorm</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0e4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_palette</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">mappable</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/1d07871fa8903f41bd8a22e6a71d37ea2b97a0017352e445e2b2b76f6cfc63a9.png" src="../../_images/1d07871fa8903f41bd8a22e6a71d37ea2b97a0017352e445e2b2b76f6cfc63a9.png" />
</div>
</div>
<p>この関数は、<span class="math notranslate nohighlight">\((1.0, 1.0)\)</span>の点を打った場所が関数の最小値をとる箇所になっているのだが、最小値の近傍が非常に狭い谷のような形になっており、さらにその谷が放物線上に湾曲しているため、この赤点の位置の最小値を求めることが困難であるとされている。</p>
<p>まずは<span class="math notranslate nohighlight">\((x, y) = (0, 0)\)</span>として、Rosenbrock関数自体の値を計算してみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span> <span class="o">+</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">**</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(1., grad_fn=&lt;AddBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>次に、単一の変数の場合と同様に、出力の<code class="docutils literal notranslate"><span class="pre">f</span></code>に対して<code class="docutils literal notranslate"><span class="pre">backward</span></code>を呼び出して、<span class="math notranslate nohighlight">\(x, y\)</span> (上記のコードでは<code class="docutils literal notranslate"><span class="pre">x</span></code>の0番目と1番目の要素に対応)に関する微分を求める。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([-2.,  0.])
</pre></div>
</div>
</div>
</div>
<p>Rosenbrock関数の<span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(y\)</span>に関する偏微分は、それぞれ</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\frac{\partial f}{\partial x} &amp;= 2a (x -1) - 4bx(y - x^2) \\
\frac{\partial f}{\partial y} &amp;= 2b (y - x^2)
\end{align}
\end{split}\]</div>
<p>であるので、<span class="math notranslate nohighlight">\(a = 1, b= 100\)</span>かつ<span class="math notranslate nohighlight">\((x, y) = (0, 0)\)</span>であるとき、導関数の値は<span class="math notranslate nohighlight">\((-2, 0)\)</span>になっており、上記の自動微分による結果と一致する。</p>
<hr class="docutils" />
<p>続いては、Rosenbrock関数の二階導関数としてのHesse行列 (Hessianとも言う)を求めてみる。この場合は、先ほどの1変数の場合よりは多少工夫が必要になる。
まずは、<code class="docutils literal notranslate"><span class="pre">f</span></code>に対して<code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code>を計算する。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span> <span class="o">+</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">**</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span>
<span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([-2.,  0.], grad_fn=&lt;AddBackward0&gt;),)
</pre></div>
</div>
</div>
</div>
<p>安直には、この<code class="docutils literal notranslate"><span class="pre">grad</span></code>に対して、もう一度<code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code>関数を適用すれば良さそうだが、前述の通り<code class="docutils literal notranslate"><span class="pre">backward</span></code>関数や<code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code>関数は、出力がスカラー出ない場合には使うことができない。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exception:&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Exception: grad can be implicitly created only for scalar outputs
</pre></div>
</div>
</div>
</div>
<p>従って、ここで計算に一工夫が必要になる。ここで連鎖律の計算を思い出してほしい。連鎖律を計算するとき、スカラー値スカラー関数の場合には、<span class="math notranslate nohighlight">\(\text{d}z / \text{d}z = 1\)</span>から、連鎖律が始まり、その前の計算の微分を順に乗していくことで最終的な入力変数に関する微分を計算していたのであった。</p>
<p>この理屈で言えば、出力が二次元ベクトルであるような関数において、連鎖律のスタートとなるべき値は</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\left( \frac{\partial x}{\partial x}, \frac{\partial y}{\partial x} \right) = (1, 0)
\left( \frac{\partial x}{\partial y}, \frac{\partial y}{\partial y} \right) = (0, 1)
\end{align}
\]</div>
<p>の2つとなることに気づく。そこで、このそれぞれを連鎖律のスタートとして<code class="docutils literal notranslate"><span class="pre">grad_outputs</span></code>パラメータに指定して<code class="docutils literal notranslate"><span class="pre">torch.autograd.grad</span></code>を呼び出してみる。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ddf_dxx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
    <span class="n">grad</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ddf_dyy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
    <span class="n">grad</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">ddf_dxx</span><span class="p">,</span> <span class="n">ddf_dyy</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[  2.,   0.],
        [  0., 200.]])
</pre></div>
</div>
</div>
</div>
<p>Rosenbrock関数のHesse行列は、解析的には</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{H} = \begin{bmatrix}
2a + 4b (y - x^2) + 8bx^2 &amp; -4bx \\
-4bx &amp; 2b
\end{bmatrix}
\end{split}\]</div>
<p>であるので、<span class="math notranslate nohighlight">\(a = 1, b = 100\)</span>, <span class="math notranslate nohighlight">\((x, y) = (0, 0)\)</span>の時には、</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{H} = \begin{bmatrix}
2 &amp; 0 \\ 0 &amp; 200
\end{bmatrix}
\end{split}\]</div>
<p>となり、自動微分の結果が解析的な微分結果と一致していることが分かる。</p>
</section>
</section>
<section id="id14">
<h2><span class="section-number">3.4. </span>ニュートン法の実装<a class="headerlink" href="#id14" title="Permalink to this heading">#</a></h2>
<p>それでは、ここで練習としてニュートン法を用いてRosenbrock関数の最小値を求めてみよう。ニュートン法は、Hesse行列<span class="math notranslate nohighlight">\(\mathbf{H}\)</span>と、<span class="math notranslate nohighlight">\(f\)</span>の勾配<span class="math notranslate nohighlight">\(\nabla f\)</span>を用いて、</p>
<div class="math notranslate nohighlight" id="equation-eq-newton-step">
<span class="eqno">(3.1)<a class="headerlink" href="#equation-eq-newton-step" title="この数式へのパーマリンク">#</a></span>\[
\boldsymbol\delta = \mathbf{H}^{-1} \nabla f
\]</div>
<p>のように更新幅を計算するような、繰り返し最適化法の一種である。これは、関数<span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span>の<span class="math notranslate nohighlight">\(\boldsymbol\delta\)</span>周りのTaylor展開により、</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x} + \boldsymbol\delta) \approx f(\mathbf{x}) + \frac{1}{1!} \boldsymbol\delta^\top \nabla f(\mathbf{x}) + \frac{1}{2!} \boldsymbol\delta^\top \mathbf{H} \boldsymbol\delta
\]</div>
<p>となることに起因する。この式を変形すると、</p>
<div class="math notranslate nohighlight">
\[
\frac{\text{d} f}{\text{d} \boldsymbol\delta}(\mathbf{x}) = \nabla f(\mathbf{x}) + \frac{1}{2} \mathbf{H}\boldsymbol\delta
\]</div>
<p>という式が得られる。従って、Taylor展開の第2項までで元の関数を近似した範囲においては、<span class="math notranslate nohighlight">\(\text{d} f / \text{d}\boldsymbol\delta = \mathbf{0}\)</span>となるような場所に移動することで、関数の最小値に近づくことができる (これは、関数を局所的に二次関数で近似して、その二次関数の「底」に移動することに対応する)。</p>
<p>実際には、最小化すべき関数が局所的に二次関数で近似できることばかりではないので、通常は<a class="reference internal" href="#equation-eq-newton-step">(3.1)</a>で求まった更新方向に小さな定数<span class="math notranslate nohighlight">\(\alpha\)</span>を乗じて<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>の値を</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^{t+1} = \mathbf{x}^t + \alpha \boldsymbol\delta
\]</div>
<p>のように更新することが多い。</p>
<p>では、ここまでの議論を踏まえて、実際に自動微分により求めたHesse行列を用いてRosenbrock関数を最小化してみよう (以下にコードと実行結果を示すが、まずは自分自身で考えてみてほしい)。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rosenbrock</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span> <span class="o">+</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">**</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span>


<span class="k">def</span> <span class="nf">calc_newton_step</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">gx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
        <span class="n">grad</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">gy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
        <span class="n">grad</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">gx</span><span class="p">,</span> <span class="n">gy</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">pts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">fx</span> <span class="o">=</span> <span class="n">rosenbrock</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">calc_newton_step</span><span class="p">(</span><span class="n">fx</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">dx</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([1., 1.], requires_grad=True)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">LogNorm</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="n">extent</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>
<span class="n">rosen</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">xs</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span> <span class="o">+</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">ys</span> <span class="o">-</span> <span class="n">xs</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span> <span class="o">**</span> <span class="mf">2.0</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">mappable</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">rosen</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">LogNorm</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0e4</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Rosenbrock function&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">rosen</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;white&quot;</span><span class="p">],</span> <span class="n">linewidths</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">norm</span><span class="o">=</span><span class="n">LogNorm</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0e4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_palette</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color_palette</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># 軌跡のプロット</span>
<span class="n">pts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pts</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pts</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">pts</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color_palette</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="s2">&quot;3.0&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">mappable</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/e065d23e1cdbcb89023cdee8bb829b89d25cd6e9eb3a072adb5f460f6d37146b.png" src="../../_images/e065d23e1cdbcb89023cdee8bb829b89d25cd6e9eb3a072adb5f460f6d37146b.png" />
</div>
</div>
<p>この図では、<span class="math notranslate nohighlight">\((0.0, 0.0)\)</span>の初期値から<span class="math notranslate nohighlight">\((1.0, 1.0)\)</span>の最小値に至るまでの最適化の過程をマーカー付きの曲線で示している。各マーカーの位置を見てみると、徐々に最小値に至るスピードが遅くなりつつも、正しく関数の最小値を取る箇所に収束していることが分かる。</p>
<p>Rosenbrock関数の最小化については、解の初期値やニュートン法のステップ幅を変化させることで、収束が不安定になって最小解からはずれて・近づいてを繰り返すような軌跡を描くこともある。ぜひ、いろいろなパラメータで軌跡を描画して、その性質の理解に努めて欲しい。</p>
<div class="admonition note">
<p class="admonition-title">注釈</p>
<p>ここでは、関数の勾配を求めて、勾配法により関数を最小化する問題を解いた。深層学習は、ニューラルネットのパラメータを変数として、その変数を同じく勾配法により最適化する問題であり、最小化する関数は<strong>損失関数</strong>(loss function)と呼ばれる (反対に目的を達成するために最大化される関数を<strong>目的関数</strong>と呼ぶ)。</p>
<p>ニューラルネットのパラメータ最適化(=訓練)には、ニュートン法や準ニュートン法のような損失関数の二階微分を考慮するような方法を用いることは少なく (ただしAdaSecant<span id="id15">[<a class="reference internal" href="#id51" title="Caglar Gulcehre, Marcin Moczulski, and Yoshua Bengio. Adasecant: robust adaptive secant method for stochastic gradient. In IEEE International Joint Conference on Neural Network. 2014.">Gulcehre <em>et al.</em>, 2014</a>]</span>のような二階微分を考慮する方法もある)、多くの場合は単純な確率的最急降下法やRMSprop, Adamのようなアルゴリズムが使われることが多い。これは、パラメータ数が多くなると、Hesse行列を求めるのに多くの計算量が必要になるためで、そうであれば、一階微分だけが求まれば実行できる最急降下法を安定化させるように工夫する方が良い、という発想である。</p>
</div>
</section>
<section id="id16">
<h2><span class="section-number">3.5. </span>深層学習<a class="headerlink" href="#id16" title="Permalink to this heading">#</a></h2>
<p>PyTorchを使った深層学習をするために準備すべきことはいくつかある。以下では、</p>
<ul class="simple">
<li><p><span class="xref myst">データローダの実装</span></p></li>
<li><p><span class="xref myst">データセットの準備</span></p></li>
<li><p><a class="reference internal" href="#ssec-network-architecture"><span class="std std-ref">ネットワークの構築</span></a></p></li>
<li><p><span class="xref myst">オプティマイザの準備</span></p></li>
<li><p><span class="xref myst">学習ループの実装</span></p></li>
</ul>
<p>のそれぞれについて順に説明する。</p>
<p>(ssec:data-loader)</p>
<section id="id17">
<h3><span class="section-number">3.5.1. </span>データローダの作成<a class="headerlink" href="#id17" title="Permalink to this heading">#</a></h3>
<p>データローダとは、PyTorchを用いたニューラルネットワークの学習において、ミニバッチ学習を簡単にするための仕組みである。通常、深層学習には大量の訓練データが必要であり、それら全てを考慮したパラメータの更新方向(=勾配)を求めることは現実的ではない。</p>
<p>そこで、大量の訓練データから少数のデータ、すなわちミニバッチをサンプルし、そのミニバッチ内のデータによって与えられる勾配が、データ全体から求まる勾配の近似として十分に正しく動作することを仮定する。データから収集してくるミニバッチの数は<code class="docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code>型のサブクラスとして用意されたデータセット・クラスを引数にとる<code class="docutils literal notranslate"><span class="pre">torch.data.utils.data.DataLoader</span></code>によって制御できる。</p>
<p>では、上記のひらがな73文字データセットについて、まずはデータの読み出しを行う役割を持つデータセット・クラスを作成してみよう。データセット・クラスは<code class="docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code>型のサブクラスとして実装する。この際、コンストラクタと合わせて、データの総数を返す<code class="docutils literal notranslate"><span class="pre">__len__</span></code>関数と、データ1つをサンプルする<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>関数の二つを実装する。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>


<span class="k">class</span> <span class="nc">HiraganaDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    ひらがな73文字データセット</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataroot</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">HiraganaDataset</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dataroot</span> <span class="o">=</span> <span class="n">dataroot</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

        <span class="c1"># 各ひらがなの画像が入っているフォルダを列挙</span>
        <span class="n">folders</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataroot</span><span class="p">)])</span>
        <span class="n">chars</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;U&quot;</span><span class="p">,</span> <span class="s2">&quot;0x&quot;</span><span class="p">),</span> <span class="mi">16</span><span class="p">))</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">folders</span><span class="p">]</span>
        <span class="n">n_chars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>
        <span class="n">char2num</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)}</span>
        <span class="n">folders</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataroot</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">folders</span><span class="p">]</span>

        <span class="c1"># 各フォルダに含まれる画像ファイルを列挙、配列に格納</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">folders</span><span class="p">:</span>
            <span class="n">char</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;U&quot;</span><span class="p">,</span> <span class="s2">&quot;0x&quot;</span><span class="p">)</span>
            <span class="n">char</span> <span class="o">=</span> <span class="nb">chr</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">char</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
            <span class="n">num</span> <span class="o">=</span> <span class="n">char2num</span><span class="p">[</span><span class="n">char</span><span class="p">]</span>

            <span class="n">image_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">d</span><span class="p">)]</span>
            <span class="n">image_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">image_files</span> <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.png&quot;</span><span class="p">)]</span>
            <span class="n">image_files</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">image_files</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="n">f</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">image_files</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ファイルの総数を返す&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;データ1つをサンプルする&quot;&quot;&quot;</span>
        <span class="n">image_file</span><span class="p">,</span> <span class="n">num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_file</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">image</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span><span class="s2">&quot;Failed to load image: </span><span class="si">{:s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">num</span>
</pre></div>
</div>
</div>
</div>
<p>さて、上記のデータセット・クラスにはコンストラクタの引数に<code class="docutils literal notranslate"><span class="pre">transform</span></code>という変数が渡されている。PyTorchではTorchVisionの<code class="docutils literal notranslate"><span class="pre">transforms</span></code>モジュールに用意されたデータ操作のためのクラスを用いることで、簡単にデータの前処理を行うことができる。</p>
<p>例えば、<a class="reference internal" href="feature-extraction.html#sec-feature-extraction"><span class="std std-ref">特徴量の抽出</span></a>で行っていたような</p>
<ul class="simple">
<li><p>画像をグレースケールに変更</p></li>
<li><p>画像をランダムに回転、拡大・縮小</p></li>
</ul>
<p>といった操作は <code class="docutils literal notranslate"><span class="pre">transforms.GrayScale</span></code>や<code class="docutils literal notranslate"><span class="pre">transforms.RandomAffine</span></code>によって実現することができる。複数の前処理操作を組み合わせる場合には、<code class="docutils literal notranslate"><span class="pre">transforms.Compose</span></code>に前処理を行うクラス・インスタンスの配列を渡せば良い。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Grayscale</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomAffine</span><span class="p">(</span><span class="n">degrees</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="mi">90</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">]),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ConvertImageDtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">HiraganaDataset</span><span class="p">(</span><span class="n">dataroot</span><span class="o">=</span><span class="s2">&quot;hiragana73&quot;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="n">train_data</span><span class="p">,</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">n_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_samples</span><span class="p">])</span>
<span class="n">test_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">n_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_samples</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="ssec-network-architecture">
<span id="id18"></span><h3><span class="section-number">3.5.2. </span>ネットワークの構築<a class="headerlink" href="#ssec-network-architecture" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id19">
<h3><span class="section-number">3.5.3. </span>学習の準備<a class="headerlink" href="#id19" title="Permalink to this heading">#</a></h3>
<p>例のごとく、最初の<span class="output text_plain">30000</span>個のデータだけを実験に用いる。</p>
</section>
<section id="id20">
<h3><span class="section-number">3.5.4. </span>最適化手法の設定<a class="headerlink" href="#id20" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span><span class="mi">48</span> <span class="o">*</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">73</span><span class="p">)</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0e-3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id21">
<h3><span class="section-number">3.5.5. </span>誤差関数の設定<a class="headerlink" href="#id21" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_true</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s2">&quot;loss=</span><span class="si">{:1.3f}</span><span class="s2">, acc=</span><span class="si">{:1.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>

    <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "7d37b9afb31840d9a8c103f56edd6037"}</script><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">41</span><span class="p">],</span> <span class="n">line</span> <span class="mi">5</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">data</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="ne">----&gt; </span><span class="mi">5</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_true</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nn">File ~/.cache/pypoetry/virtualenvs/sds-adv-ml-t6Z6UgPC-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1496</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1497</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1498</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1499</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1500</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1501</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1502</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1503</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">Cell In[38], line 11,</span> in <span class="ni">Network.forward</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">11</span>     <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span>     <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span>     <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="nn">File ~/.cache/pypoetry/virtualenvs/sds-adv-ml-t6Z6UgPC-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1496</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1497</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1498</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1499</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1500</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1501</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1502</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1503</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/.cache/pypoetry/virtualenvs/sds-adv-ml-t6Z6UgPC-py3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py:114,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: mat1 and mat2 must have the same dtype
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
<span class="n">n_succ</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">n_succ</span> <span class="o">+=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_true</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Acc: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_succ</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id22">
<h2><span class="section-number">3.6. </span>畳み込みニューラルネット<a class="headerlink" href="#id22" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">12</span> <span class="o">*</span> <span class="mi">12</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">73</span><span class="p">)</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0e-3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_true</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s2">&quot;loss=</span><span class="si">{:1.3f}</span><span class="s2">, acc=</span><span class="si">{:1.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>

    <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
<span class="n">n_succ</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">n_succ</span> <span class="o">+=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_true</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Acc: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_succ</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id23">
<h2><span class="section-number">3.7. </span>練習問題<a class="headerlink" href="#id23" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>上記のニュートン法により得られた関数最小化の軌跡を、単純な<a class="reference external" href="https://en.wikipedia.org/wiki/Gradient_descent">最急降下法</a>ならびに一階導関数だけを用いてHesse行列を近似する<a class="reference external" href="https://en.wikipedia.org/wiki/Quasi-Newton_method">準ニュートン法</a>と比較せよ。</p></li>
</ul>
</section>
<section id="id24">
<h2><span class="section-number">3.8. </span>参考文献<a class="headerlink" href="#id24" title="Permalink to this heading">#</a></h2>
<div class="docutils container" id="id25">
<dl class="citation">
<dt class="label" id="id34"><span class="brackets"><a class="fn-backref" href="#id3">Fuk80</a></span></dt>
<dd><p>Kunihiko Fukushima. Neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. <em>Biological Cybernetics</em>, 36(4):193–202, apr 1980. <a class="reference external" href="https://doi.org/10.1007/bf00344251">doi:10.1007/bf00344251</a>.</p>
</dd>
<dt class="label" id="id51"><span class="brackets"><a class="fn-backref" href="#id15">GMB14</a></span></dt>
<dd><p>Caglar Gulcehre, Marcin Moczulski, and Yoshua Bengio. Adasecant: robust adaptive secant method for stochastic gradient. In <em>IEEE International Joint Conference on Neural Network</em>. 2014.</p>
</dd>
<dt class="label" id="id33"><span class="brackets"><a class="fn-backref" href="#id4">KSH12</a></span></dt>
<dd><p>Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In <em>Proceedings of the 25th International Conference on Neural Information Processing Systems</em>, 1097–1105. 2012. <a class="reference external" href="https://doi.org/10.1145/3065386">doi:10.1145/3065386</a>.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./contents/sec2"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="feature-extraction.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">前へ</p>
        <p class="prev-next-title"><span class="section-number">2. </span>特徴量抽出</p>
      </div>
    </a>
    <a class="right-next"
       href="exercise-ogura.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">次へ</p>
        <p class="prev-next-title"><span class="section-number">4. </span>演習2 - 百人一首エージェントを作る</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> 目次
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.1. 深層学習の歴史</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch">3.2. PyTorchの基本</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torch-tensor">3.2.1. torch.Tensor</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">torch.Tensorを使う</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">torch.tensorを使う</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#torch-from-numpy">torch.from_numpy</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">3.2.2. torch.Tensorからの値の取り出し</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">3.3. 自動微分</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">3.3.1. 自動微分の仕組み</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">3.3.2. 自動微分の利用</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">3.3.3. 自動微分可能な演算の定義</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">3.3.4. 二階微分の計算</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">3.3.5. 多変数関数の微分</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">3.4. ニュートン法の実装</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">3.5. 深層学習</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">3.5.1. データローダの作成</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ssec-network-architecture">3.5.2. ネットワークの構築</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">3.5.3. 学習の準備</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">3.5.4. 最適化手法の設定</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id21">3.5.5. 誤差関数の設定</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id22">3.6. 畳み込みニューラルネット</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id23">3.7. 練習問題</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id24">3.8. 参考文献</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
著者 Tatsuya Yatagawa
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright CC BY-NC-SA 4.0, 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>